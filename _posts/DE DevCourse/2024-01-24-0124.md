---
title: "[DEV] 15주차. Kafka와 Spark Streaming 기반 스트리밍 처리 (2)"
last_modified_at: 2024-01-24T12:00:00-05:00
layout: post
categories:
    - Data Engineering
excerpt: 
toc: true
toc_sticky: true
toc_icon: "cog"
author_profile: true
mathjax: true
tag: [DevCourse, TIL, DE, KDT, Kafka]
---

## 1. Kafka 소개

### Kafka

- 실시간 데이터를 처리하기 위해 설계된 오픈소스 분산 스트리밍 플랫폼
    - 데이터 재생이 가능한 분산 커밋 로그 (Distributed Commit Log)

- Scalability와 Fault Tolerance를 제공하는 Publish-Subscription 메시징 시스템
    - 한 partition은 3개의 broker에 저장됨
    - Producer - Consumer
- **High Throughput Low Latency 실시간 데이터 처리**에 맞게 구현됨
- 분산 아키텍처를 따르기 때문에 Scale Out 형태로 스케일 가능
    - 서버(Broker) 추가를 통해 Scalability
- 정해진 보유기간 (retention period) 동안 메시지 저장

### 기존 메시징 시스템 및 DB와 비교

- **기존 메시징 시스템과는 달리 메시지를 보유 기간 동안 저장**
    - 소비자가 오프라인 상태일 때에도 내구성과 내결함성 보장
    - 보유 기간: 한 topic이 가질 수 있는 데이터의 크기를 지정할 수도 있음

- **Kafka는 메시지 생산과 소비를 분리**
    - 생산자와 소비자가 각자의 속도에 맞춰 독립적으로 작업이 가능하도록 함
    - 중간에 다른 소비자가 생기더라도 자연스럽게 추가할 수 있음
    - 시스템 안정성을 높일 수 있음

- **Kafka는 높은 처리량과 저지연 데이터 스트리밍을 제공**
    - Scale-Out 아키텍처

- **한 파티션 내에서는 메시지 순서를 보장해줌**
    - 다수의 파티션에 걸쳐서는 *Eventually Consistent*
    - topic을 생성할 때 파티션 개수, 파티션 별로 몇 개의 복제본을 만들 것인지 지정 가능     
        - Eventually Consistency vs. Strong Consistency : 소비하는 사람 관점에서 생각하여 결정하기!
        - *Strong Consistency*
            - 어떤 topic의 event를 produce해서 사용하는 경우 이 복제본이 모두에게 전달이 될 때까지 기다려야 함
            - 내가 write한 event를 바로 읽을 수 있음
            - 생성할 때에는 시간이 더 걸리지만, *읽는 관점에서는 항상 완전한 데이터*를 읽을 수 있음
        - *Eventually Consistency*  
            - 복제본 중 몇 개의 정보가 전달될 때까지 기다릴 것인지 정할 수 있음 
            - 내가 쓰고 바로 읽는 경우 내가 쓴 event가 return이 안 될 확률이 큼

- **사내 내부 데이터 버스로 사용되기 시작**
    - 워낙 데이터 처리량이 크고 다수 소비자를 지원하기 때문에 가능

#### Eventual Consistency

- 100대 서버로 구성된 분산 시스템에 레코드를 하나 쓴다면 그 레코드를 바로 읽을 수 있을까?
    - 내가 쓴 레코드가 온전히 return 될까?
    - 보통 하나의 데이터 블록은 여러 서버에 나눠 저장됨 (Replication Factor)
        - 그래서 데이터를 새로 쓰거나 수정하면 전파되는데 시간이 걸림
    - 보통 읽기 작업은 다수의 데이터 copy 중 하나를 대상으로 일어나기 때문에, 앞서 전파 시간에 따라 데이터가 있을 수도 있고 없을 수도 있음

- Strong Consistency vs. Eventual Consistency
    - 보통 데이터를 쓸 때 복제가 완료될 때까지 기다리는 구조라면 Strong Consistency
    - 바로 return한다면 **Eventual Consistency**
        - 대부분 이것으로 충분
    
### 주요 기능 및 이점

- 스트림 처리
    - 실시간 스트림 처리를 목표로 만들어진 서비스
    - ksqlDB를 통해 SQL로도 실시간 이벤트 데이터 처리 가능

- High Throughput (높은 처리량)
    - 초당 수백 만개의 메시지 처리 가능

- Fault Tolerance (내결함성)
    - 데이터 복제 및 분산 커밋 로그 기능 제공 -> 장애 대응 용이

- Scalability (확장성)
    - 클러스터에 브론커를 추ㅏ가하여 

## 2. Kafka 아키텍처

### 데이터 이벤트 스트림

- **Topic** 이라고 부름
    - producer는 topic을 만들고, consumer는 topic에서 데이터를 읽어들이는 구조
    - topic마다 보존 정책이 있어 그에 맞춰 데이터를 저장함

### Message (Event) 구조: Key, Value, Timest

- 최대 1MB
- Timestamp는 보통 데이터가 Topic에 추가된 시점
- Key 자체도 복잡한 구조를 가질 수 있음
    - key가 나중에 Topic 데이터를 나눠서 저장할 때 사용됨 (Partitioning)
- Header는 선택적 구성 요소
    - 경량 메타 데이터 정보 (key-value)

### Topic과 Partition

- 하나의 topic확장성을 위해 다수의 Partition으로 나뉘어 저장됨
- 메시지가 어느 partition에 속하는지 결정하는 방식은 *키의 유무*에 따라 달라짐
    - *키가 있다면*: hashing 값을 partition 수로 나눈 나머지로 결정
    - 키가 없다면: 라운드 로빈으로 결정 (비추)

### Topic과 Partition과 복제본

- 하나의 partition은 Fail-over를 위해 Replication Partition을 가짐
- 각 partition별로 Leader와 Follower가 존재
    - 쓰기는 Leader를 통해 이루어지고, 읽기는 Leader/Follower들을 통해 이루어짐
    - partition별로 Consistency Level 설정 가능 `in-sync replica - "ack"`
- partition별로 누가 Leader이고 Follower인지 관리가 중요해짐

### Topic 파라미터들

- 이름
- partition 수
- 복제본의 수 (원본 포함 개수)
- Consistency Level ("acks") : 1, 2, .., "all"
- 데이터 보존 기한
- 메시지 압축 방식
- ...

<br>

- 예시
<img width="503" alt="스크린샷 2024-02-02 오후 4 34 37" src="https://github.com/bokyung124/AWS_Exercise/assets/53086873/61fd5feb-44c9-4397-8eec-073ae509e7f8">

### Broker

- 실제 데이터를 저장하고 관리하는 서버
- Kafka 클러스터는 기본적으로 다수의 broker로 구성됨
    - + 원활한 관리와 부가 기능을 위한 다른 서비스들이 추가됨 (Zookeeper 등)
    - 한 클러스터는 최대 20만 개까지 partition 관리 가능
    - broker들이 실제로 Producer/Consumer들과 통신 수행

- **Topic의 Partition들을 실제로 관리해주는 것이 Broker**
    - 한 broker는 최대 4000개의 partition 처리 가능

- broker는 물리 서버 혹은 VM 혹은 docker container 위에서 동작
    - 해당 서버의 디스크에 partition 데이터들을 기록함
- **broker 수를 늘림으로써 클러스터 용량을 늘림 (Scale Out)**

- 20만개, 4천개 제약은 Zookeeper를 사용하는 경우!
    - 최근, Zookeeper를 대체하는 KRaft가 개발 중, 일부 서비스

<img width="287" alt="스크린샷 2024-02-02 오후 4 42 42" src="https://github.com/bokyung124/AWS_Exercise/assets/53086873/bafe9031-82b4-49bd-a4cc-d5c89d8c7d6b">

### 메타정보 관리

- Broker 리스트 관리 (Broker Membership)
    - 누가 controller인가 (Controller Election)
- Topic 리스트 관리 (Topic Configuration)
    - Topic을 구성하는 Partition 관리
    - Partition 별 Replica 관리
- Topic 별 ACL (Access Control Lists) 관리
- Quota 관리

### Zookeeper와 Controller

- **Controller : Broker이면서 Partition을 관리하는 책임을 지는 노드**
    - Zookeeper를 사용하여 partition을 관리해왔음
- zookeeper에 여러 문제가 있기 때문에 현재로는 두가지 모드가 존재 (복잡 & 복구 어려움)
    - *Zookeeper 모드*
        - 3, 5, 7대의 서버를 Zookeeper Ensemble을 구성하기 위해 사용
        - Controller가 Zookeeper를 통해 메타데이터 관리와 리더 선출 담당
        - 하나의 Controller 존재
    - *KRaft 모드*
        - Zookeeper를 완전히 배제하고 내부적으로 Controller가 역할을 대신 수행
        - 다수의 Controller들이 Zookeeper 역할 대신 수행
            -  Controller들은 보통 Broker들이기도 함

<br>

#### Zookeeper

- 분산 시스템에서 널리 사용되는 Distributed Coordination Service
    - 동기화, 구성 관리, 리더 선출 등 *분산 시스템의 관리와 조율*을 위한 중앙 집중 시스템 제공
- *다양한 문제 존재*
    - 지원하는 데이터 크기가 작고, 동기 모드로 동작하기 때문에 처리 속도가 느림
        - 어느 스케일 이상으로 확장성이 떨어짐
    - 환경설정 복잡
    - 기존에 Zookeeper를 사용하던 서비스들이 Zookeeper를 대체하기 시작
        - ElasticSearch가 또 다른 예

- 일반적인 사용 사례
    - Kafka (메시지 큐)
    - HBase (분산 데이터베이스 조정)
    - Storm (분산 스트림 처리)

## 3. Kafka 중요 개념

- **Producer, Broker, Consumer, Controller, Consumer Group**

<img width="556" alt="스크린샷 2024-02-02 오후 5 03 28" src="https://github.com/bokyung124/AWS_Exercise/assets/53086873/997cf13e-2241-48ba-ba70-e471dd67930e">


<br>

- **Topics, Partitions, Segments**

<img width="655" alt="스크린샷 2024-02-02 오후 5 10 00" src="https://github.com/bokyung124/AWS_Exercise/assets/53086873/3247a022-20dd-41dc-8911-dd2a5ca7e339">


### Topic

<img width="578" alt="스크린샷 2024-02-02 오후 5 13 33" src="https://github.com/bokyung124/AWS_Exercise/assets/53086873/43c13391-d144-44e1-a02e-35b584992ca1">

- Consumer가 데이터(message)를 읽는다고 없어지지 않음
- Consumer 별로 어느 위치의 데이터를 읽고 있는지 위치 정보를 공유함 `offset`
- Fault Tolerance를 위해 이 정보는 중복 저장됨

<img width="620" alt="스크린샷 2024-02-02 오후 5 15 57" src="https://github.com/bokyung124/AWS_Exercise/assets/53086873/44c475a1-f754-44ab-93db-0e4a502572d3">

### Partition과 Segment

- 하나의 partition은 다수의 segment로 구성됨    
    - segment는 변경되지 않고, 추가만 가능한 로그 파일이라고 볼 수 있음 (Immutable, Append-Only)
        - Commit Log
- 각 segment는 디스크 상에 존재하는 하나의 파일
- segment는 최대 크기가 있어 이를 넘어가면 새로운 segment 파일을 만들어냄
    - 각 segment는 데이터 오프셋 범위를 갖게됨
    - segment 최대 크기는 1GB 혹은 일주일치의 데이터