<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-10-13T12:12:43+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Your awesome title</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name>GitHub User</name></author><entry><title type="html">[k8s] Kubernetes Basic</title><link href="http://localhost:4000/infra/2023/09/22/k8s.html" rel="alternate" type="text/html" title="[k8s] Kubernetes Basic" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T07:00:00+09:00</updated><id>http://localhost:4000/infra/2023/09/22/k8s</id><content type="html" xml:base="http://localhost:4000/infra/2023/09/22/k8s.html"><![CDATA[<p>참고자료 https://www.youtube.com/watch?v=Iu9ТС13vPQ&amp;list=PLApuRIvrZKohaBHVXAOhUD-RxDOuQ3z0c&amp;index=8</p>

<h2 id="1-kubernetes">1. Kubernetes</h2>

<ul>
  <li>도커 컨테이너를 위한 오픈소스 오케스트레이션 프레임워크</li>
  <li>컨테이너화된 애플리케이션을 자동으로 배포, 스케일링 및 관리해주는 오픈소스 시스템</li>
  <li>하나의 머신에서 여러 컨테이너를 실행할 수 있고, 해당 머신이 클러스터 구성</li>
  <li>웹 애플리케이션과 같은 장기 실행 서비스 실행 가능 -&gt; 이러한 컨테이너의 상태 관리</li>
  <li>하나의 호스트에서 몇 개의 도커 컨테이너를 수동으로 실행하는 대신, 하나의 노드에서 시작해 최대 수천 개의 노드로 올라갈 수 있음</li>
  <li>자체 데이터 센터의 온프레미스, 공용 구글 클라우드, AWS, 다른 클라우드나 하이브리드 어디에서나 실행 가능</li>
</ul>

<p><br /></p>

<h2 id="2-k8s-기능">2. K8s 기능</h2>

<ul>
  <li><strong>선언적 구성과 자동화 용이</strong>
    <ul>
      <li>명령적 접근법
        <ul>
          <li>원하는 상태를 만들기 위해 필요한 동작을 지시하는 방식</li>
          <li>CLI 환경에서 <code class="language-plaintext highlighter-rouge">kubectl</code> 을 통한 구성요소 생성/수정/삭제 명령어를 수행하는 방식</li>
          <li>필요한 요소를 명령어 한 줄로 즉시 생성하여 다룰 수 있게 해주는 장점</li>
          <li>한계점
            <ul>
              <li>명령어만으로 수행 가능한 작업이 제한적</li>
              <li>협업 환경에서 작업 내역 추적 어려움</li>
              <li>현재 작업 환경의 설정사항을 직접 파악해야 함
                <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  kubectl run nginx <span class="nt">--image</span><span class="o">=</span>nginx
  kubectl create deployment nginx <span class="nt">--image</span><span class="o">=</span>nginx
  kubectl expose deployment nginx <span class="nt">--port</span><span class="o">=</span>80
  kubectl edit deployment nginx
  kubectl scale deployment nginx <span class="nt">--replicas</span><span class="o">=</span>5
  kubectl <span class="nb">set </span>image deploymnet nginx <span class="nv">ngingx</span><span class="o">=</span>nginix:1.18
  kubectl &lt;create|replace|delete&gt; <span class="nt">-f</span> nginx.yaml
</code></pre></div>                </div>
              </li>
            </ul>
          </li>
        </ul>
      </li>
      <li>선언적 접근법
        <ul>
          <li>원하는 상태 그 자체를 선언하는 방식</li>
          <li>YAML 파일을 통해 원하는 구성요소의 상태 기술 -&gt; <code class="language-plaintext highlighter-rouge">kubectl apply -f &lt;file.yaml</code> 형태의 명령어로 적용</li>
          <li>관리자가 선언한 특정한 형태를 시스템이 스스로 파악하여 반영하는 프로세스
  ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
  name: nginx
  labels:
      app: nginx
  spec:
  containers:
            <ul>
              <li>name: nginx-container
image: nginx:1.20.2
  ```</li>
            </ul>
          </li>
          <li>적용하고자 하는 yaml 파일이
            <ul>
              <li>요구되는 문법에 맞게 작성되었는지</li>
              <li>해당되는 요소가 기존 클러스터에 이미 배포되었는지</li>
              <li>있다면 업데이트,</li>
              <li>없다면 신규 생성</li>
            </ul>
          </li>
          <li>위 과정을 쿠버네티스가 알아서 진행</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>자동화된 롤아웃과 롤백</strong>
    <ul>
      <li>애플리케이션 변경시 점진적으로 롤아웃하는 동시에, 애플리케이션을 모니터링해서 모든 인스턴스가 동시에 종료되지 않도록 보장</li>
      <li>문제가 발생하면 변경사항 롤백</li>
    </ul>
  </li>
  <li><strong>스토리지 오케스트레이션</strong>
    <ul>
      <li>로컬 스토리지, AWS, GCP와 같은 퍼블릭 클라우드, 또는 NFS 같은 네트워크 스토리지 시스템에서 원하는 시스템 자동으로 마운트</li>
    </ul>
  </li>
  <li><strong>서비스 디스커버리와 로드 밸런싱</strong>
    <ul>
      <li>익숙하지 않은 서비스 디스커버리 매커니즘을 사용하기 위해 애플리케이션 수정할 필요 없음</li>
      <li>pod에 고유한 IP 주소와 pod 집합에 대한 단일 DNS명 부여</li>
      <li>그것들 간에 로드밸런스 수행할 수 있음</li>
    </ul>
  </li>
  <li><strong>자가 치유</strong>
    <ul>
      <li>실패한 컨테이너를 재시작하고, 노드가 죽는 경우 컨테이너들을 교체하기 위해 다시 스케줄링</li>
      <li>사용자가 정의한 상태 체크에 응답하지 않는 컨테이너들 종료</li>
      <li>서비스를 제공할 준비가 완료될 때까지 해당 컨테이너를 클라이언트에 알리지 않음</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="3-간단-용어">3. 간단 용어</h2>

<ul>
  <li>Cluster
    <ul>
      <li>Node라고 불리는 머신들의 집합</li>
      <li>K8s가 관리하는 컨테이너화된 애플리케이션들을 기동</li>
    </ul>
  </li>
  <li>Deployment
    <ul>
      <li>복제된 애플리케이션을 관리하는 API 객체</li>
      <li>각 레플리카는 각각 하나의 pod로 대표되며, 지정된 레플리카 수만큼 pod 수를 생성 및 유지</li>
    </ul>
  </li>
  <li>ReplicaSet
    <ul>
      <li>특정 수의 pod replica들이 동시에 구동되도록 하는 객체</li>
    </ul>
  </li>
  <li>Node
    <ul>
      <li>K8s의 워커 머신</li>
      <li>pod를 구동하기 위해 필요한 서비스들을 가지며, master 컴포넌트에 의해 관리됨</li>
    </ul>
  </li>
  <li>Pod
    <ul>
      <li>K8s의 최소 단위 객체</li>
      <li>클러스터 상에서 동작하는 컨테이너 집합</li>
    </ul>
  </li>
  <li>Service
    <ul>
      <li>pod 집합과 같은 애플리케이션들에 접근하는 방법을 기술하는 API객체</li>
    </ul>
  </li>
  <li>Namespace
    <ul>
      <li>동일한 물리 클러스터에서 여러 가상 클러스터를 지원하기 위해 K8s가 사용하는 추상화 기법</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="4-k8s-architecture">4. K8s Architecture</h2>

<p><img width="387" alt="스크린샷 2023-09-22 오후 6 26 30" src="https://github.com/bokyung124/infra-study/assets/53086873/c6a3828f-0d28-4263-9b10-479fbf2a5d62" /></p>

<h3 id="1-api-component">1) API component</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">kubectl</code> 명령으로 요청 받음</li>
  <li>요청에 대한 문법, 권한 등이 합당한지 검사</li>
  <li>합당하면 실행을 위해 문법에 맞춰 여러 컴포넌트들과 유기적으로 실행</li>
</ul>

<h3 id="2-etcd-저장소">2) ETCD 저장소</h3>

<ul>
  <li>key:value 타입으로 워커 노드들에 대한 상태 정보 저장</li>
  <li>HW 리소스를 어떤식으로 사용중인지, 도커 컨테이너의 상태, 다운받은 image의 상태 등</li>
  <li>워커노드 내 kubelet에 수집된 정보들 저장
    <ul>
      <li>kubelet 안에 cAdvisor라는 컨테이너 모델링 툴이 포함되어 있음</li>
      <li>현재 워커노드의 컨테이너 기반의 상태 정보 + HW 정보 수집</li>
    </ul>
  </li>
  <li>kubectl 명령이 어떻게 실행중인지 쿠버네티스 상태 정보도 포함함</li>
</ul>

<h3 id="3-스케줄러">3) 스케줄러</h3>

<ul>
  <li>API는 etcd의 정보를 받아서 스케줄러에게 보냄</li>
  <li>어떤 노드에 컨테이너를 실행하는 것이 가장 합당할지 물어봄</li>
  <li>스케줄러는 etcd 정보를 바탕으로 컨테이너를 실행할 노드를 정해서 API에게 응답함</li>
  <li>API는 응답받은 정보로 해당 노드의 kubelet에 접속 -&gt; 요청 (kubectl 명령 실행 요청)</li>
</ul>

<h3 id="4-kubelet">4) kubelet</h3>

<ul>
  <li>docker에게 docker 명령어로 kubectl 명령 실행 요청</li>
  <li>ex) nginx 실행 요청</li>
</ul>

<h3 id="5-docker">5) docker</h3>

<ul>
  <li>docker 플랫폼에서 hub에 있는 nginx 중 우리가 원하는 버전이 있는지 확인 후 받아서 실행</li>
</ul>

<h3 id="6-controller">6) controller</h3>

<ul>
  <li>명령에 따라 컨테이너 개수 보장</li>
  <li>의도한 상태에 가깝게 유지하는 역할</li>
  <li>컨트롤러는 컨테이너 1개가 동작 중인지 계속 확인 -&gt; nginx 동작 중인 노드 다운</li>
  <li>다른 노드에 nginx를 실행할 수 있도록 스케줄러를 통해 정보를 얻어 가능한 곳에 다시 nginx 동작</li>
</ul>

<p><br /></p>

<h2 id="5-k8s-container-working-flow">5. K8s Container Working Flow</h2>

<p><img width="555" alt="스크린샷 2023-09-22 오후 6 33 45" src="https://github.com/bokyung124/infra-study/assets/53086873/e3dd2a0e-15b1-4f92-98c2-d522cf33c7ca" /></p>

<p>1) 여러 컨테이너 빌드 (main UI 생성, 로그인, 상품 주문 등)    <br />
2) <strong>도커 명령</strong> -&gt; 도커 허브에 push  <br />
3) <strong>쿠버네티스 명령</strong> -&gt; 컨테이너 실행</p>
<ul>
  <li>yaml</li>
  <li>CLI</li>
  <li><code class="language-plaintext highlighter-rouge">kubectl create deploy web \ --image=hub.example.com/nginx</code>  <br />
4) <strong>kubectl 명령</strong> -&gt; master node에게 전달  <br />
5) <strong>master node</strong>의 API가 kubectl 명령어 요청 받음 <br />
6) <strong>API</strong>: 요청에 따라 컨테이너를 어느 노드에 배치할지 스케줄러에게 요청  <br />
7) <strong>스케줄러</strong>: 노드들의 상태를 보고 컨테이너를 실행한 노드를 선택하여 응답  <br />
8) <strong>API</strong>: 해당 노드의 kubelet에게 명령어 실행 요청 보냄  <br />
9) <strong>해당 노드의 kubelet</strong>: 해당 요청을 docker 명령어로 바꿔서 도커 데몬에게 실제 컨테이너 실행 요청   <br />
10) <strong>도커 데몬</strong>: 명령어에 정의되어 있는 허브에 해당 컨테이너가 있는지 검색, 있으면 받아와서 노드에 컨테이너로 실행   <br />
11) <strong>쿠버네티스</strong>: 이렇게 동작하는 컨테이너를 pod 라는 단위로 관리</li>
</ul>

<p><br /></p>

<h2 id="6-node">6. Node</h2>

<p><img width="509" alt="스크린샷 2023-09-22 오후 8 04 40" src="https://github.com/bokyung124/infra-study/assets/53086873/ea8710c8-01f5-479c-ae56-aba2c5e770e4" /></p>

<ul>
  <li>컨테이너를 pod 내에 배치하고 노드에서 실행함으로써 워크로드 구동</li>
  <li>클러스터를 따라 가상머신 또는 물리적인 머신일 수 있음</li>
  <li>
    <p>각 노드는 컨트롤플레인에 의해 관리되며, pod를 실행하는 데 필요한 서비스 제공</p>
  </li>
  <li>컴포넌트
    <ul>
      <li>kubelet: pod에서 컨테이너가 확실하게 동작하도록 관리</li>
      <li>컨테이너 런타임: 컨테이너 실행을 담당하는 소프트웨어</li>
      <li>kube-proxy: 각 노드에서 실행되는 네트워크 프록시</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">kubectl describe node &lt;node name&gt;</code>
    <ul>
      <li>주소, 컨디션, 용량과 할당 가능 정보</li>
    </ul>
  </li>
  <li>하트비트
    <ul>
      <li>클러스터가 개별 노드가 사용 가능한지 판단할 수 있도록 도움</li>
      <li>장애가 발견된 경우 조치할 수 있게 함</li>
      <li>kubelt이 <code class="language-plaintext highlighter-rouge">.status</code> 생성과 업데이트 &amp; 관련된 lease의 업데이트 담당</li>
    </ul>
  </li>
  <li>컨트롤러
    <ul>
      <li>등록 시점에 노드에 CIDR 블럭 할당</li>
      <li>컨트롤러의 내부 노드 리스트를 최신 상태로 유지</li>
      <li>노드의 동작 상태 모니터링 (.satus 필드의 컨디션 업데이트)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="7-lease">7. Lease</h2>

<ul>
  <li>분산 시스템에서 공유 리소스를 잠그고, 노드 간의 활동을 조정하는 메커니즘 제공</li>
  <li><code class="language-plaintext highlighter-rouge">coordination.k8s.io</code> API 그룹에 있는 <code class="language-plaintext highlighter-rouge">Lease</code> 오브젝트로 표현</li>
  <li>
    <p>각 노드는 연관된 리스 오브젝트를 가짐</p>
  </li>
  <li>하트비트
    <ul>
      <li>리스 API를 통해 kubelet 노드의 하트비트를 쿠버네티스 API 서버에 전달</li>
      <li>모든 kubelet 하트비트는 이 Lease 오브젝트에 대한 업데이트 요청</li>
      <li>이 요청은 해당 오브젝트의 <code class="language-plaintext highlighter-rouge">spec.renewTime</code> 필드 업데이트</li>
      <li>컨트롤 플레인: 이 필드의 타임스탬프를 통해 해당 노드의 가용성 확인</li>
    </ul>
  </li>
  <li>리더 선출
    <ul>
      <li>특정 시간 동안 컴포넌트의 인스턴스 하나만 실행되도록 보장</li>
      <li>컨트롤러, 스케줄러와 같은 컨트롤 플레인 컴포넌트의 고가용성 설정에서 사용됨</li>
      <li>한 인스턴스만 활성 상태로 실행되고, 다른 인스턴스는 대기 상태여야 함</li>
    </ul>
  </li>
  <li>API 서버 신원
    <ul>
      <li>클라이언트가 쿠버네티스 컨트롤 플레인을 운영중인 kube-apiserver 인스턴스 수를 파악할 수 있는 메커니즘 제공</li>
      <li>더 이상 존재하지 않는 kube-apiserver의 만료된 임대는 정해진 시간 후에 새로운 kube-apiserver에 의해 가비지컬렉션 됨</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="8-pod">8. Pod</h2>

<ul>
  <li>쿠버네티스에서 생성하고 관리할 수 있는 배포 가능한 가장 작은 컴퓨팅 단위</li>
  <li>컨테이너를 실행하기 위한 환경으로, 하나 이상의 컨테이너 그룹으로 구성</li>
  <li>스토리지 및 네트워크 공유, 해당 컨테이너 구동 방식에 대한 명세</li>
  <li>일반적으로 pod는 직접 생성하지는 않으며, 워크로드 리소스를 사용하여 생성</li>
</ul>

<p>ex) nginx:1.14.2 이미지를 실행하는 컨테이너로 구성되는 pod의 예시</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
<span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="na">spec</span><span class="pi">:</span>
    <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span>  <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
       <span class="na">image</span><span class="pi">:</span> <span class="s">nginx:1.14.2</span>
       <span class="na">ports</span><span class="pi">:</span>
       <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> https://k8s.io/examples/pods/simple-pod.yaml
</code></pre></div></div>

<h3 id="replication">Replication</h3>

<ul>
  <li>각 pod는 특정 애플리케이션의 단일 인스턴스를 실행하기 위한 것</li>
  <li>더 많은 인스턴스를 실행하여 리소스를 제공하기 위해 애플리케이션을 수평적으로 확장하려면
    <ul>
      <li>각 인스턴스를 하나씩, 여러 pod를 사용해야 함</li>
      <li>이 과정을 replication이라고 함</li>
    </ul>
  </li>
  <li>복제된 pod는 일반적으로 워크로드 리소스와 컨트롤러에 의해 그룹으로 생성되고 관리됨</li>
</ul>

<h3 id="podtemplate">PodTemplate</h3>

<ul>
  <li>워크로드 리소스의 컨트롤러가 pod를 생성하기 위한 명세</li>
  <li>pod template을 변경하는 경우, 대체 pod를 생성해야 함 (컨트롤러가)</li>
  <li>kubelet은 pod tempelate과 업데이트에 대한 정보를 직접 관리하지 않음
    <ul>
      <li>상세 내용은 추상화됨</li>
      <li>시스템 시맨틱 단순화 &amp; 코드 변경 없이 클러스터 동작 확장</li>
    </ul>
  </li>
</ul>

<p>ex) 컨테이너는 메시지를 출력한 다음 일시 중지</p>
<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">batch/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Job</span>
<span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">hello</span>
<span class="na">spec</span><span class="pi">:</span>
    <span class="na">template</span><span class="pi">:</span>
    <span class="c1"># 여기서부터 파드 템플릿</span>
    <span class="na">spec</span><span class="pi">:</span>
        <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span>  <span class="na">name</span><span class="pi">:</span> <span class="s">hello</span>
           <span class="na">image</span><span class="pi">:</span> <span class="s">busybox:1.28</span>
           <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">sh'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">-c'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">echo</span><span class="nv"> </span><span class="s">"Hello,</span><span class="nv"> </span><span class="s">Kubernetes!"</span><span class="nv"> </span><span class="s">&amp;&amp;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">3600'</span><span class="pi">]</span>
        <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">OnFailure</span>
    <span class="c1"># 여기까지 파드 템플릿</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="9-workloads">9. Workloads</h2>

<ul>
  <li>쿠버네티스에서 구동되는 애플리케이션 - 일련의 pod 집합 내에서 실행</li>
  <li>pod의 라이프사이클
    <ul>
      <li>클러스터에서 실행</li>
      <li>동작 중인 노드에서 심각한 오류가 발생하면 해당 노드의 모든 pod가 실패 = final</li>
      <li>사용자는 향후 노드의 복구와 상관없이 pod를 새로 생성해야 함</li>
    </ul>
  </li>
  <li>pod를 직접 관리할 필요없이, pod 집합을 관리하는 워크로드 리소스를 사용할 수 있음
    <ul>
      <li>올바른 수의 올바른 pod 유형이 실행되고 있는지 확인하는 컨트롤러 구성</li>
    </ul>
  </li>
  <li>built-in 워크로드 리소스
    <ul>
      <li><strong>Deployment 및 ReplicaSet</strong>: 클러스터의 stateless 애플리케이션 워크로드 관리에 적합</li>
      <li><strong>StatefulSet</strong>: 어떻게든 상태를 추적하는 하나 이상의 pod를 동작하게 해줌</li>
      <li><strong>DemonSet</strong>: 노드-로컬 기능을 제공하는 pod 정의 (네트워킹 지원 도구 / add-on 등)</li>
      <li><strong>Job 및 CronJob</strong>: 실행 완료 후 중단되는 작업 정의</li>
      <li>추가적인 제 3자의 워크로드 리소스도 추가할 수 있음</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="replicaset">ReplicaSet</h3>
<ul>
  <li>Replica pod 집합의 실행을 항상 안정적으로 유지하는 것</li>
  <li>보통 명시된 동일 pod 개수에 대한 가용성을 보증하는데 사용</li>
  <li>작동 방식
    <ul>
      <li>정의하는 필드
        <ul>
          <li>selector: 획득 가능한 pod를 식별하는 방법</li>
          <li>replicas: 유지해야 하는 pod 개수</li>
          <li>podTemplate: 레플리카 수 유지를 위해 생성하는 신규 pod에 대한 데이터 명시</li>
        </ul>
      </li>
      <li>필드에 지정된 설정을 충족하기 위해 pod 생성 및 삭제</li>
      <li>새로운 pod 생성할 경우, 명시된 podTemplate 사용</li>
    </ul>
  </li>
  <li>사용 시기
    <ul>
      <li>지정된 수의 pod 레플리카가 항상 실행되도록 보장</li>
      <li>별도의 사용자 정의 업데이트 오케스트레이션이 필요한 경우 / 업데이트가 전혀 필요없는 경우가 아니라면</li>
      <li>ReplicaSet을 직접 사용하기보다는 Deployment를 사용하는 것을 권장
        <ul>
          <li>ReplicaSet 오브젝트를 직접 조작할 필요 없음</li>
          <li>배포 작업 세분화하여 조작 가능</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>ex) controllers/frontend.yaml
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ReplicaSet</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">frontend</span>
  <span class="na">labels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">guestbook</span>
      <span class="na">tier</span><span class="pi">:</span> <span class="s">frontend</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="c1"># 케이스에 따라 레플리카 수정</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
      <span class="na">matchLabels</span><span class="pi">:</span>
          <span class="na">tier</span><span class="pi">:</span> <span class="s">frontend</span>
  <span class="na">template</span><span class="pi">:</span>
      <span class="na">metadata</span><span class="pi">:</span>
          <span class="na">labels</span><span class="pi">:</span>
              <span class="na">tier</span><span class="pi">:</span> <span class="s">frontend</span>
      <span class="na">spec</span><span class="pi">:</span>
          <span class="na">containers</span><span class="pi">:</span>
          <span class="pi">-</span>  <span class="na">name</span><span class="pi">:</span> <span class="s">php-redis</span>
             <span class="na">image</span><span class="pi">:</span> <span class="s">gcr.io/google_samples/gb-frontend:v3</span>
</code></pre></div>    </div>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> https://kubernetes.io/examples/controllers/frontend.yaml
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<h3 id="deployment">Deployment</h3>

<ul>
  <li>ReplicaSet의 상위 개념</li>
  <li>pod와 ReplicaSet에 대한 선언적 업데이트 제공</li>
  <li>Deployment는 ‘의도하는 상태’를 설명</li>
  <li>Deployment 컨트롤러는 ‘현재 상태’에서 ‘의도하는 상태’로 비율을 조정하며 변경</li>
  <li>Use Case
    <ul>
      <li>ReplicaSet 롤아웃 할 Deployment 생성</li>
      <li>pod의 새로운 상태 선언 (PodTemplateSpec 업데이트)</li>
      <li>Deployment 이전 버전으로 롤백</li>
      <li>Deployment 스케일 업</li>
      <li>Deployment 롤아웃, 상태 관리</li>
      <li>이전 ReplicaSet 정리</li>
    </ul>
  </li>
  <li>ex) 3개의 nginx pod를 불러오기 위한 ReplicaSet
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">nginx-deployment</span>
  <span class="na">labels</span><span class="pi">:</span>
      <span class="na">apps</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
      <span class="na">matchLabels</span><span class="pi">:</span>
          <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">template</span><span class="pi">:</span>
      <span class="na">metadata</span><span class="pi">:</span>
          <span class="na">labels</span><span class="pi">:</span>
              <span class="na">apps</span><span class="pi">:</span> <span class="s">nginx</span>
      <span class="na">spec</span><span class="pi">:</span>
          <span class="na">containers</span><span class="pi">:</span>
          <span class="pi">-</span>  <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
             <span class="na">image</span><span class="pi">:</span> <span class="s">nginx:1.14.2</span>
             <span class="na">ports</span><span class="pi">:</span>
             <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>
</code></pre></div>    </div>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply <span class="nt">-f</span> https://k8s.io/examples/controllers/nginx-deployment.yaml
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<h3 id="statefulset">StatefulSet</h3>

<ul>
  <li>애플리케이션의 상태 관리</li>
  <li>pod 집합의 Deployment와 스케일링 관리, <strong>pod들의 순서 및 고유성 보장</strong></li>
  <li>동일한 컨테이너 스펙을 기반으로 둔 pod들 관리, 각 pod의 독자성 유지</li>
  <li>다음 중 하나 이상이 필요한 애플리케이션에 유용
    <ul>
      <li>안정된, 고유한 네트워크 식별자</li>
      <li>안정된, 지속성을 갖는 스토리지</li>
      <li>순차적인, 정상 배포와 스케일링</li>
      <li>순차적인, 자동 롤링 업데이트</li>
    </ul>
  </li>
  <li><strong>pod마다 다른 스토리지를 사용해 각각 다른 상태를 유지하기 위해 사용</strong></li>
  <li>k8s의 ms 구조로 동작하는 애플리케이션은 대부분 stateless: deployment, replicaSet
    <ul>
      <li>모두 같은 volume으로 같은 상태를 가질 수 밖에 없음</li>
      <li>DB처럼 상태를 갖는(stateful) 애플리케이션으로 k8s를 실행하는 것은 매우 복잡</li>
      <li>완벽하진 않지만 이에 대한 해결책으로 statefulSet 오브젝트 제공</li>
    </ul>
  </li>
  <li>문제가 생긴 pod와 같은 이름, 같은 IP를 가진 pod로 교체</li>
</ul>

<p><img width="754" alt="스크린샷 2023-09-22 오후 9 29 37" src="https://github.com/bokyung124/infra-study/assets/53086873/4d628f80-38b2-4a06-9bc5-772508285fbc" /></p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
    <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="na">spec</span><span class="pi">:</span>
    <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="m">80</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">web</span> 
    <span class="na">clusterIP</span><span class="pi">:</span> <span class="s">None</span>
    <span class="na">seelctor</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">StatefulSet</span>
<span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">web</span>
<span class="na">spec</span><span class="pi">:</span>
    <span class="na">selector</span><span class="pi">:</span>
        <span class="na">matchLabels</span><span class="pi">:</span>
            <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>  <span class="c1"># .spec.template.metadata.labels 와 일치해야 함</span>
    <span class="na">serviceName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">nginx"</span>
    <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>  <span class="c1"># 기본값은 1</span>
    <span class="na">minReadySeconds</span><span class="pi">:</span> <span class="m">10</span>   <span class="c1"># 기본값은 0</span>
    <span class="na">template</span><span class="pi">:</span>
        <span class="na">metadata</span><span class="pi">:</span>
            <span class="na">labels</span><span class="pi">:</span>
                <span class="na">app</span><span class="pi">:</span> <span class="s">nginx</span>  <span class="c1"># .spec.selector.matchLables와 일치해야 함</span>
        <span class="na">spec</span><span class="pi">:</span>
            <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">10</span>
            <span class="na">containers</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">nginx</span>
              <span class="na">image</span><span class="pi">:</span> <span class="s">registry.k8s.io/nginx-slim:0.8</span>
              <span class="na">ports</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">80</span>
                <span class="na">name</span><span class="pi">:</span> <span class="s">web</span>
              <span class="na">volumnMounts</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">www</span>
                <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/usr/share/nginx/html</span>
    <span class="na">volumnClaimTemplates</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">metadata</span><span class="pi">:</span>
        <span class="na">name</span><span class="pi">:</span> <span class="s">www</span>
    <span class="na">spec</span><span class="pi">:</span>
        <span class="na">accessModes</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">ReadWriteOnce"</span><span class="pi">]</span>
        <span class="na">storageClassName</span><span class="pi">:</span> <span class="s2">"</span><span class="s">my-storage-class"</span>
        <span class="na">resources</span><span class="pi">:</span>
            <span class="na">requests</span><span class="pi">:</span>
                <span class="na">storage</span><span class="pi">:</span> <span class="s">1Gi</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="demonset">DemonSet</h3>

<ul>
  <li><strong>클러스터 전체에서 pod를 띄울 때 사용</strong></li>
  <li>모든 / 일부 노드가 pod의 사본을 실행하도록 함</li>
  <li>노드가 클러스터에 추가되면 pod도 추가됨</li>
  <li>노드가 클러스터에서 제거되면 해당 pod는 가비지로 수집됨</li>
  <li>
    <p>데몬셋을 삭제하면 데몬셋이 생성한 pod들이 정리됨</p>
  </li>
  <li>용도
    <ul>
      <li>모든 노드에서 클러스터 스토리지 데몬 실행</li>
      <li>모든 노드에서 로그 수집 데몬 실행</li>
      <li>모든 노드에서 노드 모니터링 데몬 실행</li>
    </ul>
  </li>
  <li>Deployment와 유사하게 pod 생성하고 관리
    <ul>
      <li>Deployment: 배포 작업 세분화</li>
      <li>DemonSet: 특정 노드 또는 모든 노드에 실행되어야 할 특정 pod 관리
        <ul>
          <li>새로 노드가 추가될 때 자동으로 그 노드에 데몬셋 pod 실행됨</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>데몬셋 pod와 통신
    <ul>
      <li>push, 노드IP와 포트, DNS, Service</li>
    </ul>
  </li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">DaemonSet</span>
<span class="na">metadata</span><span class="pi">:</span> 
    <span class="na">name</span><span class="pi">:</span> <span class="s">fluentd-elasticsearch</span>
    <span class="na">namespace</span><span class="pi">:</span> <span class="s">kube-system</span>
    <span class="na">labels</span><span class="pi">:</span>
        <span class="na">k8s-app</span><span class="pi">:</span> <span class="s">fluentd-logging</span>
<span class="na">spec</span><span class="pi">:</span>
    <span class="na">selector</span><span class="pi">:</span>
        <span class="na">matchLabels</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">fluentd-elasticsearch</span>
    <span class="na">template</span><span class="pi">:</span>
        <span class="na">metadata</span><span class="pi">:</span>
            <span class="na">labels</span><span class="pi">:</span>
                <span class="na">name</span><span class="pi">:</span> <span class="s">fluentd-elasticsearch</span>
        <span class="na">spec</span><span class="pi">:</span>
            <span class="na">tolerations</span><span class="pi">:</span>
            <span class="c1"># 이 톨러레이션은 데몬셋이 컨트롤 플레인 노드에서 실행될 수 있도록 만듦</span>
            <span class="c1"># 컨트롤 플레인 노드가 이 파드를 실행해서는 안되는 경우, 이 톨러레이션을 제거함</span>
            <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">node-role.kubernetes.io/control-plane</span>
              <span class="na">operator</span><span class="pi">:</span> <span class="s">Exists</span>
              <span class="na">effect</span><span class="pi">:</span> <span class="s">NoSchedule</span>
            <span class="pi">-</span> <span class="na">key</span><span class="pi">:</span> <span class="s">node-role.kubernetes.io/master</span>
              <span class="na">operator</span><span class="pi">:</span> <span class="s">Exists</span>
              <span class="na">effect</span><span class="pi">:</span> <span class="s">NoSchedule</span>
            <span class="na">containers</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">fluentd-elasticsearch</span>
              <span class="na">image</span><span class="pi">:</span> <span class="s">quay.io/fluentd_elasticsearch/fluentd:v2.5.2</span>
              <span class="na">resources</span><span class="pi">:</span>
                <span class="na">limits</span><span class="pi">:</span>
                    <span class="na">memory</span><span class="pi">:</span> <span class="s">200Mi</span>
                <span class="na">requests</span><span class="pi">:</span>
                    <span class="na">cpu</span><span class="pi">:</span> <span class="s">100m</span>
                    <span class="na">memory</span><span class="pi">:</span> <span class="s">200Mi</span>
              <span class="na">volumeMounts</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">varlog</span>
                <span class="na">mountPath</span><span class="pi">:</span> <span class="s">/var/log</span>
            <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">30</span>
            <span class="na">volumes</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">varlog</span>
              <span class="na">hostPath</span><span class="pi">:</span>
                <span class="na">path</span><span class="pi">:</span> <span class="s">/var/log</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="job">Job</h3>

<ul>
  <li>job에서 하나 이상의 pod를 생성하고, 지정된 수의 pod가 성공적으로 종료될 때까지 계속해서 pod의 실행 재시도</li>
  <li>pod가 성공적으로 완료되면, 성공적으로 완료된 job 추적</li>
  <li>지정된 수의 성공 완료에 도달하면 job 완료됨</li>
  <li>job 삭제하면 job이 생성한 pod 정리됨, 일시중지하면 다시 재개될 때까지 활성 pod가 삭제됨</li>
  <li>용도
    <ul>
      <li>백업이나 특정 배치 파일들처럼 한 번 실행하고 종료되는 작업</li>
      <li>여러 pod를 병렬을 실행할 수 있음</li>
    </ul>
  </li>
  <li>ex) 파이의 2000자리까지 계산해서 출력
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">batch/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Job</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">pi</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">template</span><span class="pi">:</span>
      <span class="na">spec</span><span class="pi">:</span>
          <span class="na">containers</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pi</span>
            <span class="na">image</span><span class="pi">:</span> <span class="s">perl:5.34.0</span>
            <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">perl"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-Mbigum=bpi"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-wle"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">print</span><span class="nv"> </span><span class="s">bpi(2000)"</span><span class="pi">]</span>
          <span class="na">restartPolicy</span><span class="pi">:</span> <span class="s">Never</span>
  <span class="na">backoffLimit</span><span class="pi">:</span> <span class="m">4</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<h2 id="10-service">10. Service</h2>

<h3 id="쿠버네티스-네트워크-모델">쿠버네티스 네트워크 모델</h3>

<ul>
  <li>클러스터의 모든 pod는 고유한 IP 주소 가짐</li>
  <li>pod 간 연결을 명시적으로 만들 필요 X, 컨테이너 포트를 호스트 포트에 매핑할 필요 거의 없음</li>
  <li>포트 할당, 네이밍, 서비스 디스커버리, 로드 밸런싱, 애플리케이션 구성, 마이그레이션 관점에서 pod를 VM / 물리 호스트처럼</li>
  <li>쿠버네티스 IP 주소는 pod 범주 내에 존재하며, pod 내의 컨테이너들은 IP 주소, MAC 주소를 포함하는 네트워크 네임스페이스 공유
    <ul>
      <li>pod 내의 컨테이너들이 각자의 포트에 <code class="language-plaintext highlighter-rouge">localhost</code>로 접근할 수 있음을 의미</li>
    </ul>
  </li>
</ul>

<h3 id="쿠버네티스-네트워킹-특징">쿠버네티스 네트워킹 특징</h3>

<ul>
  <li>pod 내의 컨테이너는 loopback 을 통한 네트워킹을 사용하여 통신</li>
  <li>클러스터 네트워킹은 서로 다른 pod 간의 통신 제공</li>
  <li>서비스 API를 사용하면 pod에서 실행 중인 애플리케이션을 클러스터 외부에서 접근할 수 있음</li>
  <li>서비스를 사용하여 서비스를 클러스터 내부에서만 사용할 수 있도록 게시할 수 있음</li>
</ul>

<h3 id="서비스">서비스</h3>

<ul>
  <li>pod 집합에서 실행 중인 애플리케이션을 네트워크 서비스로 노출하는 추상화 방법</li>
  <li>pod의 논리적 집합, 어떻게 접근할지에 대한 정책을 정의해놓은 것</li>
  <li>익숙하지 않은 서비스 디스커버리 메커니즘을 사용하기 위해 애플리케이션을 수정할 필요 없음</li>
  <li>원래 각 pod의 IP로는 외부에서 직접적인 접근이 불가능하지만, 서비스는 이를 가능하게 해줌</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">label selector</code>를 통해 어떤 pod를 포함할지 정의할 수 있음</p>
  </li>
  <li>용도
    <ul>
      <li>pod에 고유 IP 주소 부여</li>
      <li>pod 집합에 대한 단일 DNS명 부여</li>
      <li>여러 pod 묶어서 로드밸런싱</li>
    </ul>
  </li>
  <li>유형
    <ul>
      <li>ClusterIP (default): pod들이 <strong>클러스터 내부</strong>의 다른 리소스들과 통신할 수 있도록 하는 가상의 클러스터 전용 IP</li>
      <li>NodePort: 외부에서 노드 IP의 특정 포트로 들어오는 요청 감지, <strong>모든 노드</strong>의 IP와 포트로 접근 가능하게 됨</li>
      <li>LoadBalancer: 보통 클라우드 벤더에서 제공하는 설정 방식, 외부 IP를 가지고 있는 <strong>로드밸런서</strong> 할당</li>
      <li>ExternalName: selector 대신 DNS명을 직접 명시하고자 할 때 사용</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="11-add-on-program">11. Add-on Program</h2>

<h3 id="add-on">Add-on</h3>
<ul>
  <li>마스터노드, 워커노드 외에 클러스터 내부에서 필요한 기능들을 위해 실행되는 pod</li>
  <li>쿠버네티스 클러스터에서 기능 구현 및 확장하는 역할</li>
  <li>pod는 deployment, replication controller 등에 의해 관리됨</li>
  <li>외부 연동 라이브러리라고 생각하면 됨</li>
</ul>

<h3 id="dns-addon">DNS Addon</h3>
<ul>
  <li>클러스터 내에서 작동하는 DNS Server로, 필수적인 애드온!</li>
  <li>쿠버네티스 서비스 객체에게 DNS 레코드를 제공하는 역할</li>
  <li>쿠버네티스 내부에서 실행된 컨테이너들은 자동으로 DNS 서버에 등록되어 자동 탐색 가능</li>
  <li>DNS Server
    <ul>
      <li>사람이 읽을 수 있는 도메인 이름을 IP 주소로 변환할 수 있게 해주는 인터넷의 핵심 구성 요소</li>
      <li>pod 간 통신을 할 때 IP가 아닌 도메인을 설정해두고 사용할 수 있음</li>
      <li>한 클러스터에서 사용하던 YAML 파일에서 pod 간 통신을 도메인으로 설정해 둔다면, 그대로 다른 클러스터로 가져가서 사용 가능</li>
      <li>pod는 쉽게 생성하고 삭제할 수 있는 불안정한 자원 -&gt; IP로 서비스 호출하면 바뀐 IP 계속 추적해야 함</li>
    </ul>
  </li>
</ul>

<h3 id="네트워킹-addon-cno--container-network-interface">네트워킹 Addon (CNO) : Container Network Interface</h3>
<ul>
  <li>컨테이너 간의 네트워킹을 제어할 수 있는 플러그인을 만들기 위한 표준</li>
  <li>클러스터는 가상 네트워크가 구성되어 이쓴ㄴ데, 기본적으로는 kube-proxy가 네트워크 관리</li>
  <li>보다 효율적인 네트워크 환경 구성을 위해 다양한 네트워크 관련 Addon 제공됨</li>
</ul>

<h3 id="대시보드-addon">대시보드 Addon</h3>
<ul>
  <li>클러스터를 위한 웹 기반 UI</li>
  <li>일반적으로 클러스터에 명령을 내릴 때 사용하는 kubectl을 가시화하여 대시보드 제공</li>
  <li>관리의 편의성 향상</li>
</ul>

<h3 id="컨테이너-자원-모니터링-addon">컨테이너 자원 모니터링 Addon</h3>
<ul>
  <li>컨테이너의 CPU, 메모리와 같은 리소스 데이터를 저장하고 볼 수 있는 방법 제공</li>
  <li>워커노드의 kubelet에 포함된 cAdvisor도 이것의 한 종류</li>
</ul>

<h3 id="클러스터-로깅-addon">클러스터 로깅 Addon</h3>
<ul>
  <li>클러스터 내부에서 생성되는 모든 로그를 중앙화하여 관리할 수 있음</li>
  <li>클라우드 서비스가 아닌 직접 쿠버네티스를 설치한 경우에 사용 (클라우드 - 클라우드 벤더에서 로깅 서비스 제공)</li>
</ul>

<p><br /></p>

<h2 id="12-namespace">12. Namespace</h2>

<p><img width="612" alt="스크린샷 2023-09-22 오후 11 18 13" src="https://github.com/bokyung124/infra-study/assets/53086873/3ec729b9-bc38-4792-8487-5de37a913a6c" /></p>

<ul>
  <li>k8s API 중 하나</li>
  <li>단일 클러스터 내에서의 리소스 그룹 격리 메커니즘을 제공</li>
  <li>클러스터 한 개를 <strong>여러 개의 논리적인 단위로 나눠서 사용</strong></li>
  <li>클러스터 한 개를 여러 팀이나 사용자가 함께 공유 / 용도에 따라 실행해야 하는 앱을 구분할 때 사용</li>
  <li>여러 파트너 사를 운영하는 통합 솔루션 / 여러 버전을 가지고 개발에서 운영까지 하는 과정 등에 필요</li>
  <li>
    <p>실제 API는 하나인데, API가 여러 개인 것처럼 사용할 수 있음</p>
  </li>
  <li>ex) product, beta test, develop 버전</li>
  <li>
    <p>ex) 롯데 이커머스 - 홈쇼핑, 백화점, 면세점</p>
  </li>
  <li>장점
    <ul>
      <li>위의 경우, 홈쇼핑에서 동작중인 pod, service, volume 등만 따로 모아서 보고 관리할 수 있음</li>
      <li>수만은 pod 중 특정 namespace 것만 따로 보아서 한눈에 파악, 관리하기 좋음</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="default-namespace">Default Namespace</h3>

<ul>
  <li>default
    <ul>
      <li>처음에 포함되어 있는 네임스페이스로, 네임스페이스를 생성하지 않고도 새 클러스터를 사용할 수 있음</li>
    </ul>
  </li>
  <li>kube-node-lease
    <ul>
      <li>각 노드와 연관된 리스 오브젝트를 가짐</li>
      <li>노드 리스: kubelet이 하트비트를 보내서 control-plane이 노드의 장애를 탐지할 수 있게 함</li>
    </ul>
  </li>
  <li>kube-public
    <ul>
      <li>모든 클라이언트가 읽기 권한으로 접근할 수 있음</li>
      <li>주로 전체 클러스터 중 공개적으로 드러나서 읽을 수 있는 리소스를 위해 예약되어 있음</li>
    </ul>
  </li>
  <li>kube-system
    <ul>
      <li>쿠버네티스 시스템에서 생성한 오브젝트를 위한 네임스페이스</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="13-case-study">13. Case Study</h2>

<p>1) 인공지능 연구소 OpenAI</p>
<ul>
  <li>자체 데이터 센터에서 실험을 실행하고, 쉽게 확장할 수 있는 딥러닝을 위한 인프라 필요</li>
  <li>주로 배치 스케줄링 시스템으로 사용</li>
  <li>클러스터를 동적으로 확장하기 위해 오토스케일러에 의존</li>
  <li>낮은 대기 시간과 빠른 반복을 통해 유휴 노드의 비용 크게 줄일 수 있음</li>
  <li>일관된 API 제공 -&gt; 연구 실험을 클러스터 간 쉽게 이동할 수 있음</li>
  <li>자체 데이터 센터 사용 -&gt; 비용 절감, 클라우드에서 HW에 대한 액세스 제공</li>
  <li>분산 훈련 시스템 연구: 1-2주 만에 수 백개의 GPU로 확장하여 실행</li>
</ul>

<p><br /></p>

<p>2) 통신 네트워크 솔루션 회사 NOKIA</p>
<ul>
  <li>통신 네트워크를 종단간 구축하는 것</li>
  <li>여러 통신 사업자에게 소프트웨어 제공, 소프트웨어를 인프라에 넣어야 함
    <ul>
      <li>각 사업자는 다른 인프라 보유</li>
      <li>제품을 변경하지 않고 모든 다른 인프라에서 동일한 제품 실행하고자 함</li>
    </ul>
  </li>
  <li>k8s의 라벨 기반 스케줄링 -&gt; 아키텍처 확장, 안정적</li>
  <li>5G 진출을 가능하게 함</li>
  <li>인프라와 애플리케이션 계층 분리 -&gt; 시스템 의존성이 적으며, 애플리케이션 계층에서 기능 구현이 더 쉬워짐</li>
  <li>서로 다른 환경에서 동일한 테스트 여러 번 진행할 필요 없음 -&gt; 제품 출시 시간 절약</li>
</ul>]]></content><author><name>GitHub User</name></author><category term="Infra" /><summary type="html"><![CDATA[참고자료 https://www.youtube.com/watch?v=Iu9ТС13vPQ&amp;list=PLApuRIvrZKohaBHVXAOhUD-RxDOuQ3z0c&amp;index=8]]></summary></entry><entry><title type="html">[pilot] Ch5. 빅데이터 적재 이론 (2)</title><link href="http://localhost:4000/hadoop/2023/09/22/ch5.html" rel="alternate" type="text/html" title="[pilot] Ch5. 빅데이터 적재 이론 (2)" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T05:20:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/ch5</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/ch5.html"><![CDATA[<p>[출처: 실무로 배우는 빅데이터 기술, 김강원 저]</p>

<p><br /></p>

<h2 id="1-빅데이터-실시간-적재-개요">1. 빅데이터 실시간 적재 개요</h2>

<p><img src="img/CH05/1.jpg" alt="" /></p>

<ul>
  <li>앞장에 이어서 이번에는 스마트카 운전자의 실시간 운행 정보를 분석한 후 적재하는 영역 다룸</li>
  <li><strong>실시간 로그 분석</strong>에는 작지만 대량으로 발생하는 메시지성 데이터를 실시간으로 분석 처리하며, 해당 결과를 인메모리에 저장해 주변 시스템과 빠르게 공유함</li>
  <li>이때 대량의 메시지 데이터를 영구 저장하기 위해 하둡을 직접 이용하지는 않음</li>
  <li>유입된 작은 메시지 한 건을 바로 하둡에 저장할 경우 한 개의 HDFS 파일이 생성되는데, 초당 수천 건의 트랜잭션이 발생하는 메시지의 경우 파일 개수가 기하급수적으로 늘어나고, 이로 인해 하둡 클러스터에 지나친 오버헤드가 발생하기 때문</li>
  <li>중간에 메시지를 특정 크기로 모았다가 한번에 적재하거나, 대규모 트랜잭션 데이터를 처리하는 데 최적화된 칼럼 지향형 NoSQL DB 주로 이용</li>
</ul>

<p><br /></p>

<h2 id="2-hbase">2. HBASE</h2>
<h3 id="1-hbase-소개">1) HBASE 소개</h3>
<ul>
  <li>하둡 기반의 칼럼 지향 NoSQL 데이터베이스</li>
  <li>스키마 변경이 자유롭고, <code class="language-plaintext highlighter-rouge">리전</code>이라는 수십~수백 대의 분산 서버로 <strong>샤딩</strong>과 <strong>복제</strong>등의 기능을 지원해 성능과 안정성을 보장하는 특징을 가짐</li>
  <li>특히 하둡의 확장성과 내고장성을 그대로 이용할 수 있어 대규모 실시간 데이터 처리를 위한 스피트 레이어 저장소에 주로 사용됨</li>
</ul>

<p><br /></p>

<h3 id="2-주요-구성-요소">2) 주요 구성 요소</h3>

<table>
  <thead>
    <tr>
      <th>주요 구성 요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>HTable</td>
      <td>칼럼 기반 데이터 구조를 정의한 테이블 <br /> 공통점이 있는 칼럼들의 그룹을 묶은 **칼럼 패밀리**와 테이블의 로우를 식별해서 접근하기 위한 **로우키**로 구성</td>
    </tr>
    <tr>
      <td>HMaster</td>
      <td>HRegion 서버를 관리하며, HRegion들이 속한 HRegion 서버의 메타 정보 관리</td>
    </tr>
    <tr>
      <td>HRegion</td>
      <td>HTable의 크기에 따라 자동으로 수평 분할이 발생하고, 이때 분할된 블록을 HRegion 단위로 지정</td>
    </tr>
    <tr>
      <td>HRegionServer</td>
      <td>분산 노드별 HRegionServer가 구성되며, 하나의 HRegionServer에는 다수의 HRegion이 생성되어 HRegion 관리</td>
    </tr>
    <tr>
      <td>Store</td>
      <td>하나의 Store에는 칼럼 패밀리가 저장 및 관리되며, MemStore와 HFile로 구성됨</td>
    </tr>
    <tr>
      <td>MemStore</td>
      <td>Store 내의 데이터를 인메모리에 저장 및 관리하는 데이터 캐시 영역</td>
    </tr>
    <tr>
      <td>HFile</td>
      <td>Store 내의 데이터를 스토리지에 저장 및 관리하는 영구 저장 영역</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="3-hbase-아키텍처">3) HBase 아키텍처</h3>
<ul>
  <li>가장 큰 특징은 하둡의 <strong>HDFS</strong>를 기반으로 설치 및 구성된다는 것</li>
  <li>그로 인해 <strong>분산 데이터베이스 아키텍처</strong>를 채택하고 있으며,</li>
  <li>HDFS의 가용성과 확장성을 그대로 물려받음</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>클라이언트가 HBase에 데이터를 저장(put)하는 과정</strong>
<img src="img/CH05/2.png" alt="" /></li>
  <li>클라이언트가 HBase 테이블에 특정 데이터를 저장하기 전, 주키퍼를 통해 HTable의 기본 정보와 해당 HRegion의 위치 정보를 알아냄</li>
  <li>해당 정보를 기반으로 클라이언트가 직접 HRegionServer로 연결되어 HRegion의 Memory 영역인 MemStore에 데이터 저장</li>
  <li>이때 MemStore에 저장된 데이터는 특정 시점이 되면 HFile로 HDFS에 플러시(Flush)되고, HFile은 HRegion의 상황에 따라 최적의 HFile로 재구성되는 작업이 이루어짐</li>
  <li>이러한 플러시 과정들을 HBase에서는 <code class="language-plaintext highlighter-rouge">Minor/Major Compaction</code>이라고 함</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>HBase에서 특정 데이터를 가져오는 과정</strong></li>
  <li>주키퍼를 통해 로우키(RowKey)에 해당하는 데이터의 위치 정보를 알아냄</li>
  <li>해당 HRegionServer의 Memory 영역인 MemStore에서 데이터를 가져옴으로써 디스크 I/O를 최소화하면서 빠른 응답 속도 보장</li>
  <li>만일 데이터가 MemStore에서 플러시되어 존재하지 않으면 HFile 영역으로 이동해 데이터 찾게 되는데, 이때 HBase와 HDFS 사이의 모든 데이터 스트림 라인들은 항상 열려있으므로 레이턴시가 발생하지 않음  <br />
(레이턴시: 시간 지연, 하나의 데이터 패킷을 한 지점에서 다른 지점으로 보내는데 소요되는 시간)</li>
</ul>

<p><br /></p>

<h2 id="4-hbase-활용-방안">4) HBase 활용 방안</h2>
<p><img src="img/CH05/3.png" alt="" /></p>
<ul>
  <li>앞서 CH03에서 Flume을 이용해 수집한 스마트카 운전자의 운행 정보를 Kafka까지 전송했음</li>
  <li>이번 장에서는 Kafka에 저장되어 있는 데이터를 Storm이 받아서 HBase의 테이블에 모두 적재</li>
  <li>또한, HBase에 저장된 스마트카 운전자의 운행 정보를 특정 조건에 따라 필터링해서 신속하게 조회해 보고, 하이브 핸들러를 이용해 HBase에 저장된 데이터와 하이브 데이터를 동시에 활용해봄</li>
</ul>

<p><br /></p>

<h2 id="3-redis">3. Redis</h2>
<h3 id="1-레디스-소개">1) 레디스 소개</h3>
<ul>
  <li>분산 캐시 시스템이면서, NoSQL DB처럼 대규모 데이터 관리 능력도 갖춘 IMDG(In-Memory Data Grid) 소프트웨어</li>
  <li>키/값 형식의 데이터 구조를 분산 서버 상의 메모리에 저장하면서 고성능의 응답 속도 보장</li>
  <li>다양한 데이터 타입을 지원하기 때문에 데이터를 구조화해서 저장할 수 있어, 단순 키/값 이상의 데이터 복잡성도 처리할 수 있음</li>
  <li>인메모리 데이터를 영구적으로 저장할 수 있는 스냅샷 기능 제공</li>
  <li>데이터의 유실에 대비해 AOF(Append Only File) 기능으로 정합성 보장</li>
  <li>NoSQL의 특징인 데이터의 샤딩과 복제도 지원하여 높은 성능이 필요한 서비스에서 많이 사용됨</li>
</ul>

<p><br /></p>

<h3 id="2-주요-구성-요소-1">2) 주요 구성 요소</h3>

<table>
  <thead>
    <tr>
      <th>주요 구성 요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Master</td>
      <td>분산 노드 간의 데이터 복제와 Slave 서버의 관리를 위한 Master 서버</td>
    </tr>
    <tr>
      <td>Slave</td>
      <td>다수의 Slave 서버는 주로 읽기 요청을 처리하고, Master 서버는 쓰기 요청을 처리</td>
    </tr>
    <tr>
      <td>Sentinel</td>
      <td>레디스 3.x부터 지원하는 기능으로, Master 서버에 문제가 발생할 경우 새로운 Master를 선출하는 기능</td>
    </tr>
    <tr>
      <td>Replication</td>
      <td>Master 서버에 쓰인 내용을 Slave 서버로 복제해서 동기화 처리</td>
    </tr>
    <tr>
      <td>AOF / Snapshot</td>
      <td>데이터를 영구적으로 저장하는 기능으로, 명령어를 기록하는 AOF와 스냅샷 이미지 파일 방식 지원</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="3-레디스-아키텍처">3) 레디스 아키텍처</h3>
<ul>
  <li>3.x에서부터 HA 기능이 강화되면서 클러스터의 완성도가 높아짐</li>
  <li>요구사항과 데이터의 샤딩 및 복제 구성 방식에 따라 세가지 아키텍처 구성 가능</li>
</ul>

<p><br /></p>

<h4 id="1-레디스-아키텍처-1">1) 레디스 아키텍처 1</h4>
<p><img src="img/CH05/4.png" alt="" /></p>
<ul>
  <li>Single Master 형식</li>
  <li>개발과 테스트 환경에 주로 사용됨</li>
  <li>설치하기가 쉽고 단일 서버만으로도 빠른 응답 속도와 안정적인 기능을 제공함으로써 소규모이면서 중요도가 비교적 낮은 시스템 간의 데이터 공유에도 종종 사용됨</li>
</ul>

<p><br /></p>

<h4 id="2-레디스-아키텍처-2">2) 레디스 아키텍처 2</h4>
<p><img src="img/CH05/5.png" alt="" /></p>
<ul>
  <li>Single Master / Multi Slave 형식</li>
  <li>Master에 쓰여진 데이터는 복제를 통해 Slave 노드로 복제되면서 데이터 정합성 유지</li>
  <li>쓰기 / 읽기 노드를 분리해서 전체적인 성능을 향상시킨 구성</li>
  <li>Slave 2와 같이 읽기 노드를 추가해서 성능을 극대화할 수 있음</li>
</ul>

<p><br /></p>

<h4 id="3-레디스-아키텍처-3">3) 레디스 아키텍처 3</h4>
<p><img src="img/CH05/6.png" alt="" /></p>
<ul>
  <li>버전 3.x부터 지원되는 HA 클러스터링 구조</li>
  <li>아키텍처 2는 두가지 문제점이 있음
    <ul>
      <li>Master 서버 장애 발생 시 쓰기 요청이 실패하면서 데이터 유실이 발생할 수 있는 취약한 구조</li>
      <li>클라이언트가 쓰기 노드와 읽기 노드를 알고 있으야 하므로 클라이언트 프로그램에 복잡도 발생</li>
    </ul>
  </li>
  <li>이러한 문제점 극복을 위해 <code class="language-plaintext highlighter-rouge">Sentinel</code>이라는 노드 모니터링/제어 컴포넌트 추가</li>
  <li>Sentinel이 노드들을 모니터링하고 있다가, Master 서버에 문제가 발생하면 Slave 노드 중 하나를 Master 노드로 지정하고, 문제가 됐던 Master 노드와 연결을 끊으면서 HA 기능 제공</li>
</ul>

<p><br /></p>

<h3 id="4-레디스-활용-방안">4) 레디스 활용 방안</h3>
<p><img src="img/CH05/7.png" alt="" /></p>
<ul>
  <li>스마트카 운전자의 상태 정보를 실시간으로 분석</li>
  <li>분석한 결과를 빠르게 저장하면서 주변 시스템과 공유하기 위한 저장소로 레디스 활용</li>
  <li>위의 그림에서 Storm에서 두 개의 경로로 분리되는 것을 볼 수 있음
    <ul>
      <li>HBase에는 운전자의 모든 상태 정보를 저장</li>
      <li>레디스에는 운전자의 특정 패턴을 감지한 이벤트 결과(과속한 운전자 정보)만 저장</li>
    </ul>
  </li>
  <li>그러면 주변 응용 시스템에서 레디스에 적재된 정보를 빠르게 조회해서 활용하게 됨</li>
</ul>

<p><br /></p>

<h2 id="4-storm">4. Storm</h2>
<h3 id="1-스톰-소개">1) 스톰 소개</h3>
<ul>
  <li>스피드 데이터를 인메모리 상에서 병렬 처리하기 위한 소프트웨어</li>
  <li>스피드 데이터는 원천 시스템의 수많은 이벤트가 만들어내며, 작지만 대규모의 동시다발적이라는 특성이 있음</li>
  <li>이러한 스피드 데이터를 실시간으로 다루기 위해 모든 데이터를 인메모리 상에서 분산 병렬 처리하고, 분산 데이터를 통제하기 위한 강력한 기능(분리, 정제, 통합, 집계 등)과 아키텍처 제공</li>
</ul>

<p><br /></p>

<ul>
  <li>실시간 분산 처리 유형으로는 데이터 발생과 동시에 처리하는 <code class="language-plaintext highlighter-rouge">완전 실시간 방식</code>과, 발생한 데이터를 적재한 후 빠르게 배치를 실행하는 <code class="language-plaintext highlighter-rouge">마이크로 배치 방식</code>이 있음</li>
  <li>스톰은 전자에 해당하는 <strong>완전 실시간 방식</strong>으로, 조금의 레이턴시도 허용하지 않는 아키텍처에 적용</li>
</ul>

<p><br /></p>

<h3 id="2-주요-구성-요소-2">2) 주요 구성 요소</h3>

<table>
  <thead>
    <tr>
      <th>주요 구성 요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Spout</td>
      <td>외부로부터 데이터를 유입받아 가공처리해서 튜플을 생성, 이후 해당 튜플을 Bolt에 전송</td>
    </tr>
    <tr>
      <td>Bolt</td>
      <td>튜플을 받아 실제 분산 작업 수행 <br /> 필터링, 집계, 조인 등의 연산을 병렬로 실행</td>
    </tr>
    <tr>
      <td>Topology</td>
      <td>Spout-Bolt의 데이터 처리 흐름 정의 <br /> 하나의 Spout과 다수의 Bolt로 구성</td>
    </tr>
    <tr>
      <td>Nimbus</td>
      <td>Topology를 Supervisor에 배포하고 작업 할당 <br /> Supervisor를 모니터링하다 필요 시 페일오버(Fail-over) 처리</td>
    </tr>
    <tr>
      <td>Worker</td>
      <td>Supervisor 상에서 실행 중인 자바 프로세스로 Spout과 Bolt 실행</td>
    </tr>
    <tr>
      <td>Executor</td>
      <td>Worker 내에서 실행되는 자바 스레드</td>
    </tr>
    <tr>
      <td>Tasker</td>
      <td>Spout과 Bolt 객체가 할당</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="3-스톰-아키텍처">3) 스톰 아키텍처</h3>
<h4 id="1-nimbus와-supervisor">1) Nimbus와 Supervisor</h4>
<p><img src="img/CH05/s1.png" alt="" /></p>
<ul>
  <li>Nimbus가 자바 프로그램으로 구성된 Topology Jar를 배포하기 위해 주키퍼로부터 Supervisor 정보 알아냄</li>
  <li>그 후 해당 Topology Jar 파일을 각 Supervisor에 전송하면 Supervisor는 해당 Node에서 Worker, Executor를 만들고, Spout과 Bolt가 수행되기 위한 Task도 할당함</li>
  <li>Supervisor가 정상적으로 배포되면, Exeternal Source Application 1에서 발생한 데이터가 Spout을 통해 유입되기 시작</li>
  <li>이를 다시 Bolt가 받아 데이터를 분산 처리하고, 처리 결과는 Bolt를 통해 타깃 시스템인 Exeternal Target Application 2로 전송됨</li>
  <li>이때 Task, Executor 개수를 증가시키면서 대규모 병렬 처리가 가능해지고, Spout과 Bolt의 성능이 향상됨</li>
</ul>

<p><br /></p>

<ul>
  <li>매우 견고한 장애 복구 기능도 제공</li>
  <li>만약 특정 Supervisor가 생성한 Worker 프로세스에 심각한 문제가 발생해 종료되면 Supervisor는 새로운 Worker 프로세스 다시 생성</li>
  <li>이때 처리중이던 데이터들(튜플)은 이전 수신지로 롤백되고, Topology가 다시 정상적으로 복구되면 롤백 시점부터 다시 처리하면서 데이터 정합성 보장</li>
</ul>

<p><br /></p>

<h3 id="4-스톰-활용-방안">4) 스톰 활용 방안</h3>
<p><img src="img/CH05/s2.png" alt="" /></p>
<ul>
  <li>파일럿 프로젝트에서 스톰은 스마트카 운전자의 실시간 운행 정보를 대상으로 <strong>데이터 라우팅과 스트리밍 처리</strong>에 활용될 것</li>
  <li>카프카의 Spout을 통해 유입되는 모든 운전자의 운행 정보 데이터는 두 개의 Bolt (HBase Bolt / Redis Bolt)로 나눠져서 처리됨
    <ul>
      <li>HBase Bolt는 모든 운행 정보를 정제없이 HBase로 곧바로 적재</li>
      <li>Redis Bolt는 <code class="language-plaintext highlighter-rouge">에스퍼</code>라는 룰 엔진이 감지한 이상 운행 패턴의 정보만 레디스 서버에 저장</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="4-esper">4. Esper</h2>
<h3 id="1-에스퍼-소개">1) 에스퍼 소개</h3>
<ul>
  <li>실시간 스트리밍 데이터의 복잡한 이벤트 처리가 필요할 때 사용하는 룰 엔진</li>
  <li>스톰은 실시간으로 발생하는 데이터로부터 복잡한 패턴을 찾고, 그 패턴에 따른 이벤트 처리하는 것은 쉽지 않음</li>
  <li>실시간으로 발생하는 데이터 간의 관계를 복합적으로 판단 및 처리하는 것을  <code class="language-plaintext highlighter-rouge">CEP</code>라고 하는데, 에스퍼가 이 CEP 기능을 제공함</li>
</ul>

<p><br /></p>

<h3 id="2-주요-구성-요소-3">2) 주요 구성 요소</h3>

<table>
  <thead>
    <tr>
      <th>주요 구성 요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Event</td>
      <td>실시간 스트림으로 발생하는 데이터들의 특정 흐름 또는 패턴 정의</td>
    </tr>
    <tr>
      <td>EPL</td>
      <td>유사 SQL을 기반으로 하는 이벤트 데이터 처리 스크립트 언어</td>
    </tr>
    <tr>
      <td>Input Adapter</td>
      <td>소스로부터 전송되는 데이터를 처리하기 위한 어댑터 제공 (CSV, Socket, JDBC, http 등)</td>
    </tr>
    <tr>
      <td>Output Adapter</td>
      <td>타깃으로 전송하는 데이터를 처리하기 위한 어댑터 제공 (HFS, CSV, Socket, Email, Http 등)</td>
    </tr>
    <tr>
      <td>Window</td>
      <td>실시간 스트림 데이터로부터 특정 시간 또는 개수를 설정한 이벤트들을 메모리 상에 등록한 후 EPL을 통해 결과 추출</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="3-에스퍼-아키텍처">3) 에스퍼 아키텍처</h3>
<h4 id="1-에스퍼-아키텍처-1">1) 에스퍼 아키텍처 1</h4>
<p><img src="img/CH05/e1.png" alt="" /></p>
<ul>
  <li>에스퍼는 CEP(Complex Event Processing) 엔진</li>
  <li><strong>엔진</strong>은 단순 자바 라이브러리 프로그램</li>
  <li>애플리케이션 서버(톰캣, 제이보스, OSGI, 스톰 등) 또는 애플리케이션의 컨텍스트에 에스퍼 라이브러리를 설치하고, 해당 라이브러리를 이용해 CEP 프로그래밍을 하는 단순 아키텍처</li>
</ul>

<p><br /></p>

<h4 id="2-에스퍼-아키텍처2">2) 에스퍼 아키텍처2</h4>
<p><img src="img/CH05/e2.png" alt="" /></p>
<ul>
  <li>에스퍼의 EPL을 이용해 대규모 분산 아키텍처를 구성할 때는 룰을 통합 관리하고, 분산 노드에 일관되게 적용하기 위해 위 이미지처럼 다소 복잡한 구성 필요</li>
  <li>이때 분산된 응용 서버에 에스퍼 엔진을 설치하고, 에스퍼 엔진들이 동일한 EPL 룰을 동작으로 일괄 로딩하기 위해 EPL 공유 저장소가 이용됨</li>
</ul>

<p><br /></p>

<h3 id="4-에스퍼-활용-방안">4) 에스퍼 활용 방안</h3>
<p><img src="img/CH05/e3.png" alt="" /></p>
<ul>
  <li>파일럿 프로젝트에서는 운전자의 운행 데이터를 실시간으로 분석하기 위해 데스퍼 EPL 활용</li>
  <li>EPL은 30초 동안의 평균 시속을 체크해서 80km/h를 초과하는 운전자 이벤트 정보를 실시간으로 감지할 수 있도록 룰 정의</li>
  <li>해당 이벤트 데이터는 감지 즉시 레디스에 적재되어 과속한 차량 정보만 관리할 수 있게 됨</li>
</ul>

<p><br /></p>

<h2 id="5-실시간-적재-아키텍처">5. 실시간 적재 아키텍처</h2>
<h3 id="1-실시간-적재-요구사항">1) 실시간 적재 요구사항</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">요구사항 1</code> : 차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태 점검</li>
  <li><code class="language-plaintext highlighter-rouge">요구사항 2</code> : 운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행 패턴 분석</li>
</ul>

<p><br /></p>

<table>
  <thead>
    <tr>
      <th>실시간 적재 요구사항 구체화</th>
      <th>분석 및 해결 방안</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1. 1초 간격으로 발생하는 100명의 운행 정보(1건: 약 4KB는 손실없이 적재해야 함</td>
      <td>카프카와 스톰을 이용해 수집한 데이터에 대해 분산 처리 및 무결성 보장, 분산 처리가 완료된 데이터는 HBase에 적재</td>
    </tr>
    <tr>
      <td>2. 적재한 운행 정보를 대상으로 조건 검색이 가능해야 하며, 필요시 수정도 가능해야 함</td>
      <td>HBase의 테이블에 적재된 데이터는 **스캔** 조건으로 검색하며, 저장(Put) 기능을 이용해 기적재한 데이터에 대해 칼럼 기반으로 수정</td>
    </tr>
    <tr>
      <td>3. 운전자의 운행 정보 중 30초를 기준으로 평균 속도가 80km/h를 초과한 정보는 분리 적재함</td>
      <td>에스퍼의 EPL에서 사용자별로 운행 정보를 그루핑하고, 30초의 윈도우 타임 조건으로 평균 시속 집계 및 임계치별 이벤트 정의</td>
    </tr>
    <tr>
      <td>4. 과속한 차량을 분리 적재하기 위한 조건은 별도의 룰로 정의하고 쉽게 수정할 수 있어야 함</td>
      <td>과속 기준을 80km/h에서  100km/h로 수정해야 할 경우 EPL의 평균 속도를 체크하는 조건값만 수정</td>
    </tr>
    <tr>
      <td>5. 분리 적재한 데이터는 외부 애플리케이션이 빠르게 접근하고 조회할 수 있게 해야 함</td>
      <td>실시간 이벤트로 감지된 데이터는 인메모리 기반 저장소인 **레디스**에 적재하여 외부 애플리케이션에서 빠르게 조회</td>
    </tr>
    <tr>
      <td>6. 레디스에 적재한 데이터는 저장소의 공간을 효율적으로 사용하기 위해 1주일이 지나면 영구적으로 삭제함</td>
      <td>레디스 클라이언트 라이브러리인 **제디스(Jedis) 클라이언트를 이용해 데이터 적재 시 만료(Expire) 시간을 설정해 자동으로 영구 삭제 처리</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="2-실시간-적재-아키텍처">2) 실시간 적재 아키텍처</h3>
<p><img src="img/CH05/%EC%8B%A4%EC%8B%9C%EA%B0%84%EC%A0%81%EC%9E%AC%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98.png" alt="" /></p>
<ul>
  <li>CH03에서는 플럼의 DriverCarInfo 에이전트에서 수집한 운전자 운행 정보를 카프카의 토픽에 실시간으로 전송함</li>
  <li>Ch05에서는 스톰의 카프카-Spout을 이용해 카프카의 토픽에 저장되어 있는 운전자 운행 정보를 가져와 처리하고, 카프카-Bolt에서 이벤트 조건에 따라 레디스와 HBase에 각각 분리 적재함</li>
</ul>

<p><br /></p>

<h4 id="스톰의-실시간-데이터-처리">스톰의 실시간 데이터 처리</h4>
<ul>
  <li>스톰은 카프카로부터 수신받은 운행 정보 데이터를 분산 처리하고, 최종 목적지 저장소에 적재하는 역할</li>
  <li>이때 빠르게 유입되는 데이터로부터 의미 있는 패턴을 발견하기 위해 에스퍼 엔진 이용</li>
  <li>그림에서 ⓵)
    <ul>
      <li>스톰의 Spout가 카프카의 토픽으로부터 운전자의 실시간 운행 정보를 수신받아 첫 번째 볼트에 전송</li>
      <li>해당 Bolt에서는 모든 운행 정보를 HBase Bolt로 전송하면서, 에스퍼의 EPL에서 정의한 조건에 따라 과속한 차량의 정보를 레디스 Bolt에 전송</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="hbase에-모든-운전자-운행-정보-적재">HBase에 모든 운전자 운행 정보 적재</h4>
<ul>
  <li>그림에서 ⓶)
    <ul>
      <li>HBase의 테이블에는 <code class="language-plaintext highlighter-rouge">차량번호+발생일시</code>를 로우키로 해서 8개의 칼럼의 구조로 모든 스마트카 운전자의 운행 정보가 적재됨</li>
      <li><strong>칼럼</strong> (발생일시, 차량번호, 가속 페달, 브레이크 페달, 운전대 회전각, 방향지시등, 주행 속도, 주행 구역)</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="레디스에-과속한-운전자-정보-적재">레디스에 과속한 운전자 정보 적재</h4>
<ul>
  <li>그림에서 ⓷)
    <ul>
      <li>레디스에 적재될 때는 현재 날짜를 키로 해서 과속한 차량의 정보를 세트 데이터 구조로 적재</li>
      <li>적재 영속 시간은 5시간으로 하며, 이후에 만료 처리되어 메모리에서 자동으로 삭제됨</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="6-실시간-적재-환경-구성">6. 실시간 적재 환경 구성</h2>
<ul>
  <li>3개의 소프트웨어 추가 설치
    <ul>
      <li>CM으로 <code class="language-plaintext highlighter-rouge">HBase</code>를 Server01, 02에 있는 데이터노드에 설치</li>
      <li><code class="language-plaintext highlighter-rouge">레디스</code>와 <code class="language-plaintext highlighter-rouge">스톰</code>은 CM에 포함되어 있지 않은 소프트웨어로 별도의 패키지로 설치</li>
    </ul>
  </li>
</ul>

<p><img src="img/CH05/last.png" alt="" /></p>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[[출처: 실무로 배우는 빅데이터 기술, 김강원 저]]]></summary></entry><entry><title type="html">MAC 하둡 설치</title><link href="http://localhost:4000/hadoop/2023/09/22/install-hadoop.html" rel="alternate" type="text/html" title="MAC 하둡 설치" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T04:20:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/install-hadoop</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/install-hadoop.html"><![CDATA[<h2 id="1-homebrew로-하둡-설치">1. Homebrew로 하둡 설치</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>hadoop

brew info hadoop
<span class="c"># 하둡 설치 위치</span>
<span class="c">## /opt/homebrew/Cellar/hadoop/3.3.6</span>
<span class="c">## Required: openjdk@11</span>
</code></pre></div></div>

<h3 id="hadoop-환경변수-설정">HADOOP 환경변수 설정</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vi ~/.bash_profile

<span class="nb">export </span><span class="nv">HADOOP_HOME</span><span class="o">=</span>/opt/homebrew/Cellar/hadoop/3.3.6/libexec  <span class="c"># 추가</span>
<span class="nb">export </span><span class="nv">HADOOP_INSTALL</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_MAPRED_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_COMMON_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_HDFS_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">YARN_HOME</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>
<span class="nb">export </span><span class="nv">HADOOP_COMMON_LIB_NATIVE_DIR</span><span class="o">=</span><span class="nv">$HADOOP_HOME</span>/lib/native
<span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HADOOP_HOME</span>/sbin:<span class="nv">$HADOOP_HOME</span>/bin
<span class="nb">export </span><span class="nv">HADOOP_OPTS</span><span class="o">=</span><span class="s2">"-Djava.library.path=</span><span class="nv">$HADOOP_HOME</span><span class="s2">/lib"</span>
<span class="nb">export </span><span class="nv">LD_LIBRARY_PATH</span><span class="o">=</span><span class="nv">$LD_LIBRARY_PATH</span>:<span class="nv">$HADOOP_HOME</span>/lib/native
 
<span class="nb">source</span> ~/.bash_profile  <span class="c"># 적용</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="2-java_home-path---java-180_371-설정">2. JAVA_HOME PATH -&gt; java 1.8.0_371 설정</h2>

<!-- ```bash
vi ~/.bash_profile

export JAVA_HOME=/opt/homebrew/Cellar/openjdk@11/11.0.19/libexec/openjdk.jdk/Contents/Home
export PATH=$PATH:$JAVA_HOME/bin

source ~/.bash_profile 
```
```bash
java -version
# openjdk version "11.0.19" 2023-04-18
``` -->

<p>https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions</p>

<ul>
  <li>Java 8 설치 권장</li>
</ul>

<!-- ```bash
brew install cask

brew tap AdoptOpenJDK/openjdk
brew install --cask adoptopenjdk8

java -version
# java version "1.8.0_371"
``` -->

<p><br /></p>

<h3 id="jdk-버전-변경">JDK 버전 변경</h3>

<ul>
  <li>설치된 JDK 버전 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/usr/libexec/java_home <span class="nt">-V</span>

<span class="c"># Matching Java Virtual Machines (5):</span>
<span class="c">#     17.0.7 (arm64) "Oracle Corporation" - "Java SE 17.0.7" /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home</span>
<span class="c">#     1.8.371.11 (x86_64) "Oracle Corporation" - "Java" /Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home</span>
<span class="c">#     1.8.0_371 (x86_64) "Oracle Corporation" - "Java SE 8" /Library/Java/JavaVirtualMachines/jdk-1.8.jdk/Contents/Home</span>
<span class="c">#     1.8.0_292 (x86_64) "AdoptOpenJDK" - "AdoptOpenJDK 8" /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home</span>
<span class="c"># /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/Library/Java/JavaVirtualMachines/jdk-1.8.jdk/Contents/Home

java <span class="nt">-version</span>
<span class="c"># openjdk version "1.8.0_371"</span>

<span class="nb">echo</span> <span class="nv">$JAVA_HOME</span>
<span class="c"># /Library/Java/JavaVirtualMachines/jdk-1.8.jdk/Contents/Home</span>
</code></pre></div></div>

<p><br /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">~/.bash_profile</code> 파일에도 JAVA_HOME 추가
```bash
vi ~/.bash_profile</li>
</ul>

<p>export JAVA_HOME=/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home  # 추가</p>

<p>source ~/.bash_profile  # 적용</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;br&gt;

## 3. Hadoop 환경 설정

```bash
cd $HADOOP_HOME/etc/hadoop
</code></pre></div></div>

<p><br /></p>

<h3 id="1-core-sitexml">1) core-site.xml</h3>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>fs.defaultFS<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>hdfs://localhost:9000<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/tmp/hadoop-${user.name}<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="2-hdfs-stiexml">2) hdfs-stie.xml</h3>

<ul>
  <li>namenode, datanode 파일 만들어질 <code class="language-plaintext highlighter-rouge">/Users/{user.name}/hadoop</code> 폴더 만들어놓고 작성</li>
</ul>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>1<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.name.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/Users/bokyung/hadoop/namenode<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.data.dir<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>/Users/bokyung/hadoop/datanode<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.http-address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>localhost:50070<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.namenode.secondary.http-address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>localhost:50090<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>localhost:50010<span class="nt">&lt;/value&gt;</span>
   <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>dfs.datanode.http.address<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>localhost:50075<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="3-mapred-sitexml">3) mapred-site.xml</h3>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>mapreduce.framework.name<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>yarn<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>mapreduce.application.classpath<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="4-yarn-sitexml">4) yarn-site.xml</h3>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.aux-services<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>mapreduce_shuffle<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
    <span class="nt">&lt;property&gt;</span>
        <span class="nt">&lt;name&gt;</span>yarn.nodemanager.env-whitelist<span class="nt">&lt;/name&gt;</span>
        <span class="nt">&lt;value&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME<span class="nt">&lt;/value&gt;</span>
    <span class="nt">&lt;/property&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="5-hadoop-envsh">5) hadoop-env.sh</h3>

<ul>
  <li>JAVA PATH만 한 번 더 적어주기</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/opt/homebrew/Cellar/openjdk@11/11.0.19/libexec/openjdk.jdk/Contents/Home
</code></pre></div></div>

<p><br /></p>

<h2 id="4-namenode-format">4. namenode format</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs namenode <span class="nt">-format</span>
</code></pre></div></div>

<h3 id="주의할-점">주의할 점!</h3>

<ul>
  <li>환경 설정을 바꿀 때 hadoop, yarn 종료 후 변경하기
    <ul>
      <li><code class="language-plaintext highlighter-rouge">cd $HADOOP_HOME/sbin</code> -&gt; <code class="language-plaintext highlighter-rouge">stop-yarn.sh</code> <code class="language-plaintext highlighter-rouge">stop-dfs.sh</code></li>
    </ul>
  </li>
  <li>변경 후 namenode 포맷 후 재실행</li>
  <li>포맷 전에 <strong>datanode, namenode 폴더 지우고</strong> 포맷!!!
    <ul>
      <li>그렇지 않으면 datanode가 실행되지 않음!</li>
      <li><code class="language-plaintext highlighter-rouge">hdfs-site.xml</code>에서 설정한 폴더</li>
      <li>재실행 시 다시 생김</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="5-hadoop-실행">5. Hadoop 실행</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> <span class="nv">$HADOOP_HOME</span>/sbin
start-dfs.sh
start-yarn.sh

jps
<span class="c"># 98658 Jps</span>
<span class="c"># 98034 DataNode</span>
<span class="c"># 98549 NodeManager</span>
<span class="c"># 97924 NameNode</span>
<span class="c"># 98452 ResourceManager</span>
<span class="c"># 98170 SecondaryNameNode</span>
</code></pre></div></div>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[Hadoop 설치]]></summary></entry><entry><title type="html">[pilot] Ch5. 빅데이터 적재 실습 (2)</title><link href="http://localhost:4000/hadoop/2023/09/22/ch5(2).html" rel="alternate" type="text/html" title="[pilot] Ch5. 빅데이터 적재 실습 (2)" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T05:30:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/ch5(2)</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/ch5(2).html"><![CDATA[<h2 id="1-실시간-적재-환경-구성">1. 실시간 적재 환경 구성</h2>
<h3 id="1-hbase-설치">1) HBase 설치</h3>
<ul>
  <li>CM 홈 - [서비스 추가] - [HBase] 선택 - [계속]
<img src="img/CH05/hbase%20%EC%84%A4%EC%B9%98.png" alt="" /></li>
</ul>

<p><br /></p>

<ul>
  <li>HBase의 Master와 RegionServer 설치 위치 지정</li>
  <li>Server01, Server02만 있는 상태이므로, 모든 설치 위치를 Server02로 지정</li>
  <li>추기로 Thrift Server는 Server01에 설치하며, REST 서버는 사용하지 않음
<img src="img/CH05/hbase%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%A7%80%EC%A0%95%20-%20server3%EA%B0%80%20%EC%97%86%EC%96%B4%EC%84%9C%20%EC%A0%84%EB%B6%80%20server2%EB%A1%9C.png" alt="" /></li>
</ul>

<p><br /></p>

<ul>
  <li>HBase Service의 기본 설정값 변경</li>
  <li>HBase의 테이블 복제 및 인덱스는 사용하지 않음</li>
  <li>기본값을 유지하고 [계속] 클릭</li>
</ul>

<p><br /></p>

<ul>
  <li>HBase의 Thrift Http 서버 활성화</li>
  <li>CM 홈 - [HBase] - [구성]</li>
  <li>“HBase Thrift Http 서버 설정” 검색</li>
  <li><strong>HBase(서비스 전체)</strong> 항목 체크 후 [변경 내용 저장]
<img src="img/CH05/hbase%20%EA%B5%AC%EC%84%B1%20%EB%B3%80%EA%B2%BD.png" alt="" /></li>
</ul>

<p><br /></p>

<ul>
  <li>HBase 서비스 시작 또는 재시작</li>
  <li>그럼 HBase의 Master 서버와 RegionServer 기동 화면이 활성화될 것</li>
  <li>HBase처럼 규모가 있는 컴포넌트가 설치되면 이미 설치된 소프트웨어(주키퍼, HDFS, YARN 등)의 클라이언트 설정값에 변동 발생 -&gt; 클라이언트 재배포를 통해 변경사항 반영</li>
</ul>

<p><br /></p>

<ul>
  <li>HBase가 정상적으로 설치되었는지 확인하기 위해 HBase 쉘에서 테스트용 테이블을 만들고, 해당 테이블에 Put / Get 명령 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hbase shell
<span class="o">&gt;</span> create <span class="s1">'smartcar_test_table'</span>, <span class="s1">'cf'</span>
<span class="o">&gt;</span> put <span class="s1">'smartcar_test_table'</span>, <span class="s1">'row-key1'</span>, <span class="s1">'cf:model'</span>, <span class="s1">'Z0001'</span>
<span class="o">&gt;</span> put <span class="s1">'smartcar_test_table'</span>, <span class="s1">'rew-key1'</span>, <span class="s1">'cf:no'</span>, <span class="s1">'12345'</span>
<span class="o">&gt;</span> get <span class="s1">'smartcar_test_table'</span>, <span class="s1">'row-key1'</span>
</code></pre></div>    </div>
    <p><img src="img/CH05/hbase%20shell%20put%2C%20get%20%ED%85%8C%EC%8A%A4%ED%8A%B8.png" alt="" /></p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># table 삭제</span>
<span class="o">&gt;</span> disable <span class="s1">'smartcar_test_table'</span>
<span class="o">&gt;</span> drop <span class="s1">'smartcar_test_table'</span>
<span class="o">&gt;</span> <span class="nb">exit</span>
</code></pre></div></div>
<p><img src="img/CH05/hbase%20shell%20disable.png" alt="" />
<img src="img/CH05/hbase%20shell%20drop.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>HBase 웹 관리자 화면에 접속하면 HBase의 다양한 상태를 모니터링할 수 있음 <br />
http://server02.hadoop.com:16010
<img src="img/CH05/hbase%20%EC%9B%B9%EA%B4%80%EB%A6%AC%EC%9E%90%20%ED%99%94%EB%A9%B4.png" alt="" /></li>
</ul>

<p><br /></p>

<ul>
  <li>HBase는 자원 소모가 높은 서버이므로 사용하지 않을 때는 일시 정지</li>
</ul>

<p><br /></p>

<h3 id="2-레디스-설치">2) 레디스 설치</h3>
<ul>
  <li>CM의 소프트웨어 컴포넌트로 포함되어 있지 않기 때문에 레디스 설치 패키지로 Server02에 직접 설치</li>
</ul>

<p><br /></p>

<ul>
  <li>Server02에 root 계정으로 로그인</li>
  <li><strong>gcc</strong>와 <strong>tcl</strong> 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>yum <span class="nb">install</span> <span class="nt">-y</span> gcc<span class="k">*</span>
yum <span class="nb">install</span> <span class="nt">-y</span> tcl
</code></pre></div></div>

<blockquote>
  <p>yum 명령 중 “removing mirrorlist with no valid mirrors:..” 에러가 발생하면 아래 명령 모두 실행</p>
  <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"http: //vault.centos.org/6.10/os/×86_64/"</span> <span class="o">&gt;</span> /var/cache/yum/x86_64/6/base/mirrorlist.txt
<span class="nb">echo</span> <span class="s2">"http://vault.centos.org/6.10/extras/x86_64/"</span> <span class="o">&gt;</span> /var/cache/yum/×86_64/6/extras/mirrorlist.txt
<span class="nb">echo</span> <span class="s2">"http://vault.centos.org/6. 10/updates/x86_64/"</span> <span class="o">&gt;</span> /var/cache/yum/x86_64/6/updates/mirrorlist.txt
<span class="nb">echo</span> <span class="s2">"http://vault.centos.org/6.10/sclo/x86_64/rh"</span> › /var/cache/yum/×86_64/6/centos-sclo-rh/mirrorlist.txt 
<span class="nb">echo</span> <span class="s2">"http://vault.centos.org/6.10/sclo/x86_64/sclo"</span> <span class="o">&gt;</span>/var/cache/yum/×86_64/6/centos-sclo-sclo/mirrorlist.txt
</code></pre></div>  </div>
</blockquote>

<p><br /></p>

<ul>
  <li>레디스 5.0.7 다운받아 빌드 및 설치 진행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt
wget http://download.redis.io/releases/redis-5.0.7.tar.gz
<span class="nb">tar</span> <span class="nt">-xvf</span> redis-5.0.7.tar.gz
<span class="nb">cd</span> /home/pilot-pjt/redis-5.0.7
make
make <span class="nb">install
cd</span> /home/pilot-pjt/redis-5.0.7/utils
<span class="nb">chmod </span>75 install_server.sh
</code></pre></div>    </div>
    <p><img src="img/CH05/redis%20%EC%84%A4%EC%B9%981.png" alt="" />
<img src="img/CH05/redis%20%EC%84%A4%EC%B9%982-%20make.png" alt="" />
<img src="img/CH05/redis%20%EC%84%A4%EC%B9%983.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>인스톨 스크립트 실행</li>
  <li>여러 확인 메시지들 모두 엔터키 입력
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./install_server.sh
</code></pre></div>    </div>
    <p><img src="img/CH05/redis%20%EC%84%A4%EC%B9%984.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>레디스 인스턴스의 포트, 로그, 데이터 파일 등의 설정값 및 위치 정보를 물어보면 기본값을 그대로 유지하고 엔터키 입력</li>
  <li>아래 <code class="language-plaintext highlighter-rouge">vi</code> 명령으로 레디스 서버 기동 여부 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vi /var/log/redis_6379.log
</code></pre></div>    </div>
    <p><img src="img/CH05/redis%20%EC%84%9C%EB%B2%84%20%EA%B8%B0%EB%8F%99%20%EC%97%AC%EB%B6%80%20%ED%99%95%EC%9D%B8.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>레디스가 성공적으로 설치됐는지 점검하기 위해 아래 명령 실행 후 <code class="language-plaintext highlighter-rouge">Redis is running</code> 메시지 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>service redis_6379 status
</code></pre></div>    </div>
    <blockquote>
      <p>redis 서버 포트 기본값: 6379</p>
    </blockquote>
  </li>
  <li>레디스 서비스 시작 <code class="language-plaintext highlighter-rouge">service redis_6379 start</code></li>
  <li>레디스 서비스 종료 <code class="language-plaintext highlighter-rouge">service redis_6379 stop</code></li>
</ul>

<p><br /></p>

<ul>
  <li>레디스 서버에 원격 접근을 하기 위해 설정 파일을 열어 아래와 같이 수정</li>
  <li>설정 파일은 <code class="language-plaintext highlighter-rouge">/etc/redis/6379.conf</code>에 위치
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vi /etc/redis/6379.conf
</code></pre></div>    </div>
  </li>
  <li>바인딩 IP 제한 해제
    <ul>
      <li><code class="language-plaintext highlighter-rouge">bind 127.0.0.1</code> 부분 주석 처리</li>
    </ul>
  </li>
  <li>패스워드 입력 해제
    <ul>
      <li><code class="language-plaintext highlighter-rouge">protected-mode yes</code> 부분을 찾아 <strong>yes</strong> -&gt; <strong>no</strong> 로 변경
<img src="img/CH05/redis%20%EC%84%A4%EC%A0%95%ED%8C%8C%EC%9D%BC%20%EC%88%98%EC%A0%95.png" alt="" /></li>
    </ul>
  </li>
  <li>레디스 서버 재시작
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>service redis_6379 restart
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>레디스 CLI를 통해 간단히 레디스 서버에 데이터 저장(Set) / 조회(Get)</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">key:1</code>이라는 키로 “Hello!BigData” 값을 레디스 서버에 저장하고 다시 조회</li>
      <li>마지막으로 <code class="language-plaintext highlighter-rouge">key:1</code>의 데이터 삭제하고 레디스 CLI 종료
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>redis-cli
<span class="o">&gt;</span> <span class="nb">set </span>key:1 Hello!BigData
<span class="o">&gt;</span> get key:1
<span class="o">&gt;</span> del key:1
<span class="o">&gt;</span> quit
</code></pre></div>        </div>
        <p><img src="img/CH05/redis%20%EC%9E%AC%EC%8B%9C%EC%9E%91%20%ED%9B%84%20cli%20%ED%85%8C%EC%8A%A4%ED%8A%B8.png" alt="" /></p>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="3-스톰-설치">3) 스톰 설치</h3>
<ul>
  <li>Server02에 root 계정으로 접속해서 스톰 설치를 위한 tar 파일 다운로드
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt
wget http://archive.apache.org/dist/storm/apache-storm-1.2.3/apache-storm-1.2.3.tar.gz
<span class="nb">tar</span> <span class="nt">-xvf</span> apache-storm-1.2.3.tar.gz
<span class="nb">ln</span> <span class="nt">-s</span> apache-storm-1.2.3 storm
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>스톰 환경설정 파일 수정</strong></li>
  <li><code class="language-plaintext highlighter-rouge">storm.yaml</code> 파일 열어서 아래 내용과 동일하게 입력
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/storm/conf
vi storm.yaml
</code></pre></div>    </div>
    <p>```yaml
storm.zookeeper.servers:</p>
  </li>
  <li>“server02.hadoop.com”</li>
</ul>

<p>storm.local.dir: “/home/pilot-pjt/storm/data”</p>

<p>nimbus.seeds: [“server02.hadoop.com”]</p>

<p>supervisor.slots.ports:</p>
<ul>
  <li>6700</li>
</ul>

<p>ui.port: 8088</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>![](img/CH05/storm.yaml%20%ED%8C%8C%EC%9D%BC%20%EC%88%98%EC%A0%95.png)

- 5개의 스톰 설정값
    - 주키퍼 정보
    - 스톰이 작동하는 데 필요한 데이터 저장소
    - 스톰의 Nimbus 정보
    - Worker의 포트로서, 포트의 개수만큼 멀티 Worker가 만들어짐
        - 파일럿 프로젝트에서는 6700번 포트의 단일 워커만 작동
    - 마지막으로 스톰 UI 접속 포트 설정

&lt;br&gt;

- **스톰의 로그 레벨 조정**
- 기본값인 "info"로 되어있는데, 스톰에서는 대규모 트랜잭션 데이터가 유입되면서 과도한 로그로 인해 성능 저하와 디스크 공간 부족이 발생할 수 있음
- 이 같은 문제르 방지하기 위해 두 개의 파일 수정
    - cluster.zml , worker.xml 파일
    - 75번째 줄과 91번째 줄 사이의  logger 설정에서 `level="info"` -&gt; `level="error`로 모두 변경

```bash
cd /home/pilot-pjt/storm/long4j2
vi cluster.xml
vi worker.xml
</code></pre></div></div>
<p><img src="img/CH05/storm%20%EB%A1%9C%EA%B7%B8%20%EB%A0%88%EB%B2%A8%20%EC%A1%B0%EC%A0%95.png" alt="" /></p>

<p><br /></p>

<ul>
  <li><strong>root 계정의 프로파일의 스톰 path 설정</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vi /root/.bash_profile
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">/home/pilot-pjt/storm/bin</code> 경로 추가</li>
</ul>

<p><img src="img/CH05/strom%20path%20%EC%84%A4%EC%A0%95.png" alt="" /></p>

<ul>
  <li><strong>수정한 root 계정의 프로파일 정보 다시 읽어옴</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">source</span> /root/.bash_profile
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>CH02에서 설정했던 자바 명령의 링크 정보가 변경되는 경우가 있음</li>
  <li><code class="language-plaintext highlighter-rouge">java -version</code>을 실행한 후, ‘1.8.x’가 아니면 아래 명령을 통해 JDK 1.8 링크로 변경
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">rm</span> /usr/bin/java
<span class="nb">rm</span> /usr/bin/javac
<span class="nb">ln</span> <span class="nt">-s</span> /usr/java/jdk1.8.0_181-cloudera/bin/javac /usr/bin/javac
<span class="nb">ln</span> <span class="nt">-s</span> /usr/java/jdk1.8.0_181-cloudera/bin/java /usr/bin/java
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>기본적인 스톰 설치 완료</li>
  <li>리눅스가 재시작할 때도 스톰이 자동으로 실행되도록 설정</li>
  <li><code class="language-plaintext highlighter-rouge">storm-nimbus</code>, <code class="language-plaintext highlighter-rouge">storm-supervisor</code>, <code class="language-plaintext highlighter-rouge">storm-ui</code> 3개의 스톰 서비스가 있고, 3개의 자동 실행 스크립트 필요</li>
  <li>파일질라 이용해서 sever02에 3개의 스크립트 생성
<img src="img/CH05/%EC%8A%A4%ED%86%B0%20%EC%84%9C%EB%B9%84%EC%8A%A4%20%EC%9E%90%EB%8F%99%20%EC%8B%A4%ED%96%89%20%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%20%EC%97%85%EB%A1%9C%EB%93%9C.png" alt="" /></li>
</ul>

<p><br /></p>

<ul>
  <li><strong>업로드한 세 파일의 권한 변경</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod </span>755 /etc/rc.d/init.d/storm-nimbus
<span class="nb">chmod </span>755 /etc/rc.d/init.d/storm-supervisor
<span class="nb">chmod </span>755 /etc/rc.d/init.d/storm-ui
</code></pre></div>    </div>
    <p><img src="img/CH05/storm%20%EC%9E%90%EB%8F%99%EC%8B%A4%ED%96%89%20%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%20%ED%8C%8C%EC%9D%BC%20%EA%B6%8C%ED%95%9C%20%EB%B3%80%EA%B2%BD.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>서비스 등록 스크립트에 대한 Log 및 Pid 디렉터리 생성</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> /var/log/storm
<span class="nb">mkdir</span> /var/run/storm
</code></pre></div>    </div>
    <p><img src="img/CH05/%EC%84%9C%EB%B9%84%EC%8A%A4%20%EB%93%B1%EB%A1%9D%20%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%EC%97%90%20%EB%8C%80%ED%95%9C%20%EB%94%94%EB%A0%89%ED%84%B0%EB%A6%AC.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>**세 파일에 대해 아래의 service/chkconfig 등록 명령 각각 실행
```bash</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;br&gt;

- **아래 명령으로 스톰이 정상적으로 구동됐는지 확인**
```bash
service storm-nimbus status
service storm-supervisor status
service storm-ui status
</code></pre></div></div>
<ul>
  <li>모두 <code class="language-plaintext highlighter-rouge">...is running</code> 상태인지 확인
    <blockquote>
      <p>주의) 스톰은 주키퍼에 의존도가 높기 때문에, 스톰을 사용할 땐 반드시 주키퍼의 상태를 확인해야 함!</p>
    </blockquote>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>스톰 UI에 접속해서 스톰의 중요 상태들을 모니터링할 수 있음 <br />
http://server02.hadoop.com:8088
<img src="img/CH05/storm%20ui.png" alt="" /></li>
</ul>

<p><br /></p>

<h2 id="2-실시간-적재-기능-구현">2. 실시간 적재 기능 구현</h2>
<ul>
  <li>스톰의 Spout과 Bolt의 프로그램 구현 단계</li>
  <li>운전자의 운행 정보가 실시간으로 카프카에 적재되고, 이를 스톰의 Spout가 읽어서 Bolt로 전달</li>
  <li>아래 그림은 파일럿 프로젝트에서 실시간 처리와 적재를 위한 스톰 Topology</li>
  <li>Topology 안의 5개 컴포넌트는 모두 자바 프로그램이며, 해당 프로그램을 통해 실시간 적재 기능 구현
<img src="img/CH05/%EC%8B%A4%EC%8B%9C%EA%B0%84%EC%A0%81%EC%9E%AC%EA%B8%B0%EB%8A%A5.png" alt="" /></li>
</ul>

<p><br /></p>

<blockquote>
  <p><strong>용어 정리</strong> <br />
<code class="language-plaintext highlighter-rouge">table</code>: HBase는 데이터를 테이블에 조직화. 여러 개의 로우로 구성된 집합   <br />
<code class="language-plaintext highlighter-rouge">row</code>: 테이블 내에 있고, 데이터는 테이블의 로우에 따라 저장됨. 로우는 로우키와 한 개 이상의 칼럼과 값으로 구성됨.  <br />
<code class="language-plaintext highlighter-rouge">row key</code>: 로우는 로우키에 의해 유일하게 식별됨   <br />
<code class="language-plaintext highlighter-rouge">column</code>: HBase 칼럼은 column family와 column qualifier로 구성됨 <br />
<code class="language-plaintext highlighter-rouge">칼럼 패밀리</code>: 로우 내에 있는 데이터는 칼럼 패밀리에 의해 그룹화됨. 또한, HBase 내의 데이터 저장을 위한 물리적 처리 방식에 영향을 줌.</p>
</blockquote>

<p><br /></p>

<h3 id="1-카프카-spout-기능-구현">1) 카프카 Spout 기능 구현</h3>
<ul>
  <li>스톰 Spout의 기본 기능은 외부 시스템과의 연동을 통해 스톰의 Topology로 데이터를 가져오는 것</li>
  <li>파일럿 플젝에서는 카프카에 적재된 데이터를 가져오기 위해 <strong>카프카-Spout</strong>을 사용</li>
  <li>카프카 Spout은 카프카로부터 수신받은 데이터를 두 개의 Bolt(Split/Esper)에 라우팅</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>카프카 Spout 생성 - SmartCarDriverTopology.java</strong>
```java
package com.wikibook.bigdata.smartcar.storm;</li>
</ul>

<p>import java.io.IOException;
import java.util.Arrays;
import java.util.Map;
import java.util.UUID;</p>

<p>import org.apache.storm.guava.collect.Maps;
import org.apache.storm.redis.common.config.JedisPoolConfig;</p>

<p>import storm.kafka.BrokerHosts;
import storm.kafka.KafkaSpout;
import storm.kafka.SpoutConfig;
import storm.kafka.StringScheme;
import storm.kafka.ZkHosts;
import backtype.storm.Config;
import backtype.storm.StormSubmitter;
import backtype.storm.generated.AlreadyAliveException;
import backtype.storm.generated.InvalidTopologyException;
import backtype.storm.generated.StormTopology;
import backtype.storm.spout.Scheme;
import backtype.storm.spout.SchemeAsMultiScheme;
import backtype.storm.topology.TopologyBuilder;</p>

<p>public class SmartCarDriverTopology {</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>public static void main(String[] args) throws AlreadyAliveException, InvalidTopologyException, InterruptedException, IOException {  

	StormTopology topology = makeTopology();

	Map&lt;String, String&gt; HBaseConfig = Maps.newHashMap();
	HBaseConfig.put("hbase.rootdir","hdfs://server01.hadoop.com:8020/hbase");

	Config config = new Config();
	config.setDebug(true);
	config.put("HBASE_CONFIG",HBaseConfig);

	config.put(Config.NIMBUS_HOST, "server01.hadoop.com");
	config.put(Config.NIMBUS_THRIFT_PORT, 6627);
	config.put(Config.STORM_ZOOKEEPER_PORT, 2181);
	config.put(Config.STORM_ZOOKEEPER_SERVERS, Arrays.asList("server02.hadoop.com"));

	StormSubmitter.submitTopology(args[0], config, topology);
}  

private static StormTopology makeTopology() {
    
    // ⓵
	String zkHost = "server02.hadoop.com:2181";
	TopologyBuilder driverCarTopologyBuilder = new TopologyBuilder();
	
	// Spout Bolt
	BrokerHosts brkBost = new ZkHosts(zkHost);
	String topicName = "SmartCar-Topic";
	String zkPathName = "/SmartCar-Topic";

    // ⓶
	SpoutConfig spoutConf = new SpoutConfig(brkBost, topicName, zkPathName, UUID.randomUUID().toString());
	spoutConf.scheme = new SchemeAsMultiScheme(new StringScheme());
	KafkaSpout kafkaSpout = new KafkaSpout(spoutConf);
	
    // ⓷
	driverCarTopologyBuilder.setSpout("kafkaSpout", kafkaSpout, 1);
	
    // ⓸
	// Grouping - SplitBolt &amp; EsperBolt
	driverCarTopologyBuilder.setBolt("splitBolt", new SplitBolt(),1).allGrouping("kafkaSpout");
	driverCarTopologyBuilder.setBolt("esperBolt", new EsperBolt(),1).allGrouping("kafkaSpout");
	
	// HBase Bolt
	TupleTableConfig hTableConfig = new TupleTableConfig("DriverCarInfo", "r_key");
	hTableConfig.setZkQuorum("server02.hadoop.com");
	hTableConfig.setZkClientPort("2181");
	hTableConfig.setBatch(false);
	hTableConfig.addColumn("cf1", "date");
	hTableConfig.addColumn("cf1", "car_number");
	hTableConfig.addColumn("cf1", "speed_pedal");
	hTableConfig.addColumn("cf1", "break_pedal");
	hTableConfig.addColumn("cf1", "steer_angle");
	hTableConfig.addColumn("cf1", "direct_light");
	hTableConfig.addColumn("cf1", "speed");
	hTableConfig.addColumn("cf1", "area_number");
	
	HBaseBolt hbaseBolt = new HBaseBolt(hTableConfig);
	driverCarTopologyBuilder.setBolt("HBASE", hbaseBolt, 1).shuffleGrouping("splitBolt");
	
	// Redis Bolt
	String redisServer = "server02.hadoop.com";
	int redisPort = 6379;
	JedisPoolConfig jedisPoolConfig = new JedisPoolConfig.Builder().setHost(redisServer).setPort(redisPort).build();
	RedisBolt redisBolt = new RedisBolt(jedisPoolConfig);
	
	driverCarTopologyBuilder.setBolt("REDIS", redisBolt, 1).shuffleGrouping("esperBolt");

	return driverCarTopologyBuilder.createTopology();
} }   ```
</code></pre></div></div>

<ul>
  <li>⓵
    <ul>
      <li>카프카에 접속하기 위한 서버와 토픽 정보를 정의</li>
      <li>KafkaSpout이 작동하는 Worker의 구성 정보 설정</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li>KafkaSpout 객체 생성</li>
      <li>주키퍼 서버 정보, 카프카 토픽 정보, 메시지 형식, 메시지 수신 방식 등 설정</li>
    </ul>
  </li>
  <li>⓷
    <ul>
      <li>KafkaSpout 객체를 스톰의 Topology에 설정</li>
      <li>‘고유 ID’, ‘Kafka Spout 객체, ‘병렬 처리 힌트’ 설정</li>
    </ul>
  </li>
  <li>⓸
    <ul>
      <li>KafkaSpout가 수신받은 데이터를 어떻게 라우팅할지에 대한 설정</li>
      <li>스톰 Topology의 그루핑 설정으로 All-Grouping 기능을 이용해 앞서 설정한 “KafkaSpout”로부터 받은 데이터를 두 개의 Bolt(Split/Esper)에 동일하게 전달</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="2-split-bolt-기능-구현">2) Split Bolt 기능 구현</h3>
<ul>
  <li>Split Bolt는 카프카-Spout으로부터 전달받은 메시지를 HBase의 칼럼 필드 단위로 분리하기 위한 작업 수행</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>Split Bolt 소스 - SplitBolt.java</strong>
```java
package com.wikibook.bigdata.smartcar.storm;</li>
</ul>

<p>import backtype.storm.topology.BasicOutputCollector;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseBasicBolt;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Values;</p>

<p>public class SplitBolt extends BaseBasicBolt{</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private static final long serialVersionUID = 1L;

public void execute(Tuple tuple, BasicOutputCollector collector) {

	String tValue = tuple.getString(0);  

    // ⓵
    // 발생일시(14자리), 차량번호, 가속페달, 브레이크페달, 운전대회적각, 방향지시등, 주행속도, 뮤직번호
	String[] receiveData = tValue.split("\\,");
	
    // ⓶
	collector.emit(new Values(	new StringBuffer(receiveData[0]).reverse() + "-" + receiveData[1]  , 
								receiveData[0], receiveData[1], receiveData[2], receiveData[3],
								receiveData[4], receiveData[5], receiveData[6], receiveData[7]));

}

public void declareOutputFields(OutputFieldsDeclarer declarer) {
    // ⓷
	declarer.declare(new Fields("r_key"			, "date"		, "car_number", 
								"speed_pedal"	, "break_pedal"	, "steer_angle", 
								"direct_light"	, "speed"		, "area_number"));
}
</code></pre></div></div>

<p>}</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- ⓵
    - KafkaSpout에서 전달한 데이터가 튜플 형식으로 수신됨
    - 그리고 튜플에 들어있는 데이터를 `,` 단위로 분리해서 배열에 담음
    - 스톰의 메시지 단위 하나를 **튜플**이라고 하는데, 각 스톰의 레이어 간(Spout -&gt; Bolt, Bolt -&gt; Bolt 등) 메시지 전달 단위로 생각하면 됨
- ⓶
    - 스마트카 운전자의 실시간 운행 정보 데이터셋의 형식 정의
    - 해당 데이터를 배열로 구조화하고, 데이터를 다음 단계로 전송
    - 빅데이터의 비정형 로그 데이터가 정형 데이터로 변환되는 과정으로 볼 수 있음
- ⓷
    - ⓶에서 설정한 9개의 값과 순서별로 일치하는 필드명은 다음과 같음
    - **r_key**: HBase 테이블에서 사용할 로우키
    - **date**: 운행 데이터 발생 일시
    - **car_num**: 스마트카의 고유 차량 번호
    - **speed_pedal**: 과속 페달 단계
    - **break_pedal**: 브레이크 페달 단계
    - **steer_angle**: 운전대 회전 각도
    - **direct_light**: 방향 지시등
    - **speed**: 차량 속도
    - **area**: 차량 운행 지역

&lt;br&gt;

- 여기서 **r_key**는 HBase 테이블에서 로우키로 활용되는 중요 필드로, `date + car_num`을 조합한 값
- 이때 `date`에는 타임스탬프를 **뒤집은 값**이 매핑됨
    - ex) '20160124134517' -&gt; '71543152106102'
    - HBase에 데이터를 저장할 때 로우키의 HexString 값을 기준으로 저장할 Region을 결정하는 메커니즘 때문
    - 파일럿 플젝에서 사용할 로우키는 동일패턴 `20160125XXXXXX + 차량번호`의 값이 지속적으로 생성되며, 로우키의 유사 HexString 값이 만들어져 특정 Region으로만 부하가 집중되는 문제 발생
    - 핸드폰 번호(010-XXXX-XXXX)나 위치 정보(GPS, IP) 등을 로우키로 활용할 때도 주의해야 함)
    - 또한, Region은 특정 크기가 되면 자동 분할되는데, 이때 서비스가 일시 중단되는 현상이 발생하기도 함
    - 이 같은 문제를 방지하기 위해 
        - HBase 테이블을 생성할 때 사용할 Region을 미리 스플릿(Pre-Split)해서 여러 개의 RegionServer에 분리 생성해놓음
        - 데이터를 저장할 때 로우키를 리버스해 HexString 시작값을 다양하게 발생시킴
        - 여러 RegionServer로 부하를 분산시킴으로써 저장 속도 극대화
- 이와 같은 HBase 로우키 메커니즘은 데이터 설계 단계에서부터 중요하게 검토해야 할 사항!

&lt;br&gt;

### 3) HBase Bolt 기능 구현
- HBase Bolt는 스마트카 운전자의 모든 운행 데이터를 최종적으로 적재하는 기능 수행
- 앞서 Split Bolt가 분리한 필드명을 HBase의 테이블 칼럼명과 일치시켜 칼럼 단위로 저장
- HBase Bolt도 HBase의 데이터를 적재하기 위해 HBase에 연결된 **주키퍼의 연결 정보**가 필요하며, 저장하고자 하는 **테이블의 로우키**와 **칼럼 패밀리 정보**도 알고있어야 함

&lt;br&gt;

- **HBase Bolt 생성 - SmartCarDriverTopology.java**
```java
package com.wikibook.bigdata.smartcar.storm;

import java.io.IOException;
import java.util.Arrays;
import java.util.Map;
import java.util.UUID;

import org.apache.storm.guava.collect.Maps;
import org.apache.storm.redis.common.config.JedisPoolConfig;

import storm.kafka.BrokerHosts;
import storm.kafka.KafkaSpout;
import storm.kafka.SpoutConfig;
import storm.kafka.StringScheme;
import storm.kafka.ZkHosts;
import backtype.storm.Config;
import backtype.storm.StormSubmitter;
import backtype.storm.generated.AlreadyAliveException;
import backtype.storm.generated.InvalidTopologyException;
import backtype.storm.generated.StormTopology;
import backtype.storm.spout.Scheme;
import backtype.storm.spout.SchemeAsMultiScheme;
import backtype.storm.topology.TopologyBuilder;

public class SmartCarDriverTopology {


	public static void main(String[] args) throws AlreadyAliveException, InvalidTopologyException, InterruptedException, IOException {  

		StormTopology topology = makeTopology();

		Map&lt;String, String&gt; HBaseConfig = Maps.newHashMap();
		HBaseConfig.put("hbase.rootdir","hdfs://server01.hadoop.com:8020/hbase");

		Config config = new Config();
		config.setDebug(true);
		config.put("HBASE_CONFIG",HBaseConfig);

		config.put(Config.NIMBUS_HOST, "server01.hadoop.com");
		config.put(Config.NIMBUS_THRIFT_PORT, 6627);
		config.put(Config.STORM_ZOOKEEPER_PORT, 2181);
		config.put(Config.STORM_ZOOKEEPER_SERVERS, Arrays.asList("server02.hadoop.com"));

		StormSubmitter.submitTopology(args[0], config, topology);
	}  

	private static StormTopology makeTopology() {
		String zkHost = "server02.hadoop.com:2181";
		TopologyBuilder driverCarTopologyBuilder = new TopologyBuilder();
		
		// Spout Bolt
		BrokerHosts brkBost = new ZkHosts(zkHost);
		String topicName = "SmartCar-Topic";
		String zkPathName = "/SmartCar-Topic";

		SpoutConfig spoutConf = new SpoutConfig(brkBost, topicName, zkPathName, UUID.randomUUID().toString());
		spoutConf.scheme = new SchemeAsMultiScheme(new StringScheme());
		KafkaSpout kafkaSpout = new KafkaSpout(spoutConf);
		
		driverCarTopologyBuilder.setSpout("kafkaSpout", kafkaSpout, 1);
		
		// Grouping - SplitBolt &amp; EsperBolt
		driverCarTopologyBuilder.setBolt("splitBolt", new SplitBolt(),1).allGrouping("kafkaSpout");
		driverCarTopologyBuilder.setBolt("esperBolt", new EsperBolt(),1).allGrouping("kafkaSpout");
		
        // ⓵
		// HBase Bolt
		TupleTableConfig hTableConfig = new TupleTableConfig("DriverCarInfo", "r_key");
		hTableConfig.setZkQuorum("server02.hadoop.com");
		hTableConfig.setZkClientPort("2181");
		hTableConfig.setBatch(false);
		hTableConfig.addColumn("cf1", "date");
		hTableConfig.addColumn("cf1", "car_number");
		hTableConfig.addColumn("cf1", "speed_pedal");
		hTableConfig.addColumn("cf1", "break_pedal");
		hTableConfig.addColumn("cf1", "steer_angle");
		hTableConfig.addColumn("cf1", "direct_light");
		hTableConfig.addColumn("cf1", "speed");
		hTableConfig.addColumn("cf1", "area_number");
		
        // ⓶
		HBaseBolt hbaseBolt = new HBaseBolt(hTableConfig);

        // ⓷
		driverCarTopologyBuilder.setBolt("HBASE", hbaseBolt, 1).shuffleGrouping("splitBolt");
		
		// Redis Bolt
		String redisServer = "server02.hadoop.com";
		int redisPort = 6379;
		JedisPoolConfig jedisPoolConfig = new JedisPoolConfig.Builder().setHost(redisServer).setPort(redisPort).build();
		RedisBolt redisBolt = new RedisBolt(jedisPoolConfig);
		
		driverCarTopologyBuilder.setBolt("REDIS", redisBolt, 1).shuffleGrouping("esperBolt");

		return driverCarTopologyBuilder.createTopology();
	}
}  
</code></pre></div></div>

<ul>
  <li>⓵
    <ul>
      <li>HBase의 데이터를 적재하기 위한 Config 정보 설정</li>
      <li><strong>DriverCarInfo</strong>테이블에 <code class="language-plaintext highlighter-rouge">r_key</code>를 로우키로 정의</li>
      <li>칼럼 패밀리 <code class="language-plaintext highlighter-rouge">cf1</code>에 해당하는 8개의 칼럼명 (date, car_number, speed_pedal, break_pedal, steer_angle, direct_light, speed, area_number)의 정보와 Zookeeper 연결 정보도 정의</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li>설정한 HBase의 Config 정보(hTableConfig)를 이용해 HBaseBolt 객체 생성</li>
    </ul>
  </li>
  <li>⓷
    <ul>
      <li>HBaseBolt 객체를 스톰의 Topology에 설정</li>
      <li>‘고유 ID’, ‘HBaseBolt 객체’, ‘병렬 처리 힌트’ 설정</li>
      <li>SplitBolt로부터 데이터를 전달받기 위해 그루핑명을 SplitBolt의 ID인 <code class="language-plaintext highlighter-rouge">splitBolt</code>로 설정</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="4-에스퍼-bolt-기능-구현">4) 에스퍼 Bolt 기능 구현</h3>
<ul>
  <li>에스퍼 Bolt는 스마트카 운전자 가운데 과속을 하는 운전자를 찾아 이벤트를 발생시키는 기능</li>
  <li>에스퍼 Bolt의 이벤트 구현은 <strong>에스퍼 CEP 엔진</strong> 이용</li>
  <li>이때 EPL 쿼리로 30초 Window-Time 기준으로 평균 속도 80km/h를 초과한 운전자를 찾기 위한 룰 작성
    <blockquote>
      <p><code class="language-plaintext highlighter-rouge">EPL</code> : select, from, where, having 절 등을 갖는 기존 SQL과 유사한 질의 언어</p>
    </blockquote>
  </li>
  <li>
    <p>해당 차량 번호와 평균 속도를 초과한 시점의 시간 정보를 다음 Bolt에 전달</p>
  </li>
  <li>EsperBolt.java 전체 코드
```java
package com.wikibook.bigdata.smartcar.storm;</li>
</ul>

<p>import java.util.Map;</p>

<p>import backtype.storm.task.TopologyContext;
import backtype.storm.topology.BasicOutputCollector;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseBasicBolt;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Values;</p>

<p>import com.espertech.esper.client.Configuration;
import com.espertech.esper.client.EPServiceProvider;
import com.espertech.esper.client.EPServiceProviderManager;
import com.espertech.esper.client.EPStatement;
import com.espertech.esper.client.EventBean;
import com.espertech.esper.client.UpdateListener;</p>

<p>public class EsperBolt extends BaseBasicBolt{</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private static final long serialVersionUID = 1L;

private EPServiceProvider espService;

private boolean isOverSpeedEvent = false;

public void prepare(Map stormConf, TopologyContext context) {

	Configuration configuration = new Configuration();
	configuration.addEventType("DriverCarInfoBean", DriverCarInfoBean.class.getName());

	espService = EPServiceProviderManager.getDefaultProvider(configuration);
	espService.initialize();
	
	int avgOverSpeed = 80;
	int windowTime  = 30;
	
	String overSpeedEpl =  "SELECT date, carNumber, speedPedal, breakPedal, "
							+ "steerAngle, directLight, speed , areaNumber "
							+ " FROM DriverCarInfoBean.win:time_batch("+windowTime+" sec) "
							+ " GROUP BY carNumber HAVING AVG(speed) &gt; " + avgOverSpeed;

	EPStatement driverCarinfoStmt = espService.getEPAdministrator().createEPL(overSpeedEpl);

	driverCarinfoStmt.addListener((UpdateListener) new OverSpeedEventListener());
}



public void execute(Tuple tuple, BasicOutputCollector collector) {

	// TODO Auto-generated method stub
	String tValue = tuple.getString(0); 

	//발생일시(14자리), 차량번호, 가속페달, 브레이크페달, 운전대회적각, 방향지시등, 주행속도, 뮤직번호
	String[] receiveData = tValue.split("\\,");

	DriverCarInfoBean driverCarInfoBean =new DriverCarInfoBean();

	driverCarInfoBean.setDate(receiveData[0]);
	driverCarInfoBean.setCarNumber(receiveData[1]);
	driverCarInfoBean.setSpeedPedal(receiveData[2]);
	driverCarInfoBean.setBreakPedal(receiveData[3]);
	driverCarInfoBean.setSteerAngle(receiveData[4]);
	driverCarInfoBean.setDirectLight(receiveData[5]);
	driverCarInfoBean.setSpeed(Integer.parseInt(receiveData[6]));
	driverCarInfoBean.setAreaNumber(receiveData[7]);

	espService.getEPRuntime().sendEvent(driverCarInfoBean); 


	if(isOverSpeedEvent) {
		//발생일시(14자리), 차량번호
		collector.emit(new Values(	driverCarInfoBean.getDate().substring(0,8), 
									driverCarInfoBean.getCarNumber()+"-"+driverCarInfoBean.getDate()));
		isOverSpeedEvent = false;
	}

}

public void declareOutputFields(OutputFieldsDeclarer declarer) {
	// TODO Auto-generated method stub
	declarer.declare(new Fields("date", "car_number"));
}


private class OverSpeedEventListener implements UpdateListener
{
	@Override
	public void update(EventBean[] newEvents, EventBean[] oldEvents) {
		if (newEvents != null) {
			try {
				isOverSpeedEvent = true;
			} catch (Exception e) {
				System.out.println("Failed to Listener Update" + e);
			} 
		}
	}
}
</code></pre></div></div>

<p>}</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
&lt;br&gt;

- **에스퍼 Bolt 소스1 - EsperBolt.java에서 에스퍼의 EPL 쿼리 정의 및 이벤트 함수 등록**
```java
package com.wikibook.bigdata.smartcar.storm;

import java.util.Map;

import backtype.storm.task.TopologyContext;
import backtype.storm.topology.BasicOutputCollector;
import backtype.storm.topology.OutputFieldsDeclarer;
import backtype.storm.topology.base.BaseBasicBolt;
import backtype.storm.tuple.Fields;
import backtype.storm.tuple.Tuple;
import backtype.storm.tuple.Values;

import com.espertech.esper.client.Configuration;
import com.espertech.esper.client.EPServiceProvider;
import com.espertech.esper.client.EPServiceProviderManager;
import com.espertech.esper.client.EPStatement;
import com.espertech.esper.client.EventBean;
import com.espertech.esper.client.UpdateListener;


public class EsperBolt extends BaseBasicBolt{

	private static final long serialVersionUID = 1L;

	private EPServiceProvider espService;

	private boolean isOverSpeedEvent = false;

	public void prepare(Map stormConf, TopologyContext context) {

		Configuration configuration = new Configuration();
		configuration.addEventType("DriverCarInfoBean", DriverCarInfoBean.class.getName());

		espService = EPServiceProviderManager.getDefaultProvider(configuration);
		espService.initialize();
		
        // ⓵
		int avgOverSpeed = 80;
		int windowTime  = 30;
		
		String overSpeedEpl =  "SELECT date, carNumber, speedPedal, breakPedal, "
								+ "steerAngle, directLight, speed , areaNumber "
								+ " FROM DriverCarInfoBean.win:time_batch("+windowTime+" sec) "
								+ " GROUP BY carNumber HAVING AVG(speed) &gt; " + avgOverSpeed;

		EPStatement driverCarinfoStmt = espService.getEPAdministrator().createEPL(overSpeedEpl);

        // ⓶
		driverCarinfoStmt.addListener((UpdateListener) new OverSpeedEventListener());
	}
</code></pre></div></div>

<ul>
  <li>⓵
    <ul>
      <li>실시간으로 유입되는 스트림 데이터를 대상으로 매 30초 동안 평균 속도 80km/h를 초과한 스마트카 운전자를 감지하기 위한 에스퍼 EPL 쿼리 정의</li>
      <li>From절에서 <strong>Window-Time</strong>이라는 기능을 이용해 실시간 스트림 데이터를 <code class="language-plaintext highlighter-rouge">Group By</code>한 데이터를 메모리 상에 올려놓고 30초 단위로 평균 속도 계산</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li>⓵에서 정의한 EPL 쿼리 조건에 일치하는 데이터가 발생했을 때 호출될 이벤트 함수 작성</li>
      <li>함수명: <code class="language-plaintext highlighter-rouge">OverSpeedEventListener()</code></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<blockquote>
  <p><strong>에스퍼 EPL 동적 로딩</strong></p>
  <ul>
    <li>앞의 소스를 보면 에스퍼의 룰인 EPL을 EsperBolt.java에 직접 작성했음</li>
    <li>하지만, EPL은 업루 룰이 바뀔 때마다 빈번하게 수정되므로 프로그램 안에 직접 하드코딩하는 것은 좋은 방법이 아님</li>
    <li>실제 환경에서는 EPL 쿼리를 별도의 공유 저장소를 구축해 통합 보관하고, 스톰의 Bolt같은 프로그램이 이 저장소로부터 EPL 쿼리를 주기적으로 로딩하거나, 역으로 스톰의 Bolt로 푸시하는 아키텍처 구성함 <br />
<img src="img/CH05/e2.png" alt="" /></li>
    <li>위 그림을 보면 EPL의 공유 저장소를 카프카 또는 레디스로 만들고, EPL 수정이 발생하면 스톰의 Bolt가 공유 저장소로부터 EPL을 수신받아 동적으로 교체하는 방식으로 EPL 쿼리 관리</li>
  </ul>
</blockquote>

<p><br /></p>

<ul>
  <li><strong>에스퍼 Bolt 소스2 - EsperBolt.java의 에스퍼 이벤트 함수</strong>
```java
private class OverSpeedEventListener implements UpdateListener
  {
      @Override
      public void update(EventBean[] newEvents, EventBean[] oldEvents) {
          if (newEvents != null) {
              try {
                  isOverSpeedEvent = true;   // ⓵
              } catch (Exception e) {
                  System.out.println(“Failed to Listener Update” + e);
              } 
          }
      }
  }</li>
</ul>

<p>}</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- EPL로 정의한 이벤트 조건이 발생할 때 호출되는 OverSpeedEventLister() 함수
- ⓵ 
    - 이벤트 발생 시 에스퍼 Bolt의 멤버 변수인 `isOverSpeedEvent`를 `true`값으로 설정해서 해당 조건의 이벤트가 발생했음을 인지할 수 있게 함
- 에스퍼의 기능을 이용해 운전자의 실시간 운행 데이터를 처리하기 위한 모든 작업 마침

&lt;br&gt;

- Bolt의 고유 기능인 튜플로부터 데이터를 받아 처리하는 프로그램 소스
- **에스퍼 Bolt 소스3 - EsperBolt.java의 EPL 쿼리 정의 및 이벤트 함수 등록
```java
public void execute(Tuple tuple, BasicOutputCollector collector) {

		// ⓵
		String tValue = tuple.getString(0); 

		//발생일시(14자리), 차량번호, 가속페달, 브레이크페달, 운전대회적각, 방향지시등, 주행속도, 뮤직번호
		String[] receiveData = tValue.split("\\,");

        // ⓶
		DriverCarInfoBean driverCarInfoBean =new DriverCarInfoBean();

		driverCarInfoBean.setDate(receiveData[0]);
		driverCarInfoBean.setCarNumber(receiveData[1]);
		driverCarInfoBean.setSpeedPedal(receiveData[2]);
		driverCarInfoBean.setBreakPedal(receiveData[3]);
		driverCarInfoBean.setSteerAngle(receiveData[4]);
		driverCarInfoBean.setDirectLight(receiveData[5]);
		driverCarInfoBean.setSpeed(Integer.parseInt(receiveData[6]));
		driverCarInfoBean.setAreaNumber(receiveData[7]);

		espService.getEPRuntime().sendEvent(driverCarInfoBean); 

        // ⓷
		if(isOverSpeedEvent) {
			//발생일시(14자리), 차량번호
			collector.emit(new Values(	driverCarInfoBean.getDate().substring(0,8), 
										driverCarInfoBean.getCarNumber()+"-"+driverCarInfoBean.getDate()));
			isOverSpeedEvent = false;
		}

	}

	public void declareOutputFields(OutputFieldsDeclarer declarer) {
		// TODO Auto-generated method stub
		declarer.declare(new Fields("date", "car_number"));
	}
</code></pre></div></div>

<ul>
  <li>⓵
    <ul>
      <li>SplitBolt와 유사한 코드로, 튜플로부터 받은 데이터를 <code class="language-plaintext highlighter-rouge">,</code>로 분리해서 배열에 담음</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li>에스퍼에서 이벤트를 처리하기 위해 자바 VO(Value Object) 사용</li>
      <li>스마트카 운전자의 운행 정보를 객체화 한 <strong>DriverCarInfoBean</strong>이라는 VO를 생성하고, ⓵에서 분리한 운행 정보를 설정한 뒤 에스퍼 엔진에 등록</li>
    </ul>
  </li>
  <li>⓷
    <ul>
      <li>과속 이벤트가 발생하면 해당 데이터를 다음 Bolt로 전송</li>
      <li>이때 과속 <strong>발생일자</strong>와 <strong>과속 차량번호 + 타임스탬프</strong>를 데이터로 전송</li>
      <li>뒤에서 <strong>발생일자</strong>는 레디스의 키로 사용되고, <strong>과속 차량번호 + 타임스탬프</strong>는 Set 데이터 타입의 값으로 사용됨</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="5-레디스-bolt-기능-구현">5) 레디스 Bolt 기능 구현</h3>
<ul>
  <li>레디스 Bolt는 과속 차량의 데이터가 발생한 경우에만 작동</li>
  <li>레디스 서버에 <strong>과속 일자</strong>를 key로 하고, 과속한 운전자의 <strong>차량 번호 + 타임스탬프</strong> 데이터를 값으로 적재</li>
  <li>레디스 Bolt 구현의 핵심은 레디스 클라이언트 라이브러리인 <strong>제디스(Jedis)</strong></li>
</ul>

<p><br /></p>

<ul>
  <li>JedisPoolConfig를 이용한 RedisBolt 생성과 Topology 등록 방법</li>
  <li><strong>레디스 Bolt 생성 - SmartCarDriverTopology.java</strong>
    <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1">// ⓵</span>
  <span class="c1">// Redis Bolt</span>
  <span class="nc">String</span> <span class="n">redisServer</span> <span class="o">=</span> <span class="s">"server02.hadoop.com"</span><span class="o">;</span>
  <span class="kt">int</span> <span class="n">redisPort</span> <span class="o">=</span> <span class="mi">6379</span><span class="o">;</span>
  <span class="nc">JedisPoolConfig</span> <span class="n">jedisPoolConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">JedisPoolConfig</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">setHost</span><span class="o">(</span><span class="n">redisServer</span><span class="o">).</span><span class="na">setPort</span><span class="o">(</span><span class="n">redisPort</span><span class="o">).</span><span class="na">build</span><span class="o">();</span>
  <span class="nc">RedisBolt</span> <span class="n">redisBolt</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">RedisBolt</span><span class="o">(</span><span class="n">jedisPoolConfig</span><span class="o">);</span>
	
  <span class="c1">// ⓶</span>
  <span class="n">driverCarTopologyBuilder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"REDIS"</span><span class="o">,</span> <span class="n">redisBolt</span><span class="o">,</span> <span class="mi">1</span><span class="o">).</span><span class="na">shuffleGrouping</span><span class="o">(</span><span class="s">"esperBolt"</span><span class="o">);</span>

  <span class="k">return</span> <span class="n">driverCarTopologyBuilder</span><span class="o">.</span><span class="na">createTopology</span><span class="o">();</span>
</code></pre></div>    </div>
  </li>
  <li>⓵
    <ul>
      <li>레디스의 클라이언트를 이용하기 위해 JedisPoolConfig 설정</li>
      <li>레디스 서버 주소와 포트 정보를 Config로 설정하고, 해당 Config를 이용해 RedisBolt 객체 생성</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li>생성한 RedisBolt 객체를 스톰의 Topology에 등록</li>
      <li>‘고유 ID’, ‘RedisBolt 객체’, ‘병렬 처리 힌트’ 설정</li>
      <li>EsperBolt로부터 데이터를 전달받기 위해 그루핑명을 EsperBolt ID인 <code class="language-plaintext highlighter-rouge">esperBolt</code>로 설정</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>AbstractJedisBolt 클래스를 상속하고, 제디스 라이브러리를 이용하고 있는 RedisBolt 소스</li>
  <li><strong>레디스 Bolt 소스 - RedisBolt.java</strong></li>
</ul>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">package</span> <span class="nn">com.wikibook.bigdata.smartcar.storm</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.storm.redis.bolt.AbstractRedisBolt</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.storm.redis.common.config.JedisClusterConfig</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.storm.redis.common.config.JedisPoolConfig</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">redis.clients.jedis.JedisCommands</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">redis.clients.jedis.exceptions.JedisConnectionException</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">redis.clients.jedis.exceptions.JedisException</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">backtype.storm.topology.OutputFieldsDeclarer</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">backtype.storm.tuple.Tuple</span><span class="o">;</span>

<span class="kd">public</span>  <span class="kd">class</span> <span class="nc">RedisBolt</span> <span class="kd">extends</span> <span class="nc">AbstractRedisBolt</span> <span class="o">{</span>

	<span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="kt">long</span> <span class="n">serialVersionUID</span> <span class="o">=</span> <span class="mi">1L</span><span class="o">;</span>

	<span class="kd">public</span> <span class="nf">RedisBolt</span><span class="o">(</span><span class="nc">JedisPoolConfig</span> <span class="n">config</span><span class="o">)</span> <span class="o">{</span>
		<span class="kd">super</span><span class="o">(</span><span class="n">config</span><span class="o">);</span>
	<span class="o">}</span>

	<span class="kd">public</span> <span class="nf">RedisBolt</span><span class="o">(</span><span class="nc">JedisClusterConfig</span>  <span class="n">config</span><span class="o">)</span> <span class="o">{</span>
		<span class="kd">super</span><span class="o">(</span><span class="n">config</span><span class="o">);</span>
	<span class="o">}</span>


	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">execute</span><span class="o">(</span><span class="nc">Tuple</span> <span class="n">input</span><span class="o">)</span> <span class="o">{</span>

        <span class="c1">// ⓵</span>
		<span class="nc">String</span> <span class="n">date</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">getStringByField</span><span class="o">(</span><span class="s">"date"</span><span class="o">);</span>
		<span class="nc">String</span> <span class="n">car_number</span> <span class="o">=</span> <span class="n">input</span><span class="o">.</span><span class="na">getStringByField</span><span class="o">(</span><span class="s">"car_number"</span><span class="o">);</span>

        <span class="c1">// ⓶</span>
		<span class="nc">JedisCommands</span> <span class="n">jedisCommands</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>

		<span class="k">try</span> <span class="o">{</span>
            
			<span class="n">jedisCommands</span> <span class="o">=</span> <span class="n">getInstance</span><span class="o">();</span>
			<span class="n">jedisCommands</span><span class="o">.</span><span class="na">sadd</span><span class="o">(</span><span class="n">date</span><span class="o">,</span> <span class="n">car_number</span><span class="o">);</span>
			
			<span class="n">jedisCommands</span><span class="o">.</span><span class="na">expire</span><span class="o">(</span><span class="n">date</span><span class="o">,</span> <span class="mi">604800</span><span class="o">);</span>
        

		<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">JedisConnectionException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
			<span class="k">throw</span> <span class="k">new</span> <span class="nf">RuntimeException</span><span class="o">(</span><span class="s">"Exception occurred to JedisConnection"</span><span class="o">,</span> <span class="n">e</span><span class="o">);</span>
		<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">JedisException</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
			<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"Exception occurred from Jedis/Redis"</span> <span class="o">+</span> <span class="n">e</span><span class="o">);</span>
		<span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>

			<span class="k">if</span> <span class="o">(</span><span class="n">jedisCommands</span> <span class="o">!=</span> <span class="kc">null</span><span class="o">)</span> <span class="o">{</span>
				<span class="n">returnInstance</span><span class="o">(</span><span class="n">jedisCommands</span><span class="o">);</span>
			<span class="o">}</span>
			<span class="k">this</span><span class="o">.</span><span class="na">collector</span><span class="o">.</span><span class="na">ack</span><span class="o">(</span><span class="n">input</span><span class="o">);</span>
		<span class="o">}</span>
	<span class="o">}</span>

	<span class="nd">@Override</span>
	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">declareOutputFields</span><span class="o">(</span><span class="nc">OutputFieldsDeclarer</span> <span class="n">declarer</span><span class="o">)</span> <span class="o">{</span>
	<span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>⓵
    <ul>
      <li>튜플 타입인 <code class="language-plaintext highlighter-rouge">input</code> 객체에는 에스퍼 Bolt에서 전송한 과속 운전자의 <strong>과속날짜</strong>와 <strong>차량번호</strong> 데이터가 있음</li>
      <li>이 데이터를 String 타입의 <strong>date</strong>, <strong>car_number</strong> 변수에 각각 할당</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li>레디스 클라이언트 라이브러리인 <strong>JedisCommands</strong> 이용</li>
      <li>⓵에서 생성한 <strong>과속날짜(date)</strong>를 key로 하고, <strong>차량번호(car_number)</strong>를 set 타입의 값으로 해서 레디스 서버에 적재</li>
      <li>추가로 적재 데이터에 대한 만료 시간을 604800초(일주일)로 설정해서, 적재 후 일주일이 경과하면 해당 과속 운행 데이터는 영구적으로 삭제되게 함</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="6-레디스-클라이언트-애플리케이션-구현">6) 레디스 클라이언트 애플리케이션 구현</h3>
<p><img src="img/CH05/rca.png" alt="" /></p>
<ul>
  <li>앞서 레디스 Bolt에서 레디스 서버에 적재한 과속 차량 정보는 스피드 데이터로부터 추출된 유용한 정보</li>
  <li>이처럼 가치있는 실시간 정보는 주변 업무 시스템에서 바로 사용할 수 있어야 함</li>
</ul>

<p><br /></p>

<ul>
  <li>레디스 클라이언트 라이브러리인 제디스를 이용해 실시간 과속 차량 정보를 업무 시스템 입장에서 활용하는 예제</li>
  <li><strong>레디스 클라이언트 애플리케이션 - RedisClient.java</strong></li>
</ul>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">package</span> <span class="nn">com.wikibook.bigdata.smartcar.redis</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">java.util.Set</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">redis.clients.jedis.Jedis</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">redis.clients.jedis.JedisPool</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">redis.clients.jedis.JedisPoolConfig</span><span class="o">;</span>


<span class="kd">public</span> <span class="kd">class</span> <span class="nc">RedisClient</span> <span class="kd">extends</span> <span class="nc">Thread</span><span class="o">{</span>

	<span class="kd">private</span> <span class="nc">String</span> <span class="n">key</span><span class="o">;</span>
	<span class="kd">private</span> <span class="nc">Jedis</span> <span class="n">jedis</span><span class="o">;</span>

	<span class="kd">public</span> <span class="nf">RedisClient</span><span class="o">(</span><span class="nc">String</span> <span class="n">k</span><span class="o">)</span> <span class="o">{</span>

		<span class="nc">JedisPoolConfig</span> <span class="n">jedisPoolConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">JedisPoolConfig</span><span class="o">();</span>
		<span class="nc">JedisPool</span> <span class="n">jPool</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">JedisPool</span><span class="o">(</span><span class="n">jedisPoolConfig</span><span class="o">,</span> <span class="s">"server02.hadoop.com"</span><span class="o">,</span> <span class="mi">6379</span><span class="o">);</span>
		<span class="n">jedis</span> <span class="o">=</span> <span class="n">jPool</span><span class="o">.</span><span class="na">getResource</span><span class="o">();</span>

		<span class="k">this</span><span class="o">.</span><span class="na">key</span> <span class="o">=</span> <span class="n">k</span><span class="o">;</span>
	<span class="o">}</span>

	<span class="nd">@Override</span>    
	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">run</span><span class="o">()</span> <span class="o">{</span>
		
		<span class="nc">Set</span><span class="o">&lt;</span><span class="nc">String</span><span class="o">&gt;</span> <span class="n">overSpeedCarList</span> <span class="o">=</span> <span class="kc">null</span><span class="o">;</span>
		
		<span class="kt">int</span> <span class="n">cnt</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>

		<span class="k">try</span> <span class="o">{</span>
			<span class="k">while</span><span class="o">(</span><span class="kc">true</span><span class="o">)</span> <span class="o">{</span>

				<span class="n">overSpeedCarList</span> <span class="o">=</span> <span class="n">jedis</span><span class="o">.</span><span class="na">smembers</span><span class="o">(</span><span class="n">key</span><span class="o">);</span>

				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"################################################"</span><span class="o">);</span>
				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"#####   Start of The OverSpeed SmartCar    #####"</span><span class="o">);</span>
				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"################################################"</span><span class="o">);</span>
				
				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"\n[ Try No."</span> <span class="o">+</span> <span class="n">cnt</span><span class="o">++</span> <span class="o">+</span> <span class="s">"]"</span><span class="o">);</span>

                <span class="c1">// ⓵</span>
				<span class="k">if</span><span class="o">(</span><span class="n">overSpeedCarList</span><span class="o">.</span><span class="na">size</span><span class="o">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
					<span class="k">for</span> <span class="o">(</span><span class="nc">String</span> <span class="n">list</span> <span class="o">:</span> <span class="n">overSpeedCarList</span><span class="o">)</span> <span class="o">{</span>
						<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">list</span><span class="o">);</span>
					<span class="o">}</span>
					<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">""</span><span class="o">);</span>
					
					<span class="n">jedis</span><span class="o">.</span><span class="na">del</span><span class="o">(</span><span class="n">key</span><span class="o">);</span>
                    
				<span class="o">}</span><span class="k">else</span><span class="o">{</span>

                    <span class="c1">// ⓶</span>
					<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"\nEmpty Car List...\n"</span><span class="o">);</span>
				<span class="o">}</span>

				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"################################################"</span><span class="o">);</span>
				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"######   End of The OverSpeed SmartCar    ######"</span><span class="o">);</span>
				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"################################################"</span><span class="o">);</span>
				<span class="nc">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"\n\n"</span><span class="o">);</span>

				<span class="nc">Thread</span><span class="o">.</span><span class="na">sleep</span><span class="o">(</span><span class="mi">10</span> <span class="o">*</span> <span class="mi">1000</span><span class="o">);</span>
			<span class="o">}</span>

		<span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="nc">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
			<span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
		<span class="o">}</span> <span class="k">finally</span> <span class="o">{</span>
			<span class="k">if</span><span class="o">(</span> <span class="n">jedis</span> <span class="o">!=</span> <span class="kc">null</span> <span class="o">)</span> <span class="n">jedis</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
		<span class="o">}</span>
	<span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>⓵
    <ul>
      <li>레디스에는 날짜를 key로 해서 과속 차량의 데이터셋이 저장되어 있음</li>
      <li>key(날짜)에 해당하는 과속 차량 정보가 발생하면 즉시 가져와서 출력</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li>레디스에서 가져온 key의 데이터 삭제</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="3-hbase-테이블-생성">3. HBase 테이블 생성</h2>
<ul>
  <li>파일럿 플젝에서 수집한 운전자의 모든 운행 정보는 HBase에 적재됨</li>
  <li>아래 코드는 스톰의 HBase-Bolt 관련 소스코드를 일부 발췌한 것으로, 수신받은 튜플 데이터(운전자 데이터)를 HBase에 모두 적재</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>HBase의 HTable 구성 정보 - SmartCarDriverTopology.java</strong>
    <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// HBase Bolt</span>
  <span class="nc">TupleTableConfig</span> <span class="n">hTableConfig</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">TupleTableConfig</span><span class="o">(</span><span class="s">"DriverCarInfo"</span><span class="o">,</span> <span class="s">"r_key"</span><span class="o">);</span>  <span class="c1">// ⓵</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">setZkQuorum</span><span class="o">(</span><span class="s">"server02.hadoop.com"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">setZkClientPort</span><span class="o">(</span><span class="s">"2181"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">setBatch</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
                       <span class="c1">// ⓶      ⓷</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"date"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"car_number"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"speed_pedal"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"break_pedal"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"steer_angle"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"direct_light"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"speed"</span><span class="o">);</span>
  <span class="n">hTableConfig</span><span class="o">.</span><span class="na">addColumn</span><span class="o">(</span><span class="s">"cf1"</span><span class="o">,</span> <span class="s">"area_number"</span><span class="o">);</span>
		
  <span class="nc">HBaseBolt</span> <span class="n">hbaseBolt</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">HBaseBolt</span><span class="o">(</span><span class="n">hTableConfig</span><span class="o">);</span>
  <span class="n">driverCarTopologyBuilder</span><span class="o">.</span><span class="na">setBolt</span><span class="o">(</span><span class="s">"HBASE"</span><span class="o">,</span> <span class="n">hbaseBolt</span><span class="o">,</span> <span class="mi">1</span><span class="o">).</span><span class="na">shuffleGrouping</span><span class="o">(</span><span class="s">"splitBolt"</span><span class="o">);</span>
</code></pre></div>    </div>
  </li>
  <li>⓵
    <ul>
      <li>실시간 데이터를 적재할 HBase 테이블명 <code class="language-plaintext highlighter-rouge">DriverCarInfo</code>와 로우키명 <code class="language-plaintext highlighter-rouge">r_key</code> 설정</li>
    </ul>
  </li>
  <li>⓶
    <ul>
      <li><code class="language-plaintext highlighter-rouge">DriverCarInfo</code> 테이블에서 사용하는 칼럼 패밀리명 <code class="language-plaintext highlighter-rouge">cf1</code> 설정</li>
    </ul>
  </li>
  <li>⓷
    <ul>
      <li>칼럼 패밀리명 <code class="language-plaintext highlighter-rouge">cf1</code>에서 사용할 필드명 설정</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>위의 코드가 정상적으로 실행되려면 설정한 HBase 테이블(DriverCarInfo), 로우키(r_key), 칼럼패밀리(cf1)가 HBase 서버 상에 생성되어 있어야 함</li>
  <li>Sever02에 접속해 아래 명령을 실행하고, <code class="language-plaintext highlighter-rouge">CREATE, Table Name: default: DriverCarInfo..</code> 메시지 출력되는지 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hbase org.apache.hadoop.hbase.util.RegionSplitter DriverCarInfo HexStringSplit <span class="nt">-c</span> 4 <span class="nt">-f</span> cf1
</code></pre></div>    </div>
  </li>
  <li>해당 명령은 HBase에 DriverCarInfo 테이블 생성</li>
  <li>RegionSplitter를 이용했고, 칼럼패밀리로 <code class="language-plaintext highlighter-rouge">cf1</code>을 사용하는 24개의 Region을 미리 생성하기 위한 옵션 지정함</li>
  <li>이때 4개의 Region에 접근하는 방식은 로우키의 HexString 값을 이용하도록</li>
  <li>이처럼 테이블의 Region을 미리 분리해놓는 이유: 초기 대량 데이터 발생을 고려해 여러 개의 Region을 미리 만들어 성능과 안정성을 확보할 수 있기 때문</li>
  <li>또한, Region이 특정 크기에 도달하면 자동으로 분리(샤딩)되는데, 이러한 분리 과정에서 서비스가 일시적으로 중단되는 현상도 미연에 방지할 수 있음
<img src="img/CH05/hbase%20%ED%85%8C%EC%9D%B4%EB%B8%94%20%EC%83%9D%EC%84%B1.png" alt="" /></li>
</ul>

<p><br /></p>

<h2 id="4-스톰-topology-배포">4. 스톰 Topology 배포</h2>
<p><img src="img/CH05/%EC%8B%A4%EC%8B%9C%EA%B0%84%EC%A0%81%EC%9E%AC%EA%B8%B0%EB%8A%A5.png" alt="" /></p>
<ul>
  <li>스톰 Topology는 위 그림에 나와있는 Spout, Bolt의 구성과 동작 방식 등을 정의한 하나의 자바 프로그램</li>
</ul>

<p><br /></p>

<ul>
  <li>스톰 Topology 작성이 완료되면 <strong>Nimbus</strong>를 통해 해당 Topology가 <strong>Supervisor</strong>에 배포되고, Supervisor의 <strong>worker</strong> 위에 실시간 데이터를 처리하기 위한 스톰의 런타임 환경이 생성됨</li>
</ul>

<p><br /></p>

<h3 id="운전자의-실시간-운행-정보-처리하는-스톰-topology-배포"><strong>운전자의 실시간 운행 정보 처리하는 스톰 Topology 배포</strong></h3>
<h4 id="1-스톰에서-사용하는-자바-프로그램-소스를-미리-컴파일해서-패키징한-파일---server02에-업로드">1) 스톰에서 사용하는 자바 프로그램 소스를 미리 컴파일해서 패키징한 파일 -&gt; Server02에 업로드</h4>
<ul>
  <li>파일질라 사용</li>
</ul>

<p><br /></p>

<h4 id="2-업로드한-파일에-포함된-스톰의-topology-파일을-storm-명령을-통해-drivercarinfo라는-이름으로-배포">2) 업로드한 파일에 포함된 스톰의 Topology 파일을 storm 명령을 통해 <strong>DriverCarInfo</strong>라는 이름으로 배포</h4>
<ul>
  <li>배포하기 전 스톰 Nimbus, Supervisor, Ui 서버가 정상 실행 중인지 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working   
storm jar bigdata.smartcar.storm-1.0.jar com.wikibook.bigdata.smartcar.storm.SmartCarDriverTopology DriverCarInfo
</code></pre></div>    </div>
  </li>
  <li>마지막에 <code class="language-plaintext highlighter-rouge">o.a.s.StormSubmitter - Finishd submitting topology: DriverCarInfo</code> 메시지 출력되는지 확인
<img src="img/CH05/%EC%8A%A4%ED%86%B0%20topology%20%ED%8C%8C%EC%9D%BC%20%EB%B0%B0%ED%8F%AC1.png" alt="" />
<img src="img/CH05/%EC%8A%A4%ED%86%B0%20topology%20%ED%8C%8C%EC%9D%BC%20%EB%B0%B0%ED%8F%AC2.png" alt="" /></li>
</ul>

<p><br /></p>

<h4 id="3-스톰-관리자-ui로-topology가-정상적으로-배포되었는지-확인">3) 스톰 관리자 UI로 Topology가 정상적으로 배포되었는지 확인</h4>
<ul>
  <li>
    <p>Topology summary의 DriverCarInfo라는 Topology가 활성화되었는지 확인 <br />
http://server02.hadoop.com:8088
<img src="img/CH05/%EC%8A%A4%ED%86%B0%20topology%20%EB%B0%B0%ED%8F%AC%20%ED%99%95%EC%9D%B8.png" alt="" /></p>
  </li>
  <li>[DriverCarInto Topology]를 들어가면 Topology뿐 아니라, 카프카-Spout, 에스퍼-Bolt, 레디스-Bolt 등의 상태 모니터링 가능</li>
  <li>[Show Visualization] 클릭하면 배포한 Topology의 구조부터 데이터 처리량 실시간으로 모니터링 가능</li>
</ul>

<p><br /></p>

<h4 id="4-스톰-topology-제거해야-할-경우-다음-kill-명령-이용">4) 스톰 Topology 제거해야 할 경우 다음 <code class="language-plaintext highlighter-rouge">kill</code> 명령 이용</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>storm <span class="nb">kill</span> <span class="s2">"Topology 이름"</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="5-실시간-적재-기능-테스트">5. 실시간 적재 기능 테스트</h2>
<ul>
  <li>실시간 적재 기능 테스트를 위해 스마트카 운전자의 실시간 운행정보를 발생시키는 로그 시뮬레이터 작동</li>
  <li>해당 로그 파일을 플럼이 수집해서 카프카에 전송하고, 스톰이 다시 수신받아 모든 운행 데이터를 HBase에 적재</li>
  <li>그 중 에스퍼의 속도 위반 룰에 감지된 차량은 레디스로 적재</li>
</ul>

<p><br /></p>

<h3 id="1-로그-시뮬레이터-작동">1) 로그 시뮬레이터 작동</h3>
<ul>
  <li>로그 시뮬레이터가 설치되어 있는 Server02에 접속해서 <strong>DriverLogMain</strong>작동</li>
  <li>2016년 1월 3일 10대의 스마트카 운전자 정보만 생성해 테스트</li>
  <li>로그가 생성됨과 동시에 플럼의 수집 이벤트가 작동하면 <strong>플럼 -&gt; 카프카 -&gt; 스톰 -&gt; HBase</strong> 순으로 데이터 수집 및 적재됨
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working
java <span class="nt">-cp</span> bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20160103 10 &amp;
</code></pre></div>    </div>
    <p><img src="img/CH05/driverlogmain%20%EC%9E%91%EB%8F%99.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>운전자의 실시간 로그가 정상적으로 발생하는지 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working/driver-realtime-log
<span class="nb">tail</span> <span class="nt">-f</span> SmartCarDriverInfo.log
</code></pre></div>    </div>
    <p><img src="img/CH05/%EC%9A%B4%EC%A0%84%EC%9E%90%20%EC%8B%A4%EC%8B%9C%EA%B0%84%20%EB%A1%9C%EA%B7%B8%20%EB%B0%9C%EC%83%9D.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<h3 id="2-hbase-적재-데이터-확인">2) HBase 적재 데이터 확인</h3>
<h4 id="1-hbase-쉘의-count명령으로-실시간으로-적재되고-있는-운전자-정보-확인">1) HBase 쉘의 <code class="language-plaintext highlighter-rouge">count</code>명령으로 실시간으로 적재되고 있는 운전자 정보 확인</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hbase shell
hbase<span class="o">(</span>main<span class="o">)</span>:001:0&gt; count <span class="s1">'DriverCarInfo'</span>
</code></pre></div></div>
<ul>
  <li>DriverCarInfo 테이블에 적재된 데이터의 로우 수를 1000 단위로 출력
<img src="img/CH05/%EC%8B%A4%EC%8B%9C%EA%B0%84%20%EC%A0%81%EC%9E%AC%20%EC%9A%B4%EC%A0%84%EC%9E%90%20%EC%A0%95%EB%B3%B4%20%ED%99%95%EC%9D%B8.png" alt="" /></li>
  <li><code class="language-plaintext highlighter-rouge">count</code> 명령에 따른 row 값을 보면 <strong>Split Bolt</strong>에서 구현한 대로 로우키 값이 <strong>타임스탬프-리버스값 + 차량번호</strong> 형식으로 적재된 것을 볼 수 있음</li>
</ul>

<p><br /></p>

<h4 id="2-scan-명령으로-drivercarinfo-테이블에-적재된-칼럼-기반-구조의-데이터-살펴보기">2) <code class="language-plaintext highlighter-rouge">scan</code> 명령으로 DriverCarInfo 테이블에 적재된 칼럼 기반 구조의 데이터 살펴보기</h4>
<ul>
  <li>그냥 scan 명령을 내리면 모든 데이터가 조회되므로 <code class="language-plaintext highlighter-rouge">LIMIT</code> 옵션으로 20개만 조회
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hbase<span class="o">(</span>main<span class="o">)</span>:001:0&gt; scan <span class="s1">'DriverCarInfo;, {LIMIT=&gt;20}
</span></code></pre></div>    </div>
    <p><img src="img/CH05/%EC%BB%AC%EB%9F%BC%20%EA%B8%B0%EB%B0%98%20%EB%8D%B0%EC%9D%B4%ED%84%B0%2020%EA%B0%9C%EB%A7%8C.png" alt="" /></p>
  </li>
  <li>HBase의 칼럼 기반 테이블 구조로 되어있음</li>
</ul>

<p><br /></p>

<ul>
  <li>표로 표현하면 아래와 같음
<img src="img/CH05/hbase%20%ED%91%9C.png" alt="" /></li>
  <li>로우키와 칼럼패밀리(cf1)을 기준으로 <strong>RowKey -&gt; Column -&gt; Family -&gt; Field -&gt; Version -&gt; Value</strong> 순으로 데이터 봄</li>
  <li><code class="language-plaintext highlighter-rouge">Version</code>은 표에는 없지만, Filed의 Value 데이터가 바뀔 때마다 타임스탬프를 통해 버전 관리</li>
  <li>칼럼 패밀리를 여러 개로 생성해서 특징이 유사한 칼럼들을 그루핑해서 데이터를 관리할 수도 있음</li>
</ul>

<p><br /></p>

<ul>
  <li>표시된 데이터 중 특정 로우키 하나를 선택해서 scan 명령의 조건절 추가해보기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scan <span class="s1">'DriverCarInfo'</span>, <span class="o">{</span><span class="nv">STARTROW</span><span class="o">=&gt;</span><span class="s1">'00012230106102-X0005'</span>, <span class="nv">LIMIT</span><span class="o">=&gt;</span>1<span class="o">}</span>
</code></pre></div>    </div>
    <p><img src="img/CH05/scan%20%EC%A1%B0%EA%B1%B4%EC%A0%88%20%EC%B6%94%EA%B0%80.png" alt="" /></p>
  </li>
  <li><strong>car_number</strong>: X0005 -&gt; 스마트카 차량 번호가 X0005인 운전자의</li>
  <li><strong>date</strong>: 20160103221000 -&gt; 2016년 1월 3일 22시 10분 00초 운행 정보는</li>
  <li><strong>speed</strong>: 20 -&gt; 시속 20km/h로 주행</li>
  <li><strong>speed_pedal</strong>: 0 -&gt; 가속 페달을 밟지 않은 상태</li>
  <li><strong>steer_angle</strong>: F -&gt; 핸들은 직진 중</li>
  <li><strong>break_pedal</strong>: 1 -&gt; 브레이크 페달을 1단계 진행</li>
  <li><strong>direct_light</strong>: N -&gt; 깜박이는 켜지 않은 상태</li>
  <li><strong>area_number</strong>: D01 -&gt; D01 지역을 운행</li>
</ul>

<p><br /></p>

<ul>
  <li>2016년 1월 3일 E08 지역을 운행했던 모든 스마트카 운전자의 차량번호와 지역번호 출력</li>
  <li>날짜 조건 이용 방법) 테이블의 타임스탬프 이용 / 날짜 필드 직접 이용 / <strong>로우키에 포함된 날짜 정보 이용</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>scan <span class="s1">'DriverCarInfo'</span>, <span class="o">{</span><span class="nv">COLUMNS</span><span class="o">=&gt;[</span><span class="s1">'c1:car_number'</span>, <span class="s1">'cf1:area_number'</span><span class="o">]</span>, <span class="nv">FILTER</span><span class="o">=&gt;</span><span class="s2">"RowFilter(=, 'regexstring:30106102') AND SingleColumnValueFilter('cf1', 'area_number', =, 'regexstring:E08')"</span><span class="o">}</span>
</code></pre></div>    </div>
    <p><img src="img/CH05/scan%20%EC%A1%B0%EA%B1%B4%EC%A0%882.png" alt="" /></p>
  </li>
</ul>

<blockquote>
  <p>hbase&gt; scan ‘table 이름’, {COLUMNS=&gt;[‘패밀리이름:컬럼이름’, ‘패밀리이름:컬럼이름’], FILTER=&gt;”ROWFILTER(=, ‘regexstring:30106102’) AND SingleCloumnValueFilter(‘cf1’, ‘area_number’, =, ‘regexstring:E08’)”} <br />
COLUMNS: 조회할 컬럼 선택 <br />
FILTER: 이용할 필터 <br />
ROWFILTER: Row Key에서 부분문자열 조회 -&gt; row key에 ‘30106102’가 포함된 데이터만 조회 <br />
SingleColumnValueFilter: value 기반으로 매칭하여 cell 반환 -&gt; area_number가 E08인 데이터만 조회</p>
</blockquote>

<p><br /></p>

<ul>
  <li>HBase 웹관리자에 접속해서 적재한 데이터가 앞서 실행했던 <code class="language-plaintext highlighter-rouge">Pre-Split</code> 명령에 의해 2개의 HRegionServer로 골고루 분산 적재됐는지 확인 <br />
http://server02.hadoop.com:16010/</li>
</ul>

<p><br /></p>

<h3 id="3-레디스에-적재된-데이터-확인">3) 레디스에 적재된 데이터 확인</h3>
<ul>
  <li>레디스에는 스마트카 운전자 중 과속한 차량의 정보 들어있음</li>
  <li>스톰의 에스퍼 Bolt에서 에스퍼의 EPL을 이용해 일자별로 과속한 스마트카를 찾아내는 기능 구현했음</li>
  <li><strong>레디스 CLI의 <code class="language-plaintext highlighter-rouge">smembers</code> 명령을 통해 실시간 과속 차량 정보 확인</strong></li>
  <li>아래와 같이 server02에서 <strong>201601013</strong>을 키로 set 데이터 타입으로 적재되어있는 과속 차량 리스트 조회
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>redis-cli
<span class="o">&gt;</span> smembers 20160103
</code></pre></div>    </div>
    <p><img src="img/CH05/redis_%EA%B3%BC%EC%86%8D%ED%95%9C%20%EC%9A%B4%EC%A0%84%EC%9E%90%20-%20%EB%82%A0%EC%A7%9C%EB%A1%9C%20%EC%A1%B0%ED%9A%8C.png" alt="" /></p>
  </li>
  <li>3대의 스마트카 차량이 과속한 것을 감지</li>
</ul>

<p><br /></p>

<h3 id="4-레디스-클라이언트-애플리케이션-작동">4) 레디스 클라이언트 애플리케이션 작동</h3>
<ul>
  <li>레디스 클라이언트 애플리케이션은 레디스로부터 2016년 1월 3일에 발생되는 과속 차량 정보를 10초 간격으로 가져오는 프로그램</li>
  <li>파일질라로 bigdata.smartcar.redis-1.0.jar 파일을 server02의 /home/pilot-pjt/working 디렉터리에 업로드</li>
</ul>

<p><br /></p>

<ul>
  <li>server02에 접속하여 애플리케이션 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working
java <span class="nt">-cp</span> bigdata.smartcar.redis-1.0.jar com.wikibook.bigdata.smartcar.redis.OverSpeedCarInfo 20160103
</code></pre></div>    </div>
    <p><img src="img/CH05/redis%20%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8%20%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%20%EC%9E%91%EB%8F%99.png" alt="" /></p>
  </li>
  <li>차량번호 ‘X0005’, ‘W0010’번에 해당하는 스마트카 두 대가 각각 ‘2016년 1월 3일 22시 25분 12초’, ‘2016년 1월 3일 23일 54분 28초’, ‘2016년 1월 3일 22시 14분 56초’에 과속 위반 차량으로 발견됨</li>
  <li>10초 뒤인 [Try No.2]에서는 과속 차량이 발견되지 않음</li>
  <li>해당 애플리케이션을 계속 실행해두면 스톰 및 에스퍼에서 발견한 과속 차량을 실시간으로 감지해서 레디스로부터 가져오게 됨</li>
</ul>

<p><br /></p>

<ul>
  <li>로그 시뮬레이터 종료
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ps <span class="nt">-ef</span> | <span class="nb">grep </span>smartcar.log
<span class="nb">kill</span> <span class="nt">-9</span> <span class="o">[</span>pid] <span class="o">[</span>pid]
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<h3 id="5-실시간-개발-환경-구성">5) 실시간 개발 환경 구성</h3>
<ul>
  <li>파일럿 프로젝트의 프로그램 개발 환경 구성</li>
  <li>[이클립스] 실행 - C://예제소스/bigdata2nd-mastere/workspace/bigdata.smartcar.strom 경로 열기</li>
  <li><strong>메이븐(Maven)</strong> 프로젝트 import됨</li>
</ul>

<p><br /></p>

<ul>
  <li>com.wikibook.bigdata.smartcar.storm 패키지의 <strong>EsperBolt.java</strong> 파일 선택</li>
  <li>37-44번째 줄을 보면 에스퍼의 EPL 쿼리 볼 수 있음</li>
  <li>SQL과 유사하지만, 42번째 줄의 From 절에서 에스퍼 EPL만의 독특한 함수 볼 수 있음
<img src="img/CH05/esperbolt.java%20%EC%88%98%EC%A0%95.png" alt="" /></li>
  <li>EPL 쿼리를 보면 차량변호 별로 그루핑해서 최근 30초 동안 평균 속도가 80km/h를 초과한 운전자를 찾는 것</li>
  <li><code class="language-plaintext highlighter-rouge">int avgOverSpeed</code> 변수 값을 수정해서 과속 기준 속도를 변경할 수 있음</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>메이븐의 <code class="language-plaintext highlighter-rouge">install</code> 명령을 통해 수정한 소스 빌드하고 패킹</strong></li>
  <li>[Package Explorer] - pom.xml 파일 열기</li>
  <li>상단 메뉴의 [Run] - [Run As] - [Maven install] 메뉴 선택
<img src="img/CH05/maven_install%20%EC%8B%A4%ED%96%89.png" alt="" /></li>
  <li>아래 콘솔창에서 <code class="language-plaintext highlighter-rouge">BUILD SUCCESS</code> 메시지 확인
<img src="img/CH05/maven%20%EC%84%A4%EC%B9%98%EC%99%84%EB%A3%8C.png" alt="" /></li>
  <li>오류 메시지가 뜬다면 현재 파일럿 PC에 맞는 자바 런타임 환경 정보로 수정 필요</li>
</ul>

<p><br /></p>

<ul>
  <li>빌드가 끝나면 target 디렉터리 밑에 bigdata.smartcar.strom-1.0.jar 파일이 생성될 것 -&gt; server02의 /home/pilot-pjt/working 디렉터리에 업로드</li>
  <li>스톰 Topology 재배포
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>storm <span class="nb">kill </span>DriverCarInfo
storm jar bigdata.smartcar.storm-1.0.jar com.wikibook.bigdata.smartcar.storm.SmartCarDriverTopology DriverCarInfo
</code></pre></div>    </div>
    <p><img src="img/CH05/storm%20topology%20%EC%9E%AC%EB%B0%B0%ED%8F%AC.png" alt="" /></p>
  </li>
</ul>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[1. 실시간 적재 환경 구성 1) HBase 설치 CM 홈 - [서비스 추가] - [HBase] 선택 - [계속]]]></summary></entry><entry><title type="html">[pilot] Ch4. 빅데이터 적재 이론</title><link href="http://localhost:4000/hadoop/2023/09/22/ch4.html" rel="alternate" type="text/html" title="[pilot] Ch4. 빅데이터 적재 이론" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T05:00:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/ch4</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/ch4.html"><![CDATA[<p>[출처: 실무로 배우는 빅데이터 기술, 김강원 저]</p>

<p><br /></p>

<h2 id="1-빅데이터-적재-개요">1. 빅데이터 적재 개요</h2>

<ul>
  <li>CH03에서 수집한 데이터를 어디에, 어떻게 저장할 것인가</li>
  <li>수집한 데이터의 특징에 따라 처리 방식과 적재 위치가 달라질 수 있음</li>
</ul>

<p><br /></p>

<ul>
  <li>데이터 발생 주기에 따라 <strong>일괄 배치성 데이터</strong>인지, <strong>실시간 스트림 데이터</strong>인지</li>
  <li>데이터 형식에 따라 가공 처리나 사전 검증 작업을 할 것인지</li>
  <li>적재한 데이터를 어떤 비즈니스 요건에서 활용하느냐에 따라 적재 대상 위치가 달라질 수도 있음 -&gt; 분산 파일, NoSQL, 메모리 캐시 등으로 구분해서 저장</li>
</ul>

<p><img src="img/CH04/%EC%A0%81%EC%9E%AC1.png" alt="" /></p>

<p><img src="img/CH04/적재2.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>적재는 빅데이터 시스템의 중심에 위치해 중요한 만큼, 관련 SW가 다양하면서 기술 복잡도도 매우 높음</li>
  <li>CH04에서는 일 단위로 만들어지는 스마트카의 상태 정보 로그 파일(약 100MB) 적재</li>
  <li>CH05에서는 스마트카 운전자의 실시간 운행 정보인 실시간 로그(약 4K/1건) 분석 적재</li>
</ul>

<p><br /></p>

<ul>
  <li>이번 장에서는 대용량 로그 파일의 적재 다룸</li>
</ul>

<p><br /></p>

<h2 id="2-하둡">2. 하둡</h2>
<h3 id="1-하둡-소개">1) 하둡 소개</h3>
<ul>
  <li>빅데이터의 에코시스템들은 대부분 하둡을 위해 존재하고 하둡에 의존해서 발전해 가고 있다해도 과언이 아닐 정도로 빅데이터의 핵심 소프트웨어임</li>
  <li>하둡의 두 가지 기능
    <ul>
      <li>대용량 데이터 분산 저장</li>
      <li>분산 저장된 데이터를 가공/분석 처리</li>
    </ul>
  </li>
</ul>

<h3 id="2-하둡의-맵리듀스">2) 하둡의 맵리듀스</h3>
<ul>
  <li>분산 병렬 처리에서의 핵심
    <ul>
      <li>여러 컴퓨터에 분산 저장되어 있는 데이터로부터 어떻게 효율적으로 일을 나눠서 실행시킬 수 있느냐</li>
      <li>여러 컴퓨터가 나눠서 실행한 결과들을 어떻게 하나로 모으냐</li>
    </ul>
  </li>
  <li>이를 쉽고 편리하게 지원하는 프레임워크: <strong>하둡의 맵리듀스(MapReduce)</strong></li>
  <li>분산 컴퓨팅 기술을 이해하는 중요한 열쇠</li>
</ul>

<p><br /></p>

<p><img src="img/CH04/%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4.png" alt="" /></p>

<p>1) 고객정보가 담긴 1GB의 파일을 100MB 파일 10개로 나눠서 10대의 서버(하둡 데이터노드)에 분산 저장 (나눠진 100MB 파일을 블록 파일이라 부르며, 일반적으로 128MB 블록 단위로 처리)   <br />
2) 전체 고객정보에서 VIP 고객의 평균 연봉 조회 쿼리 실행 -&gt; 10대의 서버에 분산 저장된 100MB의 고객정보 파일로부터 Map 프로그램이 각각 생성  <br />
3) 실행된 Map 프로그램은 100MB의 고객정보 파일에서 VIP 고객정보만 추출한 후, 작아진 파일(2~8MB) 크기로 Server-11(Reduce)로 전송   <br />
4) Server-11에서 Reduce 프로그램이 실행되어 Server-01(Map01) ~ Server-10(Map02)이 전송한 VIP 고객정보를 merge(50MB)해 평균을 구하고 결과 파일(1KB) 생성</p>

<p><br /></p>

<ul>
  <li>1~4의 과정은 대용량 데이터에 대한 처리를 여러 대의 서버들이 나누어 작업함으로써 한 대의 고성능 서버가 처리하기 힘든 작업을 신속하게 처리</li>
  <li>맵리듀스 프로그램에서는 내부적으로 Split, Spill, Sort, Partition, Fetch, Shuffle, Merge 등 다양한 메커니즘들이 작동하며, 이 과정을 잘 이해하고 있어야 분산 환경에서 발생하는 다양한 문제에 빠르게 대처할 수 있음</li>
</ul>

<p><br /></p>

<h3 id="3-하둡의-기본-요소">3) 하둡의 기본 요소</h3>

<table>
  <thead>
    <tr>
      <th>구성요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DataNode</td>
      <td>블록(64MB / 128MB 등) 단위로 분할된 대용량 파일들이 DataNode의 디스크에 저장 및 관리</td>
    </tr>
    <tr>
      <td>NameNode</td>
      <td>DataNode에 저장된 파일들의 메타 정보를 메모리 상에서 로드해서 관리</td>
    </tr>
    <tr>
      <td>EditsLog</td>
      <td>파일들의 변경 이력(수정, 삭제 등) 정보가 저장되는 로그 파일</td>
    </tr>
    <tr>
      <td>FsImage</td>
      <td>NameNode의 메모리 상에 올라와 있는 메타 정보를 스냅샷 이미지로 만들어 생성한 파일</td>
    </tr>
    <tr>
      <td>[Ver.1.x] SecondaryNameNode</td>
      <td>NameNode의 FsImage와 EditsLog 파일을 주기적으로 유지 관리해주는 체크포인팅 노드</td>
    </tr>
    <tr>
      <td>[Ver.1.x] MapReduce v1</td>
      <td>DataNode에 분산 저장된 파일이 스플릿(Map)되어 다양한 연산을 수행한 뒤, 그 결과를 다시 병합(Reduce)하는 분산 프로그래밍 기법</td>
    </tr>
    <tr>
      <td>[Ver.1.x] JobTracker</td>
      <td>맵리듀스의 job을 실행하면서 태스크에 할당하고, 전체 job에 대해 리소스 분배 및 스케줄링</td>
    </tr>
    <tr>
      <td>[Ver.1.x] TaskTracker</td>
      <td>JobTracker가 요청한 맵리듀스 프로그램이 실행되는 태스크 <br /> 이때 맵 태스크와 리듀스 태스크가 생성됨</td>
    </tr>
    <tr>
      <td>[Ver.2.x] Active/Stand-By NameNode</td>
      <td>NameNode를 이중화하여 서비스 중인 Active NameNode와 실패 처리를 대비한 Standby NameNode로 구성</td>
    </tr>
    <tr>
      <td>[Ver.2.x] MapReduce v2 / YARN</td>
      <td>하둡 클러스터 내의 자원을 중앙 관리하고, 그 위에 다양한 애플리케이션을 실행 및 관리가 가능하도록 확장성과 호환성을 높인 하둡 2.x의 플랫폼</td>
    </tr>
    <tr>
      <td>[Ver.2.x] ResourceManager</td>
      <td>하둡 클러스터 내의 자원을 중앙 관리하면서, 작업 요청시 스케줄링 정책에 따라 자원을 분배해서 실행시키고 모니터링</td>
    </tr>
    <tr>
      <td>[Ver.2.x] NodeManager</td>
      <td>하둡 클러스터의 DataNode마다 실행되면서 Container를 실행시키고 라이프 사이클을 관리</td>
    </tr>
    <tr>
      <td>[Ver.2.x] Container</td>
      <td>DataNode의 사용 가능한 리소스를 Container 단위로 할당해서 구성</td>
    </tr>
    <tr>
      <td>[Ver.2.x] ApplicationManager</td>
      <td>애플리케이션이 실행되면 생성됨 <br /> NodeManager에게 애플리케이션이 실행될 Container를 요청하고, 그 위에서 애플리케이션 실행 및 관리</td>
    </tr>
    <tr>
      <td>[Ver.2.x] JournalNode</td>
      <td>3개 이상의 노드로 구성되어 EditsLog를 각 노드에 복제 관리 <br /> Active NameNode는 EditsLog에 쓰기만을 수행하고, Standby NameNode는 읽기만을 실행</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="4-하둡-아키텍처">4) 하둡 아키텍처</h3>

<h4 id="1-하둡-1x-버전">1) 하둡 1.x 버전</h4>
<p><img src="img/CH04/%ED%95%98%EB%91%A11.jpg" alt="" /></p>

<ul>
  <li>클라이언트에서 하둡에 파일 읽기/쓰기를 할 때는 우선 NameNode를 참조해서 파일읅 읽기/쓰기 할 DataNode 정보 전달받음</li>
  <li>클라이언트는 해당 정보를 이용해 DataNode에 직접 연결하여 파일 읽기/쓰기</li>
  <li>하둡에 적재된 데이터를 분석해야 할 때는 클라이언트가 JobTracker에게 맵리듀스 실행 요청</li>
  <li>JobTracker가 스케줄링 정책에 따라 작업할 DataNode / TaskTracker 선정</li>
</ul>

<p><br /></p>

<ul>
  <li>선정된 TaskTracker에 맵리듀스 프로그램이 전달되어 저장된 파일들을 이용해 맵리듀스 작업 실행됨</li>
  <li>하지만, 하둡 1.x 아키텍처에는 여러 문제점이 있는데, 그중 하나가 NameNode의 이중화 기능 미지원으로 SPOF가 존재한다는 점
    <ul>
      <li><code class="language-plaintext highlighter-rouge">SPOF</code> (단일 고장점) : 시스템 구성 요소 중에서 동작하지 않으면 전체 시스템이 중단되는 요소</li>
      <li>하둡에서 SPOF는 NameNode</li>
      <li>NameNode가 정상적으로 작동하지 않으면 모든 클라이언트가 HDFS에 접근 불가 -&gt; 모든 작업이 중지되고 파일을 읽거나 쓸 수 없게 됨</li>
      <li>NameNode 파일 시스템 이미지에 HDFS의 디렉터리 구조와 파일 위치가 저장되어 있기 때문에, 문제가 생기면 블록에 접근할 수 있는 통로가 사라짐</li>
    </ul>
  </li>
</ul>

<h4 id="2-하둡-2x-버전">2) 하둡 2.x 버전</h4>
<p><img src="img/CH04/%ED%95%98%EB%91%A12.jpg" alt="" /></p>

<p><br /></p>

<ul>
  <li>1.x 아키텍처의 문제점을 개선하기 위한 다양한 컴포넌트 교체 및 추가</li>
  <li>클라이언트가 DataNode로부터 파일을 읽고 쓰기 전에 NameNode를 참조하게 되는데, 이때 1.x 버전과 다르게 <code class="language-plaintext highlighter-rouge">Active</code>/<code class="language-plaintext highlighter-rouge">Standby</code>로 이중화 되어있음을 알 수 있음</li>
  <li>또한, NameNode의 메모리에서 관리되는 파일들의 네임스페이스 정보를 주기적으로 관리하기 위해 <code class="language-plaintext highlighter-rouge">JournalNode</code>가 추가되었고, <code class="language-plaintext highlighter-rouge">주키퍼</code>까지 사용됨</li>
</ul>

<p><br /></p>

<ul>
  <li>가장 큰 변화는 JobTracker, TaskTracker 대신 <code class="language-plaintext highlighter-rouge">Resource Manager</code>, <code class="language-plaintext highlighter-rouge">Node Manager</code>가 생긴 것</li>
  <li><code class="language-plaintext highlighter-rouge">Resource Manager</code>는 Node Manager의 리소스 현황들을 종합적으로 수집해가며 작업 실행을 위한 최적의 DataNode를 찾아주어 효율적인 잡 스케줄링 가능해짐 <br />
+ 1.x에서 발생했던 DataNode의 리소스 불균형 현상 문제도 해결</li>
  <li><code class="language-plaintext highlighter-rouge">NodeManager</code>의 Container, Application Master는 1.x의 맵리듀스 잡 외에도 다양한 애플리케이션을 DataNode에서 실행 및 관리할 수 있게 확장됨</li>
  <li>이렇게 변화된 하둡 2.x 플랫폼을 <code class="language-plaintext highlighter-rouge">YARN</code>이라고 함</li>
</ul>

<p><br /></p>

<h3 id="5-하둡-활용-방안">5) 하둡 활용 방안</h3>
<ul>
  <li>파일럿 프로젝트에서의 하둡의 역할 <br />
<img src="img/CH04/%ED%95%98%EB%91%A1%ED%99%9C%EC%9A%A9%EB%B0%A9%EC%95%88.jpg" alt="" /></li>
</ul>

<p><br /></p>

<ul>
  <li>스마트카 상태 정보 로그
    <ul>
      <li>비교적 큰 크기의 파일로서, <code class="language-plaintext highlighter-rouge">HDFS</code>의 특정 디렉터리에 <strong>일자</strong> 단위로 파티션해서 적재</li>
      <li>이렇게 일 단위로 분리 적재된 데이터는 일/주/월/년 별로 스마트카의 다양한 시계열 집계 분석 효율적으로 수행 가능</li>
      <li>데이터를 재적재해야 하는 경우, 전체 데이터가 아닌 해당 파티션의 데이터만 재적재할 수 있다는 장점이 있음</li>
    </ul>
  </li>
  <li>파일럿 환경에서는 이러한 일련의 작업을 처리하기 위해 주로 <code class="language-plaintext highlighter-rouge">하이브</code> 이용</li>
  <li>대규모 하이브 작업에서는 분산 병렬 처리를 위해 <code class="language-plaintext highlighter-rouge">맵리듀스</code> 프로세스가 내부적으로 작동</li>
  <li>하이브에서 처리된 결과는 다시 <code class="language-plaintext highlighter-rouge">HDFS</code>의 특정 영역(Hive Data Warehouse)에 저장되고, 이 데이터를 스마트카의 고급 분석으로까지 확장해서 사용</li>
</ul>

<p><br /></p>

<h2 id="3-주키퍼">3. 주키퍼</h2>
<h3 id="1-주키퍼-소개">1) 주키퍼 소개</h3>
<ul>
  <li>수십~수천 대의 서버에 설치되어 있는 빅데이터 분산 환경을 더욱 효율적으로 관리하기 위해서는 서버 간의 정보를 쉽고 안전하게 공유해야 함</li>
  <li><code class="language-plaintext highlighter-rouge">아파치 주키퍼</code>: 공유된 정보를 이용해 서버 간의 중요한 이벤트를 관리하며 상호작용을 조율해주는 코디네이터 시스템 (분산 코디네이터)
    <ul>
      <li>이벤트: 분산 락, 순서 제어, 부하 분산, 네임서비스 등</li>
    </ul>
  </li>
  <li>주키퍼는 하둡, HBase, 카프카, 스톰 등의 분산 노드 관리에 사용 중</li>
</ul>

<h3 id="2-주요-구성-요소">2) 주요 구성 요소</h3>

<table>
  <thead>
    <tr>
      <th>주요 구성 요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Client</td>
      <td>주키퍼의 ZNode에 담긴 데이터에 대한 쓰기, 읽기, 삭제 등의 작업을 요청하는 클라이언트</td>
    </tr>
    <tr>
      <td>ZNode</td>
      <td>주키퍼 서버에 생성되는 파일시스템의 디렉터리 개념 <br /> 클라이언트의 요청 정보를 계층적으로 관리 <br /> (버전, 접근 권한, 상태, 모니터링 객체 관리 등의 기능 지원)</td>
    </tr>
    <tr>
      <td>Ensemble</td>
      <td>3대 이상의 주키퍼 서버를 하나의 클러스터로 구성한 HA 아키텍처</td>
    </tr>
    <tr>
      <td>Leader Server</td>
      <td>Ensemble 안에는 유일한 리더 서버가 선출되어 존재 <br /> 클라이언트의 요청을 받은 서버는 해당 요청을 리더 서버에게 전달하고, 리더 서버는 모든 팔로워 서버에게 클라이언트 요청이 전달되도록 보장</td>
    </tr>
    <tr>
      <td>Follwer Server</td>
      <td>Ensemble 안에서 한 대의 리더 서버를 제외한 나머지 서버 <br /> 리더 서버와 메시지를 주고받으면서 ZNode의 데이터를 동기화하고, 리더 서버에 문제가 발생할 경우 내부적으로 새로운 리더를 선출하는 역할 수행</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="3-주키퍼-아키텍처">3) 주키퍼 아키텍처</h3>
<ul>
  <li>주키퍼는 3대 이상의 <strong>홀수 개</strong>의 서버로 구성되어야 함</li>
  <li>그 중 1대는 반드시 <strong>리더 서버</strong>가 되고, 나머지 서버는 <strong>팔로워 서버</strong>가 됨</li>
  <li>팔로워 서버 1에 저장된 ZNode 정보는 리더 서버에 전달되고, 리더 서버는 다른 모든 팔로워 서버에 요청받은 ZNode 정보를 브로드캐스트</li>
</ul>

<p><br /></p>

<h3 id="4-주키퍼-활용-방안">4) 주키퍼 활용 방안</h3>
<ul>
  <li>파일럿 프로젝트에서는 주키퍼를 직접적으로 활용하지 않음</li>
  <li>하지만, 사용되는 하둡, HBase, 카프카, 스톰 내부에서 주키퍼에 의존해 클러스터 멤버십 기능 및 환경설정의 동기화 등 사용 -&gt; 중요한 SW!</li>
</ul>

<p><br /></p>

<h2 id="4-적재-아키텍처">4. 적재 아키텍처</h2>
<h3 id="1-적재-요구사항">1) 적재 요구사항</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">요구사항 1</code> : 차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태 점검</li>
  <li><code class="language-plaintext highlighter-rouge">요구사항 2</code> : 운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행 패턴 분석</li>
</ul>

<p><br /></p>

<ul>
  <li>이번 장에서는 요구사항 1에 대해 집중적으로 다룰 것</li>
  <li>주요 기술 요소로 하둡, 플럼 활용할 것</li>
  <li>이를 통해 스마트카 데이터 안전하게 수집/적재</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>요구사항 구체화 및 분석</strong></li>
</ul>

<table>
  <thead>
    <tr>
      <th>적재 요구사항 구체화</th>
      <th>분석 및 해결 방안</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1. 100대에 달하는 스마트카들의 상태 정보가 일 단위로 취합되어 제공됨</td>
      <td>플럼에서 수집 발생 시점의 날짜를 HdfsSink에 전달해서 해당 날짜 단위로 적재</td>
    </tr>
    <tr>
      <td>2. 매일 100대의 스마트카 상태 정보는 약 100MB 정도이며, 220만 건의 상태 정보가 발생함</td>
      <td>1년 적재 시 8억 건 이상의 데이터가 적재되며, 연 단위 분석에 하둡의 병렬 처리 사용</td>
    </tr>
    <tr>
      <td>3. 스마트카의 상태 정보 데이터의 발생일과 수집/적재되는 날짜가 다를 수 있음</td>
      <td>수집/적재되는 모든 데이터마다 데이터 발생일 외에 수집/적재 처리되어야 하는 처리일 추가</td>
    </tr>
    <tr>
      <td>4. 적재된 스마트카들의 상태 정보를 일/월/년 단위로 분석할 수 있어야 함</td>
      <td>HDFS에 수집 일자별로 디렉터리 경로를 만들어서 적재</td>
    </tr>
    <tr>
      <td>5. 적재 및 생성되는 파일은 HDFS의 특성을 잘 고려해야 함</td>
      <td>플럼의 HdfsSink의 옵션을 파일럿 프로젝트의 HDFS에 최적화해서 설정</td>
    </tr>
    <tr>
      <td>6. 적재가 완료된 후에는 원천 파일이 삭제되어야 함</td>
      <td>플럼의 Source 컴포넌트 중 SpoolDir의 DeletePolicy 옵션을 활용</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="2-적재-아키텍처">2) 적재 아키텍처</h3>
<p><img src="img/CH04/collection%20arch.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>플럼의 Source 컴포넌트로 대용량 파일을 읽어들이고, Sink를 이용해 HDFS의 특정 경로에 적재하는 구성</li>
  <li>HDFS에 적재할 때는 데이터의 포맷, 경로, 파티션 값을 신중하게 설정해야 함
    <ul>
      <li>데이터 적재 정책에 따라 뒤에서 이어질 탐색/분석을 위한 후처리 작업량과 복잡도가 달라질 수 있기 때문</li>
    </ul>
  </li>
  <li>HDFS에 적재된 데이터는 부분 수정/삭제가 어렵기 때문에 유형에 따라 특별한 관리 정책이 필요</li>
  <li>시계열 형식의 트랜잭션(거래, 이력 등) 데이터는 일자별 파티션 폴더를 구성해 파티션 단위로 데이터 적재 및 수정</li>
  <li>마스터(고객정보, 상품정보 등) 데이터는 상대적으로 크기가 작아 전체 데이터셋을 교체해 버리는 방식 주로 이용</li>
  <li>이러한 데이터 관리 정책을 통해 초기 적재 레이어에는 원천을 그대로 유지하며 <strong>데이터 레이크</strong>라 불리는 영역을 만들게 되고, 이후 데이터 가공 작업으로 데이터의 품질을 높이며 <strong>빅데이터 웨어하우스</strong>와 <strong>마트</strong>를 구성</li>
</ul>

<p><br /></p>

<h4 id="1-플럼의-hdfs-sink">1) 플럼의 HDFS Sink</h4>
<ul>
  <li>플럼에서 가장 중요한 컴포넌트</li>
  <li>플럼의 Source에서 읽어들인 데이터를 하둡에 적재해야 하는데, 이때 플럼의 HDFS Sink에서 다양한 옵션과 기능들을 사용할 수 있음</li>
</ul>

<p><br /></p>

<ul>
  <li>아키텍처 그림에서 ⓵)
    <ul>
      <li>HDFS Sink의 기본 기능은 수집한 데이터를 HDFS의 특정 경로에 적재하는 것</li>
      <li>적재할 때 사용될 파일 타입, 파일명, 배치 크기, 생성 파일 크기 등의 정보를 설정</li>
      <li>이때 사용하는 옵션은 주변의 환경과 요구사항에 따라 최적화해야 하는데, 수집되는 데이터 양과 주기, 포맷, 향후 분석 형태 등을 고려해 설정</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h4 id="2-hdfs의-파티션-적재">2) HDFS의 파티션 적재</h4>
<ul>
  <li>HDFS의 적재 경로를 하이브에서 인지할 수 있는 특정한 구분값(날짜, 시간, 코드 등)으로 파니셔닝함</li>
</ul>

<p><br /></p>

<ul>
  <li>아키텍처 그림에서 ⓶)
    <ul>
      <li>파이션은 주로 날짜별 디렉터리로 만들어 관리하는데, 업무코드 + 날짜를 조합해서 고유한 파티션 경로를 구성함</li>
      <li>향후 적재한 데이터를 하이브에서 사용하는데, 데이터 조회 시 전체 파일을 스캔하지 않고 파티션 조건에 해당하는 디렉터리만 직접 참조하고 수정할 수 있어 효율성이 좋아짐</li>
      <li>유사한 기능으로 하이브의 버킷도 있음</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="5-적재-환경-구성">5. 적재 환경 구성</h2>
<p><img src="img/CH04/collection2.png" alt="" /></p>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[[출처: 실무로 배우는 빅데이터 기술, 김강원 저]]]></summary></entry><entry><title type="html">[pilot] Ch4. 빅데이터 적재 실습</title><link href="http://localhost:4000/hadoop/2023/09/22/ch4(2).html" rel="alternate" type="text/html" title="[pilot] Ch4. 빅데이터 적재 실습" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T05:10:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/ch4(2)</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/ch4(2).html"><![CDATA[<h2 id="1-하둡-설치">1. 하둡 설치</h2>
<ul>
  <li>이미 CH02에서 CM을 통해 설치 완료</li>
  <li>하둡은 수집, 적재, 처리, 분석의 전 영역에 걸쳐 모든 컴포넌트와 연결되어 설치 구성됨</li>
</ul>

<p><br /></p>

<ul>
  <li>하둡 웹 관리 화면 <br />
http://server01.hadoop.com:9870  <br />
<img src="img/CH04/%ED%95%98%EB%91%A1%20%EC%83%81%ED%83%9C%20%EC%A0%95%EB%B3%B4%20%ED%99%95%EC%9D%B8.png" alt="" /></li>
</ul>

<p><br /></p>

<ul>
  <li>하둡 웹 관리 화면은 CM 홈에서 [HDFS] 선택 후, 상단의 [NameNode 웹 UI] 메뉴로 접근할 수 있음</li>
  <li>하둡 클러스터의 오버뷰와 각종 설정들의 요약 정보가 메인 화면에서 제공됨
    <ul>
      <li>전체 용량, 사용률, 활성/비활성 노드, 네임노드 상태, 저널노드 상태 등)</li>
    </ul>
  </li>
  <li>상단의 데이터노드 메뉴등을 통해 다양한 하둡 클러스터 정보 확인 가능</li>
</ul>

<p><br /></p>

<ul>
  <li>추가로 하둡은 주요 리소스를 관리 및 모니터링할 수 있는 웹 UI 제공</li>
  <li>파일럿 환경의 잡 히스토리 서버는 VM의 비정상 종료 및 리소스 부족 현상 등으로 셧다운이 자주 발생함</li>
  <li>잡 모니터링 관련 기능에 문제가 발생할 경우 CM 홈의 [YARN (MR2 Include)] -&gt; [인스턴스]에서 JobHistory Server 상태가 <strong>시작됨</strong> 상태인지 확인하고, 정지 상태이면 재시작</li>
</ul>

<p><br /></p>

<p><a href="http://server01.hadoop.com:8088/cluster">리소스 매니저</a>
<a href="http://server01.hadoop.com:19888/jobhistory">Job History</a></p>

<p><br /></p>

<ul>
  <li>파일럿 환경에서 SW 설치가 진행될 때마다 CM의 모니터링이 각 서버들의 인스턴스에서 자원 부족 및 클록 오프셋 경고 메시지 등을 표시</li>
  <li>파일럿 환경에서는 크게 문제될 상황은 아니지만, 일단 클록 오프셋을 조정해 경고 메시지를 줄일 수 있음</li>
  <li>클록 오프셋 조정
    <ul>
      <li>CM 홈 상단 [호스트] -&gt; [모든 호스트] -&gt; 우측 상단의 [구성]</li>
      <li>검색창에 ‘클록 오프셋’ 입력</li>
      <li>경고/심각 항목에 모두 <code class="language-plaintext highlighter-rouge">안함</code>으로 섧정한 후 저장</li>
    </ul>
  </li>
  <li>클록 오프셋 외에도 다양한 경고 메시지가 표시될 때, 파일럿 환경에 맞춰 임계값을 수정해 경고 메시지를 없앨 수 있음</li>
</ul>

<p><br /></p>

<h2 id="2-적재-기능-구현">2. 적재 기능 구현</h2>
<h3 id="1-smartcar-에이전트-수정">1) SmartCar 에이전트 수정</h3>
<ul>
  <li>CM 홈 - [Flume] - [구성]</li>
  <li>CH03에서 만든 SmartCar_Agent의 구성 파일에서 Logger Sink의 구성 요소들을 HDFS Sink로 교체</li>
</ul>

<p><img src="img/CH04/flume%20%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C%20%EA%B5%90%EC%B2%B4.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>수정할 기존 Logger Sink
```conf
vSmartCar_Agent.sources  = SmartCarInfo_SpoolSource DriverCarInfo_TailSource
SmartCar_Agent.channels = SmartCarInfo_Channel DriverCarInfo_Channel
SmartCar_Agent.sinks    = SmartCarInfo_HdfsSink DriverCarInfo_KafkaSink  #1</li>
</ul>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000</p>

<p>#2
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors = timeInterceptor typeInterceptor collectDayInterceptor filterInterceptor</p>

<p>#3
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.timeInterceptor.type = timestamp
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.timeInterceptor.preserveExisting = true</p>

<p>#4
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.typeInterceptor.type = static
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.typeInterceptor.key = logType
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.typeInterceptor.value = car-batch-log</p>

<p>#5
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.collectDayInterceptor.type = com.wikibook.bigdata.smartcar.flume.CollectDayInterceptor$Builder</p>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.type = regex_filter
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.regex = ^\d{14}
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.excludeEvents = false</p>

<p>SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory
SmartCar_Agent.channels.SmartCarInfo_Channel.capacity  = 100000
SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity  = 10000</p>

<p>#6
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.type = hdfs
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.path = /pilot-pjt/collect/%{logType}/wrk_date=%Y%m%d
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.filePrefix = %{logType}
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.fileSuffix = .log
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.fileType = DataStream
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.writeFormat = Text
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.batchSize = 10000
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.rollInterval = 0
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.rollCount = 0
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.idleTimeout = 100
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.callTimeout = 600000
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.rollSize = 67108864
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.threadsPoolSize = 10</p>

<p>#7
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.channel = SmartCarInfo_Channel</p>

<p>SmartCar_Agent.sources.DriverCarInfo_TailSource.type = exec
SmartCar_Agent.sources.DriverCarInfo_TailSource.command = tail -F /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log
SmartCar_Agent.sources.DriverCarInfo_TailSource.restart = true
SmartCar_Agent.sources.DriverCarInfo_TailSource.batchSize = 1000</p>

<p>SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors = filterInterceptor2
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.type = regex_filter
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.regex = ^\d{14}
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.excludeEvents = false</p>

<p>SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.topic = SmartCar-Topic
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.brokerList = server02.hadoop.com:9092
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.requiredAcks = 1
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.batchSize = 1000</p>

<p>SmartCar_Agent.channels.DriverCarInfo_Channel.type = memory
SmartCar_Agent.channels.DriverCarInfo_Channel.capacity= 100000
SmartCar_Agent.channels.DriverCarInfo_Channel.transactionCapacity = 10000</p>

<p>SmartCar_Agent.sources.DriverCarInfo_TailSource.channels = DriverCarInfo_Channel
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.channel = DriverCarInfo_Channel</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- #1
    - HDFS Sink 정보를 설정하기 위한 SmartCarInfo_HdfsSink 리소스 선언
- #2
    - 3개의 Interceptor 추가
    - 타임스탬프를 활용하기 위한 `timeInterceptor`
    - 로그 유형에 해당하는 상수값을 정의하기 위한 `typeInterceptor`
    - 수집 일자를 추가하기 위한 `collectDayInterceptor`
- #3
    - timeInterceptor의 설정
    - 타임스탬프 Interceptor를 추가하면, 플럼의 이벤트 헤더에 현재 타임 스탬프가 설정되어 필요시 헤더로부터 타임스탬프 값을 가져와 활용할 수 있음
- #4
    - typeInterceptor의 설정
    - 플럼의 해당 이벤트 내에서 사용할 상수를 선언하고 값을 설정
    - `logType` 이라는 상수를 선언했고, 값은 "car-batch-log"로 설정했음
- #5
    - collectDayInterceptor의 설정
    - 플럼 이벤트 바디에 수집된 당일의 작업 날짜(YYYYMMDD)를 추가하기 위한 Interceptor
    - 플럼에서 기본으로 제공하는 Interceptor가 아닌, 이번 파일럿 프로젝트를 위해 추가로 개발한 사용자 정의 Interceptor

&lt;br&gt;

- collectDayInterceptor
```java
package com.wikibook.bigdata.smartcar.flume;

import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.List;

import org.apache.flume.Context;
import org.apache.flume.Event;
import org.apache.flume.interceptor.Interceptor;


public class CollectDayInterceptor implements Interceptor {


	public CollectDayInterceptor(){
	}

	@Override
	public void initialize() {

	}

	@Override
	public Event intercept(Event event) {

		String eventBody = new String(event.getBody()) + "," + getToDate();
		event.setBody(eventBody.getBytes());
		return event;

	}


	@Override
	public void close() {
	}

	
	@Override
	public List&lt;Event&gt; intercept(List&lt;Event&gt; events)
	{
		for (Event event:events) {
			intercept(event);
		}
		return events;
	}
	

	public static class Builder implements Interceptor.Builder
	{
		@Override
		public void configure(Context context) {
		}

		@Override
		public Interceptor build() {
			return new CollectDayInterceptor();
		}
	}

	public  String getToDate() {

		long todaytime;
		SimpleDateFormat day;
		String toDay;

		todaytime = System.currentTimeMillis(); 
		day = new SimpleDateFormat("yyyyMMdd");

		toDay =  day.format(new Date(todaytime));

		return toDay;

	}
}
</code></pre></div></div>

<p><br /></p>

<ul>
  <li>#6
    <ul>
      <li>HDFS Sink의 상세 설정 값</li>
      <li>앞서 등록한 Interceptor의 값을 활용해 HDFS의 경로를 동적으로 파티션하는 “path” 설정과, 적재 시 HDFS에 생성되는 파일명의 규칙, 파일의 크기(64MB) 등 정의</li>
    </ul>
  </li>
  <li>#7
    <ul>
      <li>HDFS Sink인 <code class="language-plaintext highlighter-rouge">SmartCarInfo_HdfsSink</code>를 Memory Channel인 <code class="language-plaintext highlighter-rouge">SmartCarInfo_Channel</code>과 연결</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="3-적재-기능-테스트">3. 적재 기능 테스트</h2>
<h3 id="1-플럼의-사용자-정의-interceptor-추가">1) 플럼의 사용자 정의 Interceptor 추가</h3>
<ul>
  <li>사용자 정의 Interceptor인 <code class="language-plaintext highlighter-rouge">collectDayInterceptor</code>를 플럼의 <strong>Library</strong> 디렉터리에 추가</li>
  <li>‘파일질라’ 사용</li>
</ul>

<h3 id="2-플럼의-conf-파일-수정">2) 플럼의 Conf 파일 수정</h3>
<ul>
  <li>
    <p>플럼의 Conf 파일을 HDFS에 적재하는 Sink 구조로 변경</p>
  </li>
  <li>
    <p>CM 홈 - [Flume] - [구성] - ‘구성 파일’
```conf
SmartCar_Agent.sources  = SmartCarInfo_SpoolSource DriverCarInfo_TailSource
SmartCar_Agent.channels = SmartCarInfo_Channel DriverCarInfo_Channel
SmartCar_Agent.sinks    = SmartCarInfo_HdfsSink DriverCarInfo_KafkaSink</p>
  </li>
</ul>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.type = spooldir
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.spoolDir = /home/pilot-pjt/working/car-batch-log
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.deletePolicy = immediate
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.batchSize = 1000</p>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors = timeInterceptor typeInterceptor collectDayInterceptor filterInterceptor</p>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.timeInterceptor.type = timestamp
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.timeInterceptor.preserveExisting = true</p>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.typeInterceptor.type = static
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.typeInterceptor.key = logType
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.typeInterceptor.value = car-batch-log</p>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.collectDayInterceptor.type = com.wikibook.bigdata.smartcar.flume.CollectDayInterceptor$Builder</p>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.type = regex_filter
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.regex = ^\d{14}
SmartCar_Agent.sources.SmartCarInfo_SpoolSource.interceptors.filterInterceptor.excludeEvents = false</p>

<p>SmartCar_Agent.channels.SmartCarInfo_Channel.type = memory
SmartCar_Agent.channels.SmartCarInfo_Channel.capacity  = 100000
SmartCar_Agent.channels.SmartCarInfo_Channel.transactionCapacity  = 10000</p>

<p>SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.type = hdfs
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.path = /pilot-pjt/collect/%{logType}/wrk_date=%Y%m%d
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.filePrefix = %{logType}
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.fileSuffix = .log
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.fileType = DataStream
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.writeFormat = Text
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.batchSize = 10000
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.rollInterval = 0
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.rollCount = 0
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.idleTimeout = 100
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.callTimeout = 600000
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.rollSize = 67108864
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.hdfs.threadsPoolSize = 10</p>

<p>SmartCar_Agent.sources.SmartCarInfo_SpoolSource.channels = SmartCarInfo_Channel
SmartCar_Agent.sinks.SmartCarInfo_HdfsSink.channel = SmartCarInfo_Channel</p>

<p>SmartCar_Agent.sources.DriverCarInfo_TailSource.type = exec
SmartCar_Agent.sources.DriverCarInfo_TailSource.command = tail -F /home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log
SmartCar_Agent.sources.DriverCarInfo_TailSource.restart = true
SmartCar_Agent.sources.DriverCarInfo_TailSource.batchSize = 1000</p>

<p>SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors = filterInterceptor2
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.type = regex_filter
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.regex = ^\d{14}
SmartCar_Agent.sources.DriverCarInfo_TailSource.interceptors.filterInterceptor2.excludeEvents = false</p>

<p>SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.type = org.apache.flume.sink.kafka.KafkaSink
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.topic = SmartCar-Topic
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.brokerList = server02.hadoop.com:9092
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.requiredAcks = 1
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.batchSize = 1000</p>

<p>SmartCar_Agent.channels.DriverCarInfo_Channel.type = memory
SmartCar_Agent.channels.DriverCarInfo_Channel.capacity= 100000
SmartCar_Agent.channels.DriverCarInfo_Channel.transactionCapacity = 10000</p>

<p>SmartCar_Agent.sources.DriverCarInfo_TailSource.channels = DriverCarInfo_Channel
SmartCar_Agent.sinks.DriverCarInfo_KafkaSink.channel = DriverCarInfo_Channel</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- 변경 내용 저장 후 플럼 재시작

&lt;br&gt;

### 3) SmartCar 로그 시뮬레이터 작동
- CH04에서는 스마트카의 상태 정보 로그 파일을 하둡에 적재
- 2개의 시뮬레이터 중 **CarLogMain.java**만 작동시켜 2016년 1월 1일 날짜의 스마트카 상태 정보 로그 파일 생성

&lt;br&gt;

1) Server02에 SSH로 접속하고, bigdata.smartcar.loggen-1.0.jar가 위치한 경로인 /home/pilot-pjt/working 으로 이동
```bash
cd /home/pilot-pjt/working
</code></pre></div></div>

<p><br /></p>

<p>2) 스마트카 로그 시뮬레이터를 아래의 자바 명령으로 백그라운드 방식으로 실행</p>
<ul>
  <li>2016-01-01의 100대의 스마트카 상태 정보 로그 생성
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20160101 100 &amp;
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<p>3) /home/pilot-pjt/working/SmartCar 경로에 SmartCarStatusInfo_20160101.txt 파일 생성됐는지 확인</p>
<ul>
  <li>2016년 1월 1일 날짜로 100대의 스마트카 상태 정보가 기록된 것을 확인할 수 있음</li>
  <li>최종 로그 파일의 크기는 100MB이고, 생성되기까지 1~2분 정도 걸림</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working/SmartCar
<span class="nb">tail</span> <span class="nt">-f</span> SmartCarStatusInfo_20160101.txt
</code></pre></div></div>

<p><img src="img/CH04/hdfs%20%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%B9%B4%20%EC%83%81%ED%83%9C%EC%A0%95%EB%B3%B4%ED%8C%8C%EC%9D%BC%20%ED%99%95%EC%9D%B81.png" alt="" /></p>

<p><br /></p>

<h3 id="4-플럼-이벤트-작동">4) 플럼 이벤트 작동</h3>
<ul>
  <li>플럼의 SmartCar 에이전트가 정상적으로 작동하고 있다면, SpoolDir이 참조하고 있는 /home/pilot-pjt/working/car-batch-log 경로에 파일이 생성됨과 동시에 플럼의 파일 수집 이벤트가 작동</li>
</ul>

<p><br /></p>

<p>1) /home/pilot-pjt/working/SmartCar 경로에 만들어진 SmartCarStatusInfo_20160101.txt 파일을 플럼의 SmartCarInfo의 SpoolDir 경로인 /home/pilot-pjt/working/car-batch-log로 옮겨서 플럼의 File 이벤트가 작동되도록 함</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mv</span> /home/pilot-pjt/working/SmartCar/SmartCarStatusInfo_20160101.txt /home/pilot-pjt/working/car-batch-log/
</code></pre></div></div>

<p><br /></p>

<p>2) 플럼의 실행 로그를 통해 SmartCarInfo_Agent가 정상적으로 작동하는지 확인</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /var/log/flume-ng/
<span class="nb">tail</span> <span class="nt">-f</span> /var/log/flume-ng/flume-cmf-flume-AGENT-server02.hadoop.com.log
</code></pre></div></div>

<p><img src="img/CH04/%ED%94%8C%EB%9F%BC%EC%9D%B4%EB%B2%A4%ED%8A%B8%20%EC%9E%91%EB%8F%99.png" alt="" /></p>

<ul>
  <li>
    <p>위의 이미지와 같이 특별한 에러 없이 <code class="language-plaintext highlighter-rouge">Creating /pilot-pjt/collect ... </code> 또는 <code class="language-plaintext highlighter-rouge">Updating checkpoint for file: ... </code>메시지가 나타나면 정상적으로 HDFS에 적재중인 것</p>
  </li>
  <li>
    <p>위의 이미지와 같이 <code class="language-plaintext highlighter-rouge">...BucketWriter: Closing /pilot-pjt/...</code>, <code class="language-plaintext highlighter-rouge">BucketWriter: Renaming /pilot-pjt/...</code>, <code class="language-plaintext highlighter-rouge">...Writer callback called.</code> 라는 메시지가 보이면 모든 HDFS 적재가 성공적으로 끝난 것</p>
  </li>
</ul>

<p><br /></p>

<h3 id="5-hdfs-명령어-확인">5) HDFS 명령어 확인</h3>
<ul>
  <li>HDFS CLI 명령어로도 적재되고 있는 스마트카 로그 파일 확인 가능</li>
  <li>ls 명령 중 <code class="language-plaintext highlighter-rouge">-R</code> 옵션을 지정하면 해당 하위 디렉터리의 모든 파일 목록 볼 수 있음</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-ls</span> <span class="nt">-R</span> /pilot-pjt/collect/car-batch-log/
</code></pre></div></div>

<p><img src="img/CH04/hdfs%20%EC%A0%81%EC%9E%AC%EB%90%98%EA%B3%A0%20%EC%9E%88%EB%8A%94%20%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%B9%B4%20%EB%A1%9C%EA%B7%B8%ED%8C%8C%EC%9D%BC.png" alt="" /></p>

<ul>
  <li>위의 이미지를 보면 스마트카 상태 정보 파일(100MB) 한 개가 64MB와 46MB의 2개로 나눠져 HDFS의 “wrk_date=작업일자” 파티션 디렉터리에 적재된 것을 확인할 수 있음</li>
</ul>

<p><br /></p>

<h4 id="hdfs에-적재된-스마트카-상태-정보-파일-내용-직접-확인"><strong>HDFS에 적재된 스마트카 상태 정보 파일 내용 직접 확인</strong></h4>
<ul>
  <li>적재된 일자와 시간에 따라 파일 경로와 최종 파일명이 다를 수 있음
```bash
hdfs dfs -cat “출력된 디렉터리/파일명.log”</li>
</ul>

<h1 id="필자-환경에서-단순-데이터-확인">필자 환경에서 단순 데이터 확인</h1>
<p>hdfs dfs -tail /pilot-pjt/collet/car-batch-log/wrk_date=20230109/car-batch-log.1673203446499.log</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>![](img/CH04/hdfs%20%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%B9%B4%20%EC%83%81%ED%83%9C%EC%A0%95%EB%B3%B4%ED%8C%8C%EC%9D%BC%20%ED%99%95%EC%9D%B81.png)   
![](img/CH04/hdfs%20%EC%8A%A4%EB%A7%88%ED%8A%B8%EC%B9%B4%20%EC%83%81%ED%83%9C%EC%A0%95%EB%B3%B4%ED%8C%8C%EC%9D%BC%20%ED%99%95%EC%9D%B82.png)

- 이미지를 보면 각 행의 내용이 모두 "20160101"로 시작됨
- 로그 시뮬레이터 설정으로 스마트카 상태 정보 데이터를 "2016년 1월 1일"로 발생하게 했기 때문
- 또한, 각 행의 끝에 붙은 "20230109"는 수집일자 정보로서, 플럼의 Interceptor가 붙여넣은 추가 정보

&lt;br&gt;

- 백그라운드로 실행했던 스마트카 로그 시뮬레이터 모두 종료
```bash
ps -ef | grep smartcar.log
kill -9 [pid]
</code></pre></div></div>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[1. 하둡 설치 이미 CH02에서 CM을 통해 설치 완료 하둡은 수집, 적재, 처리, 분석의 전 영역에 걸쳐 모든 컴포넌트와 연결되어 설치 구성됨]]></summary></entry><entry><title type="html">[pilot] Ch3. 빅데이터 수집 이론</title><link href="http://localhost:4000/hadoop/2023/09/22/ch3.html" rel="alternate" type="text/html" title="[pilot] Ch3. 빅데이터 수집 이론" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T04:50:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/ch3</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/ch3.html"><![CDATA[<p>[출처: 실무로 배우는 빅데이터 기술, 김강원 저]</p>

<p><br /></p>

<h2 id="1-플럼-flume">1. 플럼 Flume</h2>

<h3 id="1-플럼">1) 플럼</h3>
<ul>
  <li>빅데이터를 __수집__할 때 다양한 수집 요구사항들을 해결하기 위한 기능으로 구성된 소프트웨어</li>
  <li>통신 프로토콜, 메시지 포맷, 발생 주기, 데이터 크기 등 데이터를 수집할 때 고려해야 할 것들을 쉽게 해결할 수 있는 기능과 아키텍처 제공</li>
</ul>

<p><br /></p>

<h3 id="2-주요-구성요소">2) 주요 구성요소</h3>

<table>
  <thead>
    <tr>
      <th>구성요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Source</td>
      <td>다양한 원천 시스템의 데이터를 수집하기 위해 Avro, Thrift, JMS, Spool Dir, Kafka 등 컴포넌트 제공 <br /> 수집한 데이터 Channel로 전달</td>
    </tr>
    <tr>
      <td>Channel</td>
      <td>Source와 Sink 연결 <br /> 데이터를 버퍼링하는 컴포넌트로 메모리, 파일, 데이터베이스를 채널의 저장소로 활용</td>
    </tr>
    <tr>
      <td>Sink</td>
      <td>수집한 데이터를 Channel로부터 전달받아 최종 목적지에 저장하기 위한 기능 <br /> HDFS, Hive, Logger, Avro, ElasticSearch, Thrift 등 제공</td>
    </tr>
    <tr>
      <td>Interceptor</td>
      <td>Source와 Channel 사이에서 데이터 필터링 및 가공하는 컴포넌트 <br /> Timestamp, Host, Regex Filtering 등 기본 제공 <br /> + 필요 시 사용자 정의 Interceptor 추가</td>
    </tr>
    <tr>
      <td>Agent</td>
      <td>Source → (Interceptor) → Channel → Sink 컴포넌트 순으로 구성된 작업 단위 <br /> 독립된 인스턴스로 생성</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="3-플럼-아키텍처">3) 플럼 아키텍처</h3>
<ul>
  <li>플럼 메커니즘 : Source, Channel, Sink 만을 활용하는 매우 단순하고 직관적인 구조</li>
  <li><code class="language-plaintext highlighter-rouge">Source</code>에서 데이터 로드, <code class="language-plaintext highlighter-rouge">Channel</code>에서 데이터 임시 저장, <code class="language-plaintext highlighter-rouge">Sink</code>를 통해 목적지에 최종 적재</li>
</ul>

<p><br /></p>

<h4 id="3-1-유형-1">3-1) 유형 1</h4>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcFIlJB%2FbtrWPK83bP5%2FhRnLmBlAMQNtXg9zQyb6Pk%2Fimg.png" alt="flume1" /></p>

<ul>
  <li>가장 단순한 플럼 에이전트 구성</li>
  <li>원천 데이터를 특별한 처리 없이 단순 수집/적재</li>
</ul>

<p><br /></p>

<h4 id="3-2-유형-2">3-2) 유형 2</h4>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F4z94Z%2FbtrWQtS8Zed%2FT0fVeS4HqQiSjfCbMoOqSk%2Fimg.png" alt="flume2" /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Interceptor</code>를 추가해 데이터 가공</li>
  <li>데이터의 특성에 따라 Channel에서 다수의 Sink 컴포넌트로 라우팅이 필요할 때 구성
    <blockquote>
      <p>데이터 통신에서의 라우팅: 네트워크상에서 주소를 이용하여 목적지까지 메시지를 전달하는 방법을 체계적으로 결정하는 경로선택 과정</p>
    </blockquote>
  </li>
  <li>한 개의 플럼 에이전트 안에서 두 개 이상의 S-C-S 컴포넌트 구성 및 관리도 가능</li>
</ul>

<p><br /></p>

<h4 id="3-3-유형-3">3-3) 유형 3</h4>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbO9D2Z%2FbtrWQLstjKN%2FcuVXRU2bSWA7hpvReeoUmK%2Fimg.png" alt="flume3" /></p>
<ul>
  <li>플럼 에이전트에서 수집한 데이터를 에이전트 2, 3에 전송할 때 로드밸런싱, 복제, 페일오버 등의 기능을 선택적으로 수행 가능</li>
  <li>수집해야 할 원천 시스템은 한 곳이지만, 높은 성능과 안정성이 필요할 때 주로 사용</li>
</ul>

<p><br /></p>

<blockquote>
  <p><strong>로드밸런싱(부하분산)</strong>: 서버가 처리해야 할 업무 혹은 요청을 여러 대의 서버로 나누어 처리하는 것. 한 대의 서버로 부하가 집중되지 않도록 트래픽을 관리해 각각의 서버가 최적의 퍼포먼스를 보일 수 있도록 하는 것이 목적</p>
</blockquote>

<blockquote>
  <p><strong>페일오버(장애 극복 기능)</strong>: 컴퓨터 서버, 시스템, 네트워크 등에서 이상이 생겼을 때 예비 시스템으로 자동전환되는 기능. 시스템 설계에서 높은 가용성과 신뢰성이 요구되는 경우 페일오버 기능을 탑재하는 것이 일반적</p>
</blockquote>

<p><br /></p>

<h4 id="3-4-유형-4">3-4) 유형 4</h4>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbtuTWx%2FbtrWQq952UX%2F4ZT1Aa7j0By0TU1F4SRZkK%2Fimg.png" alt="flume4" /></p>

<ul>
  <li>수집해야 할 원천 시스템이 다양하고, 대규모의 데이터가 유입될 때</li>
  <li>에이전트 1, 2, 3, 4에서 수집한 데이터를 에이전트 5에서 집계하고, 이때 에이전트 6으로 이중화해서 성능과 안정성 보장</li>
</ul>

<p><br /></p>

<h3 id="4-활용-방안">4) 활용 방안</h3>
<ul>
  <li>스마트카에서 발생하는 로그 직접 수집하는 역할. 로그 유형에 따라 두 가지 에이전트 구성할 것</li>
</ul>

<h4 id="4-1-100대의-스마트카-상태-정보-로그파일">4-1) 100대의 스마트카 상태 정보 로그파일</h4>
<ul>
  <li>로그 시뮬레이터를 통해 매일 생성됨</li>
  <li>생성된 상태 정보 파일을 플럼 에이전트가 일 단위로 수집해서 하둡에 적재, 이후 대규모 배치 분석에 활용</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcMRe8i%2FbtrWSu35Iq5%2Fzk4ItlgvgxxrfuybwCO8X1%2Fimg.png" alt="flume5" /></p>

<p><br /></p>

<h4 id="4-2-스마트카-운전자-100명의-운행-정보-실시간-기록">4-2) 스마트카 운전자 100명의 운행 정보 실시간 기록</h4>
<ul>
  <li>로그 시뮬레이터에 의해 운행 정보 실시간 로그 파일 생성됨</li>
  <li>로그 발생과 동시에 플럼 에이전트가 수집해서 kafka에 전송</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FemDzEF%2FbtrWPOp1t4r%2F3rf9dPHwJh78bvtrC2VzZk%2Fimg.png" alt="flume6" /></p>

<p><br /></p>

<h2 id="2-카프카-kafka">2. 카프카 Kafka</h2>

<h3 id="1-카프카">1) 카프카</h3>
<ul>
  <li>Message Oriented Middleware (MOM) 소프트웨어 중 하나</li>
  <li>대규모로 발생하는 메시지성 데이터를 비동기 방식으로 중계</li>
  <li>원천 시스템으로부터 대규모 트랜잭션 데이터가 발생했을 때, 중간에 데이터를 버퍼링하면서 타깃 시스템에 안정적으로 전송해주는 중간 시스템</li>
</ul>

<p><br /></p>

<h3 id="2-주요-구성요소-1">2) 주요 구성요소</h3>

<table>
  <thead>
    <tr>
      <th>구성요소</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Broker</td>
      <td>카프카의 서비스 인스턴스 <br /> 다수의 Broker를 클러스터로 구성하고 Topic이 생성되는 물리적 서버</td>
    </tr>
    <tr>
      <td>Topic</td>
      <td>Broker에서 데이터의 발행/소비 처리를 위한 저장소</td>
    </tr>
    <tr>
      <td>Provider</td>
      <td>Broker의 특정 Topic에 데이터를 전송(발행)하는 역할 <br /> 카프카 라이브러리를 통해 구현</td>
    </tr>
    <tr>
      <td>Consumer</td>
      <td>Broker의 특정 Topic에서 데이터를 수신(소비)하는 역할 <br /> 카프카 라이브러리를 통해 구현</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="3-카프카-아키텍처">3) 카프카 아키텍처</h3>
<ul>
  <li>클러스터 방식에 따라 세가지 아키텍처 구성 가능, 반드시 주키퍼 이용</li>
</ul>

<h4 id="3-1-유형-1---싱글-브로커--싱글-노드">3-1) 유형 1 - 싱글 브로커 / 싱글 노드</h4>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbHQAQw%2FbtrWQsfLOc6%2FeMIWZZ0jZO4Mvtu4UTmZdK%2Fimg.png" alt="kafka1" /></p>

<ul>
  <li>1대의 카프카 서버와 1개의 Broker만 구성한 아키텍처</li>
  <li>대량의 발행 / 소비 요건이 없고, 업무 도메인이 단순할 때 이용</li>
</ul>

<p><br /></p>

<h4 id="3-2-유형-2---멀티-브로커--싱글-노드">3-2) 유형 2 - 멀티 브로커 / 싱글 노드</h4>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcdOoeq%2FbtrWPOp1CkC%2FDp36P6KAWKOdHjQk42QWO0%2Fimg.png" alt="kafka2" /></p>

<ul>
  <li>1대의 카프카 서버에 2개의 Broker를 구성한 아키텍처</li>
  <li>물리적인 카프카 서버가 1대이므로 대량의 발행 / 소비 요건에는 사용 어려움</li>
  <li>하지만, 업무 도메인이 복잡해서 메시지 처리를 분리 관리해야 할 때 이용</li>
</ul>

<p><br /></p>

<h4 id="3-3-유형-3---멀티-브로커--멀티-노드">3-3) 유형 3 - 멀티 브로커 / 멀티 노드</h4>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FefW4SY%2FbtrWQJO6l5T%2FXz4FyS48o1EvPlczR6qmbK%2Fimg.png" alt="kafka3" /></p>

<ul>
  <li>2대 이상의 카프카 서버로 멀티 브로커 구성</li>
  <li>대규모 발행 / 소비 데이터 처리에 적합</li>
  <li>물리적으로 나눠진 브로커 간의 데이터 복제가 가능해 안정성이 높음</li>
  <li>업무 도메인별 메시지 그룹을 분류할 수 있어 복잡한 메시지 송/수신에 적합</li>
</ul>

<p><br /></p>

<h3 id="4-활용-방안-1">4) 활용 방안</h3>
<ul>
  <li>플럼이 실시간 데이터를 수집해 카프카 Topic에 전달하면, 카프카는 받은 데이터를 Topic에 임시로 저장하고 있다가 Consumer 프로그램이 작동해 Topic에서 데이터 가져감</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fcdo8X3%2FbtrWRCIjAQr%2Fj1jY1R9kpa2kKZR1S2BOs1%2Fimg.png" alt="kafka4" /></p>

<p><br /></p>

<ul>
  <li>카프카 활용 목적 : 플럼이 아주 빠르게 발생하는 데이터를 실시간으로 수집하게 되면, 이를 최종 목적지에 전달하기 전 중간에서 안정적인 버퍼링 처리가 필요</li>
  <li>카프카를 거치지 않고 바로 타깃 저장소인 HBase에 전송 → HBase에 장애가 발생하면 플럼의 Channel에 전송하지 못한 데이터들이 빠르게 쌓여 곧바로 플럼의 장애로도 이어짐 → 데이터 유실 발생</li>
</ul>

<p><br /></p>

<ul>
  <li>HBase에 장에가 발생해도 카프카에서 데이터를 저장해 놓았다가 HBase가 복구되면 곧바로 재처리 가능 <br />
  플럼이 수집한 데이터를 카프카의 토픽에 비동기로 전송함으로써 수집 속도가 빨라짐</li>
</ul>

<blockquote>
  <p><strong>비동기 방식</strong>: 동시에 일어나지 않을 수 있음 (요청을 보냈을 때 응답 상태와 상관없이 다음 동작을 수행 할 수 있음)  <br />
  → 자원을 효율적으로 이용할 수 있음</p>
</blockquote>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdLfb9Y%2FbtrWS1Oiqj3%2Fe3vIsmeuGDCkAVAVsom3PK%2Fimg.png" alt="kafka5" /></p>

<p><br /></p>

<h2 id="3-수집-파일럿-실행-1단계---수집-아키텍처">3. 수집 파일럿 실행 1단계 - 수집 아키텍처</h2>

<h3 id="1-수집-요구사항">1) 수집 요구사항</h3>
<ul>
  <li>차량의 다양한 장치로부터 발생하는 로그 파일 수집해서 기능별 상태 점검</li>
  <li>운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행 패턴 분석</li>
</ul>

<p><br /></p>

<table>
  <thead>
    <tr>
      <th>수집 요구사항 구체화</th>
      <th>분석 및 해결 방안</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>스마트카로부터 로그 파일 주기적으로 발생</td>
      <td>플럼 → 대용량 배치 파일 및 실시간 로그 파일 수집</td>
    </tr>
    <tr>
      <td>스마트카의 배치 로그 파일 이벤트 감지</td>
      <td>플럼의 Source 컴포넌트 중 SpoolDir → 주기적인 로그 파일 발생 이벤트 감지</td>
    </tr>
    <tr>
      <td>스마트카의 실시간 로그 발생 이벤트 감지</td>
      <td>플럼의 Source 컴포넌트 중 Exec-Tail → 특정 로그 파일에서 로그 생성 이벤트 감지</td>
    </tr>
    <tr>
      <td>스마트카가 만들어내는 로그 데이터에 가비지 데이터가 있을 수 있음</td>
      <td>플럼의 Interceptor → 정상 패턴의 데이터만 필터링</td>
    </tr>
    <tr>
      <td>수집 도중 장애가 발생해도 데이터를 안전하게 보관, 재처리해야 함</td>
      <td>플럼의 메모리 Channel, 카프카 Broker → 로컬 디스크의 파일 시스템에 수집 데이터 임시 저장</td>
    </tr>
    <tr>
      <td>스마트카의 실시간 로그 파일은 비동기 처리로 빠른 수집 처리</td>
      <td>플럼에서 수집한 데이터를 카프카 Sink 컴포넌트를 이용해 카프카 Topic에 비동기 전송</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="2-수집-아키텍처">2) 수집 아키텍처</h3>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoLkHN%2FbtrWRDgajq4%2FSekbPKLFBAkMf0QXIkpWkk%2Fimg.png" alt="collect1" /> <br />
<br /></p>

<h4 id="2-1-로그-시뮬레이터">2-1) 로그 시뮬레이터</h4>
<ul>
  <li>스마트카의 상태 정보와 운전자의 운행 정보 로그를 가상으로 만드는 자바 로그 발생기</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>스마트카 상태 정보</strong> : 100대 스마트카 장치들의 상태 정보를 3초 간격으로 발생 시킴, 1일 100MB 로그 파일 생성</li>
  <li><strong>운전자 운행 정보</strong> : 100명의 스마트카 운전자들의 운행 정보 실시간으로 발생 시킴, 하나의 운행 정보 로그는 4KB 미만, 동시에 최대 400KB 용량으로 실시간 데이터 발생</li>
</ul>

<p><br /></p>

<h4 id="2-2-플럼-에이전트1">2-2) 플럼 에이전트1</h4>
<ul>
  <li>대용량 로그 파일을 주기적으로 수집해서 표준 입출력 로거로 보여주는 레이어</li>
  <li>스마트카 상태 정보를 기록한 로그 파일을 일별로 수집하기 위한 배치성 플럼 에이전트</li>
</ul>

<p><br /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">SpoolDir Source</code> : 약속된 로그 발생 디렉터리를 모니터링하다가 정의된 로그 파일 발생 시 해당 파일의 내용을 읽어서 수집하는 기능 제공</li>
  <li><code class="language-plaintext highlighter-rouge">Memory Channel</code> : SpoolDir Source로부터 수집된 데이터를 메모리 Channel에 중간 적재. 버퍼링 기능을 제공하며 , Sink와 연결되어 트랜잭션 처리 지원함</li>
  <li><code class="language-plaintext highlighter-rouge">Logger Sink</code> : Channel로부터 읽어들인 데이터를 플럼의 표준 로그 파일로 출력</li>
</ul>

<p><br /></p>

<h4 id="2-3-플럼-에이전트2">2-3) 플럼 에이전트2</h4>
<ul>
  <li>실시간으로 발생하는 로그를 라인 단위로 수집해 카프카의 Topic에 전송하는 레이어</li>
  <li>스마트카 운전자의 운행 정보 실시간으로 수집하기 위한 실시간성 플럼 에이전트</li>
</ul>

<p><br /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Exec-Tail Source</code> : 로그가 쌓이고 있는 파일에 Tail 파이프라인을 이용해 실시간으로 데이터를 수집하는 기능</li>
  <li><code class="language-plaintext highlighter-rouge">Memory Channel</code> : Exec-Tail Source로부터 수집한 데이터를 메모리 Channel에 버퍼링 처리를 하면서 임시 적재</li>
  <li><code class="language-plaintext highlighter-rouge">Kafka Sink</code> : Channel로부터 읽어들인 데이터를 카프카 Broker의 특정 토픽에 비동기 방식으로 전송하는 Provider 역할 수행</li>
</ul>

<p><br /></p>

<h4 id="2-4-기타">2-4) 기타</h4>
<ul>
  <li>플럼이 수집한 로그 데이터 임시 출력 및 저장</li>
</ul>

<p><br /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Flume Stdout</code> : 플럼의 Logger-Sink를 통해 표준 출력 로그가 출력됨</li>
  <li><code class="language-plaintext highlighter-rouge">Kafka Topic</code> : 플럼의 Kafka-Sink는 수집된 실시간 로그를 임시 적재함</li>
</ul>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[[출처: 실무로 배우는 빅데이터 기술, 김강원 저]]]></summary></entry><entry><title type="html">[pilot] Ch3. 빅데이터 수집 실습</title><link href="http://localhost:4000/hadoop/2023/09/22/ch3(2).html" rel="alternate" type="text/html" title="[pilot] Ch3. 빅데이터 수집 실습" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T04:55:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/ch3(2)</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/ch3(2).html"><![CDATA[<h2 id="0-이번-장에서-할-것">0. 이번 장에서 할 것</h2>
<ul>
  <li>빅데이터 아키텍처의 첫 번째 레이어인 <strong>수집 영역</strong> 구축</li>
  <li>스마트카 시뮬레이터로 배치 파일(스마트카 상태 정보)과 실시간 로그(스마트카 운행 정보) 생성</li>
  <li>이를 플러모가 카프카로 수집</li>
</ul>

<p><br /></p>

<h2 id="1-flume-설치">1. Flume 설치</h2>
<ul>
  <li>CM 홈에서 [서비스 추가] - [Flume] 선택
<img src="/img/CH03/flume%20%EC%84%A4%EC%B9%98.png" alt="" /></li>
  <li>서버 호스트 <code class="language-plaintext highlighter-rouge">server02.hadoop.com</code> 선택</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>Flume Heap Memory 수정</strong>
    <ul>
      <li>50Mib -&gt; <strong>100MiB</strong>
  <img src="img/CH03/flume%20heap%20memory%20%EB%B3%80%EA%B2%BD.png" alt="" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="2-kafka-설치">2. Kafka 설치</h2>
<ul>
  <li>
    <p>CM 홈에서 [서비스 추가] - [Kafka] 선택
<img src="img/CH03/kafka%20%EC%84%A4%EC%B9%98.png" alt="" /></p>
  </li>
  <li>
    <p>서버 호스트 <code class="language-plaintext highlighter-rouge">server02.hadoop.com</code> 선택</p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>카프카에 저장될 메시지 보관 기간 짧게 조정</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">Data Retention Time</code> 7일 -&gt; <strong>10분</strong>
  <img src="img/CH03/kafka%20data%20retention%20time%20%EB%B3%80%EA%B2%BD.png" alt="" /></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="3-플럼-수집-기능-구현">3. 플럼 수집 기능 구현</h2>
<ul>
  <li>플럼에서 2개의 에이전트 구현
    <ul>
      <li>스마트카 상태정보 수집하는 <code class="language-plaintext highlighter-rouge">SmartCarInfo Agent</code></li>
      <li>운전자의 운행정보 수집하는 <code class="language-plaintext highlighter-rouge">DriverCarInfo Agent</code></li>
    </ul>
  </li>
  <li>에이전트 생성
    <ul>
      <li>플럼이 인식할 수 있는 특정 디렉터리에 <code class="language-plaintext highlighter-rouge">{Agent 고유 이름}.conf</code> 파일 생성</li>
      <li>파일럿 프로젝트에서는 CM에서 제공하는 플럼 구성 정보 설정을 통해 에이전트 편리하게 생성 가능</li>
    </ul>
  </li>
</ul>

<h3 id="1-smartcar-에이전트-생성">1) SmartCar 에이전트 생성</h3>
<ul>
  <li>CM 홈 [Flume] - [구성]</li>
  <li><code class="language-plaintext highlighter-rouge">구성 파일</code> 항목 수정</li>
</ul>

<p><img src="img/CH03/flume%20agent%20생성.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>Agent 이름: <code class="language-plaintext highlighter-rouge">SmartCar_Agent</code></li>
  <li>구성 파일</li>
</ul>

<div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#1
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>  = <span class="n">SmartCarInfo_SpoolSource</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>    = <span class="n">SmartCarInfo_LoggerSink</span> 

<span class="c">#2
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">type</span> = <span class="n">spooldir</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">spoolDir</span> = /<span class="n">home</span>/<span class="n">pilot</span>-<span class="n">pjt</span>/<span class="n">working</span>/<span class="n">car</span>-<span class="n">batch</span>-<span class="n">log</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">deletePolicy</span> = <span class="n">immediate</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">batchSize</span> = <span class="m">1000</span>

<span class="c">#3
</span><span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">type</span> = <span class="n">memory</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">capacity</span>  = <span class="m">100000</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">transactionCapacity</span>  = <span class="m">10000</span>

<span class="c">#4
</span><span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">type</span> = <span class="n">logger</span>

<span class="c">#5
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">channel</span> = <span class="n">SmartCarInfo_Channel</span>
</code></pre></div></div>

<ul>
  <li>#1
    <ul>
      <li>플럼의 에이전트에서 사용할 Source, Channle, Sink의 각 리소스 변수 정의</li>
    </ul>
  </li>
  <li>#2
    <ul>
      <li>에이전트의 Source 설정</li>
      <li>#1에서 Source로 선언했던 <code class="language-plaintext highlighter-rouge">SmartCarInfo_SpoolSource</code> 변수의 type을 <code class="language-plaintext highlighter-rouge">spooldir</code>로 설정</li>
      <li><code class="language-plaintext highlighter-rouge">spooldir</code> : 지정한 특정 디렉터리를 모니터링하고 있다가 새로운 파일이 생성되면 이벤트를 감지해서 <code class="language-plaintext highlighter-rouge">batchSize</code> 설정값만큼 읽어서 #3의 Channel에 데이터 전송</li>
    </ul>
  </li>
  <li>#3
    <ul>
      <li>에이전트의 Channel로서 <code class="language-plaintext highlighter-rouge">SmartCarInfo_Channel</code>의 type을 <code class="language-plaintext highlighter-rouge">memory</code>로 설정</li>
      <li>채널의 종류) memory / file</li>
      <li>Memory Channel은 Source로부터 받은 데이터를 메모리 상에 중간 적재 -&gt; 성능 높지만, 안정성 낮음</li>
      <li>File Channel은 Source에서 전송한 데이터를 받아 로컬 파일시스템 경로인 <code class="language-plaintext highlighter-rouge">dataDirs</code>에 임시로 저장했다가 Sink에게 데이터 제공 -&gt; 성능 낮지만, 안정성 높음</li>
    </ul>
  </li>
  <li>#4
    <ul>
      <li>에이전트의 최종 목적지</li>
      <li>SmartCarInfo_LoggerSink의 type을 <code class="language-plaintext highlighter-rouge">logger</code>로 설정</li>
      <li>Logger Sink는 수집한 데이터를 테스트 및 디버깅 목적으로 플럼의 표준 출력 로그 파일인 <code class="language-plaintext highlighter-rouge">/var/log/flume-ng/flume-cmf-flume-AGENT-server02.hadoop.com.log</code>에 출력</li>
    </ul>
  </li>
  <li>#5
    <ul>
      <li>Source와 Channel Sink 연결</li>
      <li>앞서 정의한 SmartCarInfo_SpoolSource의 채널값을 <code class="language-plaintext highlighter-rouge">SmartCarInfo_Channel</code>로 설정</li>
      <li>SmartCarInfo_LoggerSink의 채널값도 <code class="language-plaintext highlighter-rouge">SmartCarInfo_Channel</code>로 설정</li>
      <li>File -&gt; Channel -&gt; Sink로 이어지는 에이전트 리소스를 하나로 연결</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="2-smartcar-에이전트에-interceptor-추가">2) SmartCar 에이전트에 Interceptor 추가</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Interceptor</code> : Source와 Channel의 중간에서 데이터를 가공하는 역할</li>
  <li>플럼의 Source에서 유입되는 데이터 중 일부 데이터를 수정하거나 필요한 데이터만 필터링하는 등 중간에 데이터를 추가/가공/정제하는 데 사용됨</li>
  <li>플럼에서 데이터 전송 단위 <code class="language-plaintext highlighter-rouge">Event</code> - Header와 본문 Body로 구성됨</li>
  <li>Interceptor는 Event의 Header에 특정값을 추가하거나 Body에 데이터를 가공하는 기능으로 활용됨</li>
</ul>

<p><br /></p>

<ul>
  <li>파일럿 프로젝트에서는 SmartCarInfo 로그 파일을 수집하는데 총 4개의 Interceptor를 추가할 것</li>
  <li>이번 장에서는 <code class="language-plaintext highlighter-rouge">Filter Interceptor</code> 하나만 추가</li>
  <li>앞서 작성한 SmartCarInfo 에이전트 수정해서 Filter Interceptor 사용</li>
</ul>

<p><img src="img/CH03/flume%20interceptor%20추가.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>CM 홈 [Flume] - [구성] - [구성 파일]</li>
  <li>Source와 Channel 사이에 Interceptor 추가</li>
</ul>

<div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>  = <span class="n">SmartCarInfo_SpoolSource</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>    = <span class="n">SmartCarInfo_LoggerSink</span> 

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">type</span> = <span class="n">spooldir</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">spoolDir</span> = /<span class="n">home</span>/<span class="n">pilot</span>-<span class="n">pjt</span>/<span class="n">working</span>/<span class="n">car</span>-<span class="n">batch</span>-<span class="n">log</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">deletePolicy</span> = <span class="n">immediate</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">batchSize</span> = <span class="m">1000</span>

<span class="c">#1
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span> = <span class="n">filterInterceptor</span>

<span class="c">#2
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">type</span> = <span class="n">regex_filter</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">regex</span> = ^\\<span class="n">d</span>{<span class="m">14</span>}
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">excludeEvents</span> = <span class="n">false</span>


<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">type</span> = <span class="n">memory</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">capacity</span>  = <span class="m">100000</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">transactionCapacity</span>  = <span class="m">10000</span>


<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">type</span> = <span class="n">logger</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">channel</span> = <span class="n">SmartCarInfo_Channel</span>
</code></pre></div></div>

<ul>
  <li>#1
    <ul>
      <li>수집 데이터를 필터링하기 위해 <code class="language-plaintext highlighter-rouge">filterInterceptor</code> 변수를 선언해서 SmartCarInfo_SpoolSource에 할당</li>
    </ul>
  </li>
  <li>#2
    <ul>
      <li>filterInterceptor의 type을 <code class="language-plaintext highlighter-rouge">regex_filter</code>로 설정</li>
      <li>정규 표현식(Regular Expression)을 이용해 수집 데이터를 필터링할 때 유용하게 사용</li>
      <li>아래 이미지에서 스마트카 로그 생성기가 만든 로그 파일 내용을 보면, 중간에 로그 포맷의 형식을 알리는 메타 정보가 포함되어 있음</li>
      <li>이 메타 정보를 수집 데이터에서 제외하고, 필요한 데이터만 수집해야 함</li>
      <li>이때 간단한 정규 표현식을 이용해서 해결 가능
        <ul>
          <li>스마트카 로그의 경우) 정상적인 로그 데이터가 발생했을 때 14자리의 날짜 형식을 가짐</li>
          <li>이 14자리 날짜 형식으로 시작하는 데이터에 대한 정규 표현식 <code class="language-plaintext highlighter-rouge">^\\d{14}</code>를 “regex” 속성에 설정</li>
          <li>“excludeEvents” 속성이 <strong>false</strong> 로 되어있는데, <strong>true</strong> 로 하면 반대로 제외 대상만 수집하게 됨</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="3-drivercarinfo-에이전트-생성">3) DriverCarInfo 에이전트 생성</h3>
<ul>
  <li>앞서 작성한 SmartCar 에이전트에 DriverCarInfo 에이전트를 위한 Source, Channel, Sink를 추가하여 생성</li>
  <li>한 개의 플럼 에이전트 파일에 여러 개의 에이전트를 만들어 사용</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>DriverCarInfo 리소스 변수 추가</strong></li>
</ul>

<div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#1
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>  = <span class="n">SmartCarInfo_SpoolSource</span> <span class="n">DriverCarInfo_TailSource</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span> <span class="n">DriverCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>    = <span class="n">SmartCarInfo_LoggerSink</span> <span class="n">DriverCarInfo_KafkaSink</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">type</span> = <span class="n">spooldir</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">spoolDir</span> = /<span class="n">home</span>/<span class="n">pilot</span>-<span class="n">pjt</span>/<span class="n">working</span> /<span class="n">car</span>-<span class="n">batch</span>-<span class="n">log</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">deletePolicy</span> = <span class="n">immediate</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">batchSize</span> = <span class="m">1000</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span> = <span class="n">filterInterceptor</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">type</span> = <span class="n">regex_filter</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">regex</span> = ^\\<span class="n">d</span>{<span class="m">14</span>}
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">excludeEvents</span> = <span class="n">false</span>


<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">type</span> = <span class="n">memory</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">capacity</span>  = <span class="m">100000</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">transactionCapacity</span>  = <span class="m">10000</span>


<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">type</span> = <span class="n">logger</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">channel</span> = <span class="n">SmartCarInfo_Channel</span>
</code></pre></div></div>
<ul>
  <li>#1
    <ul>
      <li>에이전트의 Source, Channel, Sink에 DriverCarInfo 리소스 변수 추가</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>DriverCarInfo 설정 추가</strong></li>
</ul>

<div class="language-conf highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>  = <span class="n">SmartCarInfo_SpoolSource</span> <span class="n">DriverCarInfo_TailSource</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span> <span class="n">DriverCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>    = <span class="n">SmartCarInfo_LoggerSink</span> <span class="n">DriverCarInfo_KafkaSink</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">type</span> = <span class="n">spooldir</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">spoolDir</span> = /<span class="n">home</span>/<span class="n">pilot</span>-<span class="n">pjt</span>/<span class="n">working</span>/<span class="n">car</span>-<span class="n">batch</span>-<span class="n">log</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">deletePolicy</span> = <span class="n">immediate</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">batchSize</span> = <span class="m">1000</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span> = <span class="n">filterInterceptor</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">type</span> = <span class="n">regex_filter</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">regex</span> = ^\\<span class="n">d</span>{<span class="m">14</span>}
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor</span>.<span class="n">excludeEvents</span> = <span class="n">false</span>


<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">type</span> = <span class="n">memory</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">capacity</span>  = <span class="m">100000</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">SmartCarInfo_Channel</span>.<span class="n">transactionCapacity</span>  = <span class="m">10000</span>


<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">type</span> = <span class="n">logger</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">SmartCarInfo_SpoolSource</span>.<span class="n">channels</span> = <span class="n">SmartCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">SmartCarInfo_LoggerSink</span>.<span class="n">channel</span> = <span class="n">SmartCarInfo_Channel</span>

<span class="c">#1
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">type</span> = <span class="n">exec</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">command</span> = <span class="n">tail</span> -<span class="n">F</span> /<span class="n">home</span>/<span class="n">pilot</span>-<span class="n">pjt</span>/<span class="n">working</span>/<span class="n">driver</span>-<span class="n">realtime</span>-<span class="n">log</span>/<span class="n">SmartCarDriverInfo</span>.<span class="n">log</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">restart</span> = <span class="n">true</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">batchSize</span> = <span class="m">1000</span>

<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">interceptors</span> = <span class="n">filterInterceptor2</span>

<span class="c">#2
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor2</span>.<span class="n">type</span> = <span class="n">regex_filter</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor2</span>.<span class="n">regex</span> = ^\\<span class="n">d</span>{<span class="m">14</span>}
<span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">interceptors</span>.<span class="n">filterInterceptor2</span>.<span class="n">excludeEvents</span> = <span class="n">false</span>

<span class="c">#3
</span><span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">DriverCarInfo_KafkaSink</span>.<span class="n">type</span> = <span class="n">org</span>.<span class="n">apache</span>.<span class="n">flume</span>.<span class="n">sink</span>.<span class="n">kafka</span>.<span class="n">KafkaSink</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">DriverCarInfo_KafkaSink</span>.<span class="n">topic</span> = <span class="n">SmartCar</span>-<span class="n">Topic</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">DriverCarInfo_KafkaSink</span>.<span class="n">brokerList</span> = <span class="n">server02</span>.<span class="n">hadoop</span>.<span class="n">com</span>:<span class="m">9092</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">DriverCarInfo_KafkaSink</span>.<span class="n">requiredAcks</span> = <span class="m">1</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">DriverCarInfo_KafkaSink</span>.<span class="n">batchSize</span> = <span class="m">1000</span>

<span class="c">#4
</span><span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">DriverCarInfo_Channel</span>.<span class="n">type</span> = <span class="n">memory</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">DriverCarInfo_Channel</span>.<span class="n">capacity</span>= <span class="m">100000</span>
<span class="n">SmartCar_Agent</span>.<span class="n">channels</span>.<span class="n">DriverCarInfo_Channel</span>.<span class="n">transactionCapacity</span> = <span class="m">10000</span>

<span class="c">#5
</span><span class="n">SmartCar_Agent</span>.<span class="n">sources</span>.<span class="n">DriverCarInfo_TailSource</span>.<span class="n">channels</span> = <span class="n">DriverCarInfo_Channel</span>
<span class="n">SmartCar_Agent</span>.<span class="n">sinks</span>.<span class="n">DriverCarInfo_KafkaSink</span>.<span class="n">channel</span> = <span class="n">DriverCarInfo_Channel</span>
</code></pre></div></div>

<ul>
  <li>앞서 선언한 SmartCarInfo 에이전트와 유사하게 Source, Interceptor, Channel, Sink 순서대로 정의</li>
  <li>일부 Source와 Sink 유형이 달라짐</li>
</ul>

<p><br /></p>

<ul>
  <li>#1
    <ul>
      <li>Source의 type이 <code class="language-plaintext highlighter-rouge">exec</code></li>
      <li><code class="language-plaintext highlighter-rouge">exec</code>는 플럼 외부에서 수행한 명령의 결과를 플럼의 Event로 가져와 수집할 수 있는 기능 제공</li>
      <li>스마트카 운전자의 운행 정보가 로그 시뮬레이터를 통해 <code class="language-plaintext highlighter-rouge">/home/pilot-pjt/working/driver-realtime-log/SmartCarDriverInfo.log</code>에 생성
  -&gt; 리눅스의 <code class="language-plaintext highlighter-rouge">tail</code> 명령을 플럼의 <code class="language-plaintext highlighter-rouge">exec</code>를 실행해서 운전자의 실시간 운행 정보 수집</li>
    </ul>
  </li>
  <li>#2
    <ul>
      <li>Interceptor 정의</li>
      <li>데이터 필터링을 위한 <code class="language-plaintext highlighter-rouge">regex_filter</code>만 추가</li>
    </ul>
  </li>
  <li>#3
    <ul>
      <li>스마트카 운전자의 실시간 운행 정보는 플럼에서 수집과 동시에 카프카로 전송</li>
      <li>플럼의 <code class="language-plaintext highlighter-rouge">KafkaSink</code>의 내용을 보면, 카프카 브로커 서버가 실행중인 server02.hadoop.com:9092에 연결해서 SmartCar-Topic에 데이터를 100개의 배치 크기로 전송</li>
    </ul>
  </li>
  <li>#4
    <ul>
      <li>DriverCarInfo의 Channel을 <code class="language-plaintext highlighter-rouge">Memory Channel</code>로 선언</li>
    </ul>
  </li>
  <li>#5
    <ul>
      <li>DriverCarInfo의 Source와 Sink의 Channel을 앞서 정의한 DriverCarInfo_Channel로 설정해서 Source-Channel-Sink 구조 완성</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="4-카프카-기능-구현">4. 카프카 기능 구현</h2>
<ul>
  <li>카프카에 대한 직접적인 기능 구현은 하지 않음</li>
  <li>이미 플럼의 <code class="language-plaintext highlighter-rouge">DriverCarInfo_KafkaSink</code>를 통해 수집한 실시간 데이터를 카프카에 전송하는 기능 구현은 끝났기 때문</li>
  <li>카프카 명령어를 이용해 카프카의 <code class="language-plaintext highlighter-rouge">브로커</code> 안에 앞으로 사용하게 될 토픽 생성 &amp; 카프카의 <code class="language-plaintext highlighter-rouge">Producer</code> 명령을 통해 토픽에 데이터 전송</li>
  <li>토픽에 들어간 데이터를 다시 카프카의 <code class="language-plaintext highlighter-rouge">Consumer</code> 명령어로 수신</li>
</ul>

<p><br /></p>

<h3 id="1-카프카-topic-생성">1) 카프카 Topic 생성</h3>
<ul>
  <li>카프카가 설치되어 있는 Server02에서 카프카의 <code class="language-plaintext highlighter-rouge">CLI</code> 명령어를 이용해 다양한 카프카 기능 사용</li>
  <li>PuTTY로 Server02에 SSH 접속 - root 계정으로 로그인</li>
  <li>아래 카프카 토픽 명령어로 <strong>SmartCar-Topic</strong> 생성
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kafka-topics <span class="nt">--create</span> <span class="nt">--zookeeper</span> server02.hadoop.2181 <span class="nt">--replication-factor</span> 1 <span class="nt">--partitions</span> 1 <span class="nt">--topic</span> SmartCar-Topic
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="img/CH03/kafka%20topic%20생성.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>위 명령어 실행하고 <code class="language-plaintext highlighter-rouge">Created Topic SmartCar-Topic</code> 메시지가 나오면 토픽이 정상적으로 생성된 것</li>
  <li><code class="language-plaintext highlighter-rouge">--zookeeper</code> 옵션
    <ul>
      <li>토픽의 메타 정보들이 Zookeeper의 Z노드에 만들어지고 관리됨</li>
      <li><code class="language-plaintext highlighter-rouge">replication-factor</code> 옵션은 카프카를 다중 Broker로 만들고, 전송한 데이터를 replication-factor 개수만큼 복제하게 됨. 파일럿 플젝은 단일 카프카 브로커 -&gt; 복제 개수 1</li>
      <li><code class="language-plaintext highlighter-rouge">partitions</code> 옵션은 해당 Topic에 데이터들은 partitions 개수만큼 분리 저장하게 됨. 다중 Broker에서 쓰기/읽기 성능 향상을 위해 사용</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--topic</code> 옵션
    <ul>
      <li>파일럿 환경에서 사용할 토픽명 정의</li>
      <li><strong>SmartCar-Topic</strong>이라는 이름으로 토픽 정의</li>
      <li>플럼의 DriverCarInfo_KafkaSink에서 설정한 토픽 이름과 같아야 함</li>
      <li>토픽 삭제 명령어
  <code class="language-plaintext highlighter-rouge">kafka-topics --delete --zookeeper server02.hadoop.com:2181 --topic 토픽명</code></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h3 id="2-카프카-producer-사용">2) 카프카 Producer 사용</h3>
<ul>
  <li>Server02 SSH 접속 후 아래 명령 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kafka-console-producer <span class="nt">--broker-list</span> server02.hadoop.com:9092 <span class="nt">-topic</span> SmartCar-Topic
</code></pre></div>    </div>
  </li>
  <li>이후 <code class="language-plaintext highlighter-rouge">Hello! BigData!</code> 를 입력하고 엔터 키를 누름</li>
  <li>에러 메시지가 없으면 <strong>SmartCar-Topic</strong>에 “Hello! BigData!” 메시지를 성공적으로 전송한 것</li>
</ul>

<p><img src="img/CH03/kafka%20producer(1).png" alt="" />    <br />
<img src="img/CH03/kafka%20producer(2).png" alt="" /></p>

<p><br /></p>

<ul>
  <li>카프카 Producer와 Consumer 기능 점검</li>
</ul>

<p><img src="img/CH03/producer.jpg" alt="" /></p>

<ul>
  <li>앞서 Producer가 전송한 “Hello! BigData!” 메시지는 아직 카프카 토픽에 머물러 있는 상태</li>
  <li>Consumer 콘솔 1, 2를 실행해서 <strong>SmartCar-Topic</strong>에 연결하면 “Hello! BigData!” 메시지를 Consumer가 동시에 수신받게 될 것</li>
</ul>

<p><br /></p>

<h3 id="3-카프카-consumer-사용">3) 카프카 Consumer 사용</h3>
<ul>
  <li>Server02에 SSH 터미널을 2개 열어서 각각에 아래 카프카 Consumer 명령 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kafka-console-consumer <span class="nt">--bootstrap-server</span> server02.hadoop.com:9092 <span class="nt">--topic</span> SmartCar-Topic <span class="nt">--partition</span> 0 <span class="nt">--from-beginning</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>실행과 동시에 Producer에서 입력했던 “Hello! BigData!”가 출력되는 것을 볼 수 있음</li>
</ul>

<p><img src="img/CH03/kafka%20consumer(1).png" alt="" />
<img src="img/CH03/kafka%20consumer(2).png" alt="" /></p>

<ul>
  <li>위에서 “Hello! BigData!”를 입력했던 Producer 콘솔창에서 메시지를 전송할 때마다 2개의 Consumer 콘솔창에 브로드캐스트되어 동일 메시지가 수신됨</li>
</ul>

<p><br /></p>

<h2 id="5-수집-기능-테스트">5. 수집 기능 테스트</h2>

<h3 id="1-smartcar-로그-시뮬레이터-작동">1) SmartCar 로그 시뮬레이터 작동</h3>
<ul>
  <li>2016년 1월 1일에 3대의 스마트카 로그만 발생시켜 보기</li>
</ul>

<h4 id="1-server02에-ssh-접속-후-bigdatasmartcarloggen-10jar가-위치한-곳으로-이동">1) Server02에 SSH 접속 후 bigdata.smartcar.loggen-1.0.jar가 위치한 곳으로 이동</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working
</code></pre></div></div>

<p><br /></p>

<h4 id="2-다음-명령으로-2개의-스마트카-로그-시뮬레이터를-백그라운드-방식으로-실행">2) 다음 명령으로 2개의 스마트카 로그 시뮬레이터를 백그라운드 방식으로 실행</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-cp</span> bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20160101 3 &amp;
java <span class="nt">-cp</span> bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20160101 3 &amp;
</code></pre></div></div>

<p><img src="img/CH03/smartcar%20log%20시뮬레이터%20작동.png" alt="" /></p>

<ul>
  <li>2016년 1월 1일에 3대의 스마트카에 대한 상태 정보와 운전자의 운행 정보 생성 시작</li>
</ul>

<p><br /></p>

<h4 id="3-정상적으로-시뮬레이터가-작동되고-있는지-아래-내용으로-확인">3) 정상적으로 시뮬레이터가 작동되고 있는지 아래 내용으로 확인</h4>
<ul>
  <li>/home/pilot-pjt/working/SmartCar 경로에 SmartCarStatusInfo_20160101.txt 파일이 생성됐는지 확인</li>
  <li>파일의 내용 확인해보면 3대의 스마트카 상태 정보가 기록된 것을 볼 수 있음
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working/SmartCar
vi SmartCarStatusInfo_20160101.txt
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="img/CH03/smartcarstatusinfo%20파일%20생성%20확인.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>/home/pilot-pjt/working/driver-realtime-log 경로에 SmartCarDriverInfo.log 파일 생성됐는지 확인</li>
  <li>tail -f SmartCarDriverInfo.log 명령을 통해 3대의 스마트카 운전자의 운행 정보가 실시간으로 발생하는 것을 볼 수 있음</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working/driver-realtime-log
<span class="nb">tail</span> <span class="nt">-f</span> SmartCarDriverInfo.log
</code></pre></div></div>

<p><img src="img/CH03/smartcardriverinfo%20파일%20생성%20확인.png" alt="" /></p>

<p><br /></p>

<h4 id="4-homepilot-pjtworkingsmartcar-경로에-만들어진-smartcarstatusinfo_20160101txt-파일을-플럼-smartcarinfo-에이전트의-spooldir-경로로-옮김">4) /home/pilot-pjt/working/SmartCar 경로에 만들어진 SmartCarStatusInfo_20160101.txt 파일을 플럼 SmartCarInfo 에이전트의 SpoolDir 경로로 옮김</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mv</span> /home/pilot-pjt/working/SmartCar/SmartCarStatusInfo_20160101.txt /home/pilot-pjt/working/car-batch-log/
</code></pre></div></div>

<p><img src="img/CH03/smartcarstatusinfo%20파일%20이동.png" alt="" /></p>

<p><br /></p>

<h3 id="2-플럼-에이전트-작동">2) 플럼 에이전트 작동</h3>
<ul>
  <li>플럼 에이전트를 작동시켜 스마트카 로그 시뮬레이터가 만들어낸 두 유형의 로그 수집</li>
  <li>CM 홈 - [Flume] - [재시작] - 플럼 에이전트 재기동</li>
</ul>

<p><br /></p>

<h3 id="3-카프카-consumer-작동">3) 카프카 Consumer 작동</h3>
<ul>
  <li>Server02에 접속하여 다음과 같은 카프카 명령 실행</li>
  <li>이전에 사용한 Consumer 명령과 -from-beginning 옵션은 생략
    <ul>
      <li>-from-beginning 옵션: 해당 토픽에 저장된 첫 데이터부터 마지막 데이터까지 일괄 수신 후 대기하게 됨</li>
      <li>여기서는 실시간으로 발생된 데이터만 수신할 것이므로 해당 옵션 제외</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kafka-console-consumer <span class="nt">--bootstrap-server</span> server02.hadoop.com:9092 <span class="nt">--topic</span> SmartCar-Topic <span class="nt">--partition</span> 0
</code></pre></div></div>

<p><img src="img/CH03/kafka%20consumer%20작동.png" alt="" /></p>

<p><br /></p>

<ul>
  <li>앞서 실행한 시뮬레이터에 의해 스마트카의 운행 로그 데이터가 실시간으로 카프카에 유입되는 것을 확인할 수 있음</li>
</ul>

<p><br /></p>

<h3 id="4-수집-기능-점검">4) 수집 기능 점검</h3>

<h4 id="1-스마트카의-상태-정보-로그-파일이-플럼의-표준-출력-로그로-전송됐는지-리눅스-tail-명령어로-확인">1) 스마트카의 상태 정보 로그 파일이 플럼의 표준 출력 로그로 전송됐는지 리눅스 tail 명령어로 확인</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">tail</span> <span class="nt">-f</span> /var/log/flume-ng/flume-cmf-flume-AGENT-server02.hadoop.com.log
</code></pre></div></div>

<p><br /></p>

<ul>
  <li>아래 그림처럼 수집된 스마트카의 상태값 데이터가 출력되면 성공적으로 수집되고 있는 것</li>
</ul>

<p><img src="img/CH03/수집기능점검(1).png" alt="" /></p>

<ul>
  <li>참고로 출력되고 있는 로그의 내용을 보면, 플럼의 데이터 전송 단위인 Event가 Header와 Body 구조로 분리된 것을 확인할 수 있음</li>
</ul>

<p><br /></p>

<h4 id="2-스마트카-운전자의-실시간-운전-정보인-drivercarinfo가-정상적으로-수집되는지-확인">2) 스마트카 운전자의 실시간 운전 정보인 DriverCarInfo가 정상적으로 수집되는지 확인</h4>
<ul>
  <li>앞서 실행했던 카프카의 Consumer 콘솔창 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kafka-console-consumer <span class="nt">--bootstrap-server</span> server02.hadoop.com:9092 <span class="nt">--topic</span> SmartCar-Topic <span class="nt">--partition</span> 0
</code></pre></div></div>

<p><br /></p>

<ul>
  <li>아래와 같이 스마트카의 운전자 정보가 실시간으로 수집되고 있는지 확인할 수 있음</li>
</ul>

<p><img src="img/CH03/수집기능점검(2).png" alt="" /></p>

<p><br /></p>

<h4 id="3-백그라운드로-실행했던-스마트카-로그-시뮬레이터-모두-종료">3) 백그라운드로 실행했던 스마트카 로그 시뮬레이터 모두 종료</h4>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ps <span class="nt">-ef</span> | <span class="nb">grep </span>smartcar.log
</code></pre></div></div>

<p><br /></p>

<ul>
  <li>위 명령어로 조회된 두 자바 프로세스 (CarLogMain, DriverLogMain)의 pid를 찾아 강제 종료
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">kill</span> <span class="nt">-9</span> <span class="o">[</span>pid]
</code></pre></div>    </div>
  </li>
</ul>

<p><br /></p>

<h2 id="6-파일럿-환경의-로그-확인">6. 파일럿 환경의 로그 확인</h2>
<ul>
  <li>Hadoop 에코시스템 서버들의 로그 위치 : /var/log/디렉터리(cloudera, Hadoop, Oozie 등)</li>
  <li>Redis 서버 로그 위치 : /var/log/redis_6379.log</li>
  <li>Storm 서버 로그 위치 : /var/log/storm/</li>
  <li>Zeppelin 서버 로그 위치 : /home/pilot-pjt/zeppelin-0.8.2-bin-all/logs</li>
</ul>

<p><br /></p>

<h2 id="7-파일럿-환경에서-hdfs-문제-발생">7. 파일럿 환경에서 HDFS 문제 발생</h2>
<ul>
  <li>개인의 파일럿 프로젝트 환경은 가상머신으로 구성되어 있어 비정상적인 종료가 자주 발생할 수 있음</li>
  <li>이때 HDFS 상에 CORRUPT BLOCKS/FILES 같은 문제가 발생하거나, Safe 모드로 전환되어 빠져나오지 못하는 경우가 자주 발생</li>
  <li>파일럿 환경의 일부 기능 또는 설치 중에 문제가 발생한다면 HDFS의 파일/블록 깨짐 또는 Safe 모드 전환 여부 체크해야 함</li>
</ul>

<p><br /></p>

<ul>
  <li>HDFS 파일 시스템 검사 : <code class="language-plaintext highlighter-rouge">hdfs fsck /</code></li>
  <li>HDFS에 Safe 모드 발생 후 빠져나오지 못할 경우 Safe 모드 강제 해제 : <code class="language-plaintext highlighter-rouge">hdfs dfsadmin -safamode leave</code></li>
  <li>HDFS에 CORRUPT BLOCKS/FILES 등이 발생해 복구가 불가능한 경우
    <ul>
      <li>손상된 파일 강제 삭제 : <code class="language-plaintext highlighter-rouge">hdfs fsck / -delete</code></li>
      <li>손상된 파일을 /lost + found 디렉터리로 이동 : <code class="language-plaintext highlighter-rouge">hdfs fsck / -move</code></li>
    </ul>
  </li>
</ul>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[0. 이번 장에서 할 것 빅데이터 아키텍처의 첫 번째 레이어인 수집 영역 구축 스마트카 시뮬레이터로 배치 파일(스마트카 상태 정보)과 실시간 로그(스마트카 운행 정보) 생성 이를 플러모가 카프카로 수집]]></summary></entry><entry><title type="html">[pilot] Ch2. 파일럿 프로젝트 아키텍처 이론</title><link href="http://localhost:4000/hadoop/2023/09/22/ch2.html" rel="alternate" type="text/html" title="[pilot] Ch2. 파일럿 프로젝트 아키텍처 이론" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T04:30:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/ch2</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/ch2.html"><![CDATA[<p>[출처: 실무로 배우는 빅데이터 기술, 김강원 저]</p>

<p><br /></p>

<h2 id="1-요구사항-파악">1. 요구사항 파악</h2>

<h3 id="1-차량의-다양한-장치로부터-발생하는-로그-파일을-수집해서-기능별-상태를-점검한다">1) 차량의 다양한 장치로부터 발생하는 로그 파일을 수집해서 기능별 상태를 점검한다.</h3>
<h3 id="2-운전자의-운행-정보가-담긴-로그를-실시간으로-수집해서-주행-패턴을-분석한다">2) 운전자의 운행 정보가 담긴 로그를 실시간으로 수집해서 주행 패턴을 분석한다.</h3>

<p><br /></p>

<h2 id="2-데이터셋-살펴보기">2. 데이터셋 살펴보기</h2>

<h3 id="1-스마트카-상태-정보-데이터">1) 스마트카 상태 정보 데이터</h3>
<ul>
  <li>스마트카의 각종 센서로부터 발생하는 차량의 상태 정보 데이터셋</li>
  <li>요구사항 1과 관련, 로그 시뮬레이터를 통해 생성됨</li>
</ul>

<h3 id="2-스마트카-운전자-운행-데이터">2) 스마트카 운전자 운행 데이터</h3>
<ul>
  <li>스마트카 운전자의 운전 패턴 / 운행 정보가 담긴 데이터셋</li>
  <li>요구사항 2와 관련, 로그 시뮬레이터를 통해 생성됨</li>
</ul>

<h3 id="3-스마트카-마스터-데이터">3) 스마트카 마스터 데이터</h3>
<ul>
  <li>스마트카 운전자의 프로파일 정보가 담긴 데이터셋</li>
  <li>요구사항 1, 2와 관련된 분석 데이터셋을 만들 때 활용, 이미 만들어진 샘플 파일 이용</li>
</ul>

<h3 id="4-스마트카-물품-구매-이력-데이터">4) 스마트카 물품 구매 이력 데이터</h3>
<ul>
  <li>스마트카 운전자가 차량 내의 스마트 스크린을 통해 쇼핑몰에서 구입한 차량 물품 구매 목록 데이터셋</li>
  <li>요구사항 1, 2와 관련된 분석 데이터셋을 만들 때 활용, 이미 만들어진 샘플 파일 이용</li>
</ul>

<p><br /></p>

<h2 id="3-파일럿-프로젝트-소프트웨어-아키텍처">3. 파일럿 프로젝트 소프트웨어 아키텍처</h2>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbyLmtt%2FbtrUIZmQfNM%2Fbzo2admbnvciKPiCJTOeck%2Fimg.png" alt="sw" /></p>

<ul>
  <li>하둡을 중심으로 앞쪽을 수집/적재 (전처리) 영역, 뒤쪽을 탐색/분석 (후처리) 영역</li>
</ul>

<p><br /></p>

<h3 id="1-수집-레이어">1) 수집 레이어</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Flume</code>: 차량의 로그 수집</li>
  <li><code class="language-plaintext highlighter-rouge">Storm:</code> 실시간 로그 이벤트 처리</li>
  <li><code class="language-plaintext highlighter-rouge">Kafka</code>: 플럼과 스톰 사이에서 데이터의 안정적인 수집을 위해 버퍼링, 트랜잭션 처리</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcWmWKE%2FbtrUM57qDGA%2FrkDf9rPGJunJGJxaip96s0%2Fimg.png" alt="collect" /></p>

<p><br /></p>

<h3 id="2-적재-레이어">2) 적재 레이어</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">Hadoop</code>, <code class="language-plaintext highlighter-rouge">HBase</code>, <code class="language-plaintext highlighter-rouge">Redis</code></li>
  <li>대용량 로그파일: 플럼 -&gt; 하둡</li>
  <li>실시간 데이터: 플럼 -&gt; 카프카 -&gt; 스톰 -&gt; HBase/Redis</li>
  <li>스톰을 통해 실시간 이벤트 분석 -&gt; 결과에 따라 HBase와 레디스로 나누어 적재</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFZraV%2FbtrUKmB4dbg%2FIk87w7E4vULbeq0B5XRJx1%2Fimg.png" alt="load" /></p>

<p><br /></p>

<h3 id="3-처리탐색-레이어">3) 처리/탐색 레이어</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">하이브</code>: 하둡에 적재된 데이터 정제/변형/통합/분리/탐색 등의 작업 수행, 데이터를 정형화된 구조로 정규화해 데이터마트 생성</li>
  <li><code class="language-plaintext highlighter-rouge">스쿱</code>: 가공/분석된 데이터 외부로 제공 + 분석/응용 단계에서도 사용</li>
  <li><code class="language-plaintext highlighter-rouge">우지</code>: 길고 복잡한 처리/탐색 프로세스를 우지의 워크플로로 구성해 복잡도 낮추고 자동화</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbt92DO%2FbtrUP0K6TGp%2FppmunqNB41RoKZXQlkfMwk%2Fimg.png" alt="process" /></p>

<p><br /></p>

<h3 id="4-분석응용-레이어">4) 분석/응용 레이어</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">임팔라</code>, <code class="language-plaintext highlighter-rouge">제플린</code>: 스마트카 상태 점검과 운전자 운행 패턴 빠르게 분석</li>
  <li><code class="language-plaintext highlighter-rouge">머하웃</code>, <code class="language-plaintext highlighter-rouge">스파크ML</code>: 스마트카 데이터 분석을 위한 군집, 분류/예측, 추천 등</li>
  <li><code class="language-plaintext highlighter-rouge">R</code>: 통계 분석</li>
  <li><code class="language-plaintext highlighter-rouge">텐서플로</code>: 딥러닝 모델 생성</li>
  <li><code class="language-plaintext highlighter-rouge">플라스크</code>: 서비스 API 제공</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbLt9Z5%2FbtrUNU5JckW%2FRzRkc1cyi7ytgxY9WTpU0K%2Fimg.png" alt="analysis" /></p>

<p><br /></p>

<h2 id="4-하드웨어-아키텍처">4. 하드웨어 아키텍처</h2>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbqUmw2%2FbtrUOQPvzpr%2FSSz0Knsc6ALZxmUGpErP1K%2Fimg.png" alt="hw" /></p>

<p><br /></p>

<h2 id="5-cloudera-manager-cm">5. Cloudera Manager (CM)</h2>

<ul>
  <li>빅데이터 자동화 관리 툴</li>
  <li>하둡을 포함한 에코시스템 17개 편리하게 설치 및 관리
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdgrhZY%2FbtrUKYOQmH2%2Fkn9pfO6wlfXFhPPAYhI7U1%2Fimg.png" alt="cm" /></li>
</ul>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[[출처: 실무로 배우는 빅데이터 기술, 김강원 저]]]></summary></entry><entry><title type="html">[pilot] Ch2. 파일럿 프로젝트 아키텍처 설계(2)</title><link href="http://localhost:4000/hadoop/2023/09/22/architecture2.html" rel="alternate" type="text/html" title="[pilot] Ch2. 파일럿 프로젝트 아키텍처 설계(2)" /><published>2023-09-22T00:00:00+09:00</published><updated>2023-09-23T04:46:00+09:00</updated><id>http://localhost:4000/hadoop/2023/09/22/architecture2</id><content type="html" xml:base="http://localhost:4000/hadoop/2023/09/22/architecture2.html"><![CDATA[<p>[출처: 실무로 배우는 빅데이터 기술, 김강원 저]</p>

<h2 id="1-클라우데라-매니저cm-설치">1. 클라우데라 매니저(CM) 설치</h2>

<ul>
  <li>CM : 빅데이터 에코시스템을 쉽게 설치하고 관리해주는 빅데이터 시스템 자동화 도구</li>
  <li>빅데이터 소프트웨어에 대한 프로비저닝, 매니지먼트, 모니터링 수행
    <ul>
      <li>프로비저닝 : 하둡 에코시스템 편리하게 설치, 삭제, 수정 관리</li>
      <li>매니지먼트 : 설치한 에코시스템의 설정 변경 및 최적화 지원</li>
      <li>모니터링 : 하드웨어의 리소스 및 설치 컴포넌트의 상태 모니터링 / 대시보드</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<h2 id="2-가상머신-서버-설치">2. 가상머신 서버 설치</h2>

<ul>
  <li>원래는 명령어를 이용하여 CM을 설치해야 하지만, 현재 CM 정책이 수정되어 책에 나와있는 명령어로 설치가 안됨</li>
  <li>저자님의 깃허브에서 가상머신 2개 이미지 파일을 받을 수 있음</li>
</ul>

<p>https://drive.google.com/file/d/1oLikMIC6bzt0jNV0n49YNOM0foNPXDZh/view?usp=sharing</p>

<p><br /></p>

<ul>
  <li>기존에 설치했던 서버들을 지우고, 이 이미지 파일로 서버를 설치하면 됨</li>
</ul>

<p><br /></p>

<h2 id="3-파일럿-pc-운영체제-호스트-파일-수정">3. 파일럿 pc 운영체제 호스트 파일 수정</h2>

<ul>
  <li>메모장 관리자 권한으로 실행</li>
  <li>
    <p>[파일] - [열기] 에서 C:\Windows\System32\drivers\etc 로 이동 후 hosts 파일 열기
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAAk4M%2FbtrVOztPphs%2FukJmfqv1cQbcxb0ehpKQT0%2Fimg.png" alt="" /></p>
  </li>
  <li>가상머신에 설치한 리눅스 서버의 IP/도메인명 정보 입력 후 저장 (server01, server02만 입력)</li>
</ul>

<p><br /></p>

<h2 id="4-크롬으로-cm-접속">4. 크롬으로 CM 접속</h2>

<p><a href="http://server01.hadoop.com:7180"></a></p>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FoAePZ%2FbtrVQN5VGHq%2FL05FOfb1W8eRNb8GA3wuj0%2Fimg.png" alt="" /></p>

<ul>
  <li>기동하는데 시간이 조금 걸리기 때문에 접속이 바로 안되더라도 여러 번 새로고침</li>
  <li>사용자 이름, 암호 모두 admin</li>
</ul>

<p><br /></p>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbGNmVJ%2FbtrVT73Coaa%2FYnPz6ZgiGsQ7C2dOwv0yj1%2Fimg.png" alt="" /></p>
<ul>
  <li>CM 첫화면</li>
  <li>우선은 HDFS, YARN, ZooKeeper 만 설치</li>
</ul>

<p><br /></p>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiV0mK%2FbtrVUAK303T%2Fxxbj3ECFODv21OU24TFd61%2Fimg.png" alt="" /></p>
<ul>
  <li>CM 홈화면</li>
  <li>각 서버의 리소스(CPU,  메모리, 디스크, I/O 등)와 설치된 SW 모니터링하며 현재 상태값 보여줌</li>
  <li>각 소프트웨어가 불량으로 표시되어도, 정지 상태가 아니라면 진행에 문제 없음 -&gt; 리소스 절약</li>
</ul>

<p><br /></p>

<h2 id="5-hdfs-구성-변경">5. HDFS 구성 변경</h2>

<h3 id="1-hdfs-복제-계수-설정">1) HDFS 복제 계수 설정</h3>
<ul>
  <li>하둡에서 원본 파일을 저장하면 안정성을 위해 2개의 복제본 추가로 생성해 총 3개의 파일 만들어짐</li>
  <li>파일럿 프로젝트에서는 2개로도 충분하기 때문에 2개로 변경</li>
  <li>복제 계수를 늘리면 여러 데이터노드에 파일이 분산 저장되어 분석 작업시 성능 극대화</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FlO3FO%2FbtrVRCwsHuf%2FhovRKbctGPWa5QcvzHUVz0%2Fimg.png" alt="" /></p>

<p><br /></p>

<h3 id="2-hdfs-접근-권한-해제">2) HDFS 접근 권한 해제</h3>
<ul>
  <li>하둡 파일시스템에 대한 접근 권한 해제</li>
  <li>테스트 환경을 고려한 설정. 실제 플젝에서는 계정별로 접근 권한 분리하여 적용
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcCb6vH%2FbtrVRDvmBcz%2F4AQhAt2qGnLGnALYknfuyK%2Fimg.png" alt="" /></li>
</ul>

<p><br /></p>

<h2 id="3-hdfs-블록-크기-변경">3) HDFS 블록 크기 변경</h2>
<ul>
  <li>128MB -&gt; <strong>64MB</strong></li>
  <li>파일럿 프로젝트에서 수집/적재하는 파일의 최대 크기는 110MB</li>
  <li>하둡은 기본 블록 크기보다 작은 파일 처리시 효율성 떨어짐
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F0C4zG%2FbtrVUzSZKIw%2Fht8VbB1dOjxiisgA2Whpx0%2Fimg.png" alt="" /></li>
</ul>

<p><br /></p>

<h2 id="6-yarn-구성-변경">6. YARN 구성 변경</h2>

<ul>
  <li>YARN 스케줄러와 리소스매니저 메모리 크기 설정
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb5XatB%2FbtrVTUKvbhZ%2F4CyGaZuuIF4YhlBQIlrzW1%2Fimg.png" alt="" /></li>
  <li>1 -&gt; <strong>1.5 GiB</strong></li>
</ul>

<p><br /></p>

<h3 id="2-yarn-스케줄러-변경">2) YARN 스케줄러 변경</h3>
<ul>
  <li>하둡에서 job이 실행될 때 YARN의 스케줄러가 분산 데이터노드의 리소스를 고려해 잡 스케줄링</li>
  <li>FairScheduler -&gt; <strong>FIFOScheduler</strong></li>
  <li>Fair가 더 개선된 스케줄이지만, 개인의 pc로 이용하기에는 리소스 경합이 발생해 병목 현상 발생
    <blockquote>
      <p>병목 현상 : 두 구성 요소의 최대 성능의 차이로 인해 한 구성 요소가 다른 하드웨어의 잠재 성능을 제한하는 것</p>
    </blockquote>
  </li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcQSRkk%2FbtrVUmfmWGe%2Fj1RBAu5WxDgHe3RDrYkjm0%2Fimg.png" alt="" /></p>

<p><br /></p>

<h2 id="7-클러스터-재시작">7. 클러스터 재시작</h2>

<ul>
  <li>설정들 최종 반영하기 위해 클러스터 재시작</li>
  <li>홈에서 [Cluster 1] - [작업] - [재시작]
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcQEJbM%2FbtrVT8oaLnU%2F7Dq2jSHGK5S9GSxY4zG58K%2Fimg.png" alt="" /> <br />
<br /></li>
</ul>

<h2 id="8-hdfs-예제-실습">8. HDFS 예제 실습</h2>

<ul>
  <li>저자님 깃허브에서 예제소스 폴더 다운로드 (제가 올려도 되는건지 모르겠어서 링크는 생략하겠습니다)</li>
</ul>

<h2 id="1-filezilla로-샘플-txt-파일---server02-homebigdata-로-전송">1) Filezilla로 샘플 txt 파일 -&gt; server02 /home/bigdata 로 전송</h2>
<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F7U9Wk%2FbtrVRDWCHvw%2F1LtsmVSqFnZmyaqunxumN1%2Fimg.png" alt="" /> <br />
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FswFYF%2FbtrVUiYoJlt%2FWWsNvYz7QRfLkS5exLtJd0%2Fimg.png" alt="" /></p>

<p><br /></p>

<blockquote>
  <p>HDFS 명령어 <br />
https://hadoop.apache.org/docs/r3.1.2/hadoop-project-dist/hadoop-common/FileSystemShell.html</p>
</blockquote>

<p><br /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="o">[</span>GENERIC_OPTIONS] <span class="o">[</span>COMMAND_OPTIONS]
</code></pre></div></div>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cat : 파일 읽어서 보여줌 (리눅스 cat과 동일)</span>
hdfs dfs <span class="nt">-cat</span> <span class="o">[</span>경로]

<span class="c"># count : 폴더, 파일, 파일 사이즈</span>
hdfs dfs <span class="nt">-count</span> <span class="o">[</span>경로]

<span class="c"># ls : 디렉터리 내부 파일</span>
hdfs dfs <span class="nt">-ls</span> <span class="o">[</span>디렉터리]

<span class="c"># mkdir : 특정 path에 디렉터리 생성</span>
hdfs dfs <span class="nt">-mkdir</span> <span class="o">(</span><span class="nt">-p</span><span class="o">)</span> <span class="o">[</span>path]

<span class="c"># cp : 파일 복사</span>
hdfs dfs <span class="nt">-cp</span> <span class="o">[</span>소스 경로] <span class="o">[</span>복사 경로]
</code></pre></div></div>

<p><br /></p>

<h3 id="2-파일-저장-및-확인">2) 파일 저장 및 확인</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/bigdata
hdfs dfs <span class="nt">-put</span> Sample.txt /tmp
</code></pre></div></div>
<ul>
  <li>Sample.txt 파일이 HDFS의 /tmp 디렉터리로 저장됨</li>
</ul>

<p><br /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-ls</span> /tmp
</code></pre></div></div>
<ul>
  <li>파일 목록에 Sample.txt 존재</li>
</ul>

<p><br /></p>

<h3 id="3-파일-내용-보기">3) 파일 내용 보기</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-cat</span> /tmp/Sample.txt
</code></pre></div></div>
<p><br /></p>

<h3 id="4-저장한-파일-상태-확인">4) 저장한 파일 상태 확인</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-stat</span> <span class="s1">'%b %o %r %u %n'</span> /tmp/Sample.txt
</code></pre></div></div>
<ul>
  <li>파일 크기, 파일 블록 크기, 복제 수, 소유자명, 파일명 정보 보여줌</li>
</ul>

<p><br /></p>

<h3 id="5-파일-이름-바꾸기">5) 파일 이름 바꾸기</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfs <span class="nt">-mv</span> /tmp/Sample.txt /tmp/Sample2.txt
</code></pre></div></div>
<ul>
  <li>Sample.txt -&gt; <strong>Sample2.txt</strong> 로 변경</li>
</ul>

<p><br /></p>

<h3 id="6-파일-시스템-상태-검사">6) 파일 시스템 상태 검사</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs fsck /
</code></pre></div></div>
<ul>
  <li>전체 크기, 디렉터리 수, 파일 수, 노트 수 등 파일 시스템의 전체 상태 보여줌</li>
</ul>

<p><br /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hdfs dfsadmin <span class="nt">-report</span>
</code></pre></div></div>
<ul>
  <li>하둡 파일시스템의 기본 정보 및 통계 보여줌</li>
</ul>

<p><br /></p>

<ul>
  <li>HDFS 파일의 비정상 상태
    <ul>
      <li>HDFS 점검 명령을 실행할 때 파일 시스템에 문제가 발생할 경우 “CORRUPT FILES”, “MISSING BLOCKS”, “MISSING SIZE”, “CORRUPT BLOCKS” 등의 항목에 숫자가 표기됨</li>
      <li>이 같은 상태가 지속되면 하둡은 물론 HBase, 하이브 등에 부분적인 문제 발생 가능</li>
      <li>HDFS는 비정상적인 파일 블록 발견한 경우 다른 노드에 복구하려고 시도, 사용자가 직접 삭제/이동 명령 조치할 수 있음</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 강제로 안전모드 해제</span>
hdfs dfsadmin <span class="nt">-safemode</span> leave

<span class="c"># 손상된 파일 강제로 삭제</span>
hdfs fsck / <span class="nt">-delete</span>

<span class="c"># 손상된 파일을 /lost + found 디렉터리로 이동</span>
hdfs fsck / <span class="nt">-move</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="9-주키퍼-클라이언트-명령을-이용한-설치-확인">9. 주키퍼 클라이언트 명령을 이용한 설치 확인</h2>

<h3 id="1-zookeeper-client-실행">1) zookeeper-client 실행</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>zookeeper-client
</code></pre></div></div>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb1RBT0%2FbtrWzRkXLZN%2FjQqdo6KAYMCJBPd38wNgOK%2Fimg.png" alt="" /> <br />
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FFYtuR%2FbtrWw73p7Oj%2F57nMmLAg60caCRCEGR1nMK%2Fimg.png" alt="" /></p>

<p><br /></p>

<h3 id="2-주키퍼-z노드-등록조회삭제">2) 주키퍼 z노드 등록/조회/삭제</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>create /pilot-pjt bigdata
<span class="nb">ls</span> /
get /pilot-pjt
delete /pilot-pjt
</code></pre></div></div>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcjgD2u%2FbtrWxquRFRa%2F8ZblaH486UKM7KSZhepIE0%2Fimg.png" alt="" /></p>

<ul>
  <li>bigdata를 담고 있는 pilot-pjt 라는 znode 생성, 조회, 삭제</li>
</ul>

<p><br /></p>

<ul>
  <li>zookeeper와 znode
    <ul>
      <li>zookeeper : 분산 어플리케이션을 구성하기 쉽게 도와주는 시스템 (znode로 구성된 분산 데이터 모델을 지원하는 시스템)</li>
      <li>z노드 : 클러스터를 구성하고 있는 각각의 서버</li>
      <li>주키퍼는 데이터를 디렉터리 구조로 관리하며, key-value 스토리지처럼 key로 접근 가능</li>
      <li>디렉터리 구조의 각 데이터 노드가 znode</li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>참고 사이트   <br />
https://engkimbs.tistory.com/660</p>
</blockquote>

<p><br /></p>

<h2 id="10-스마트카-로그-시뮬레이터-설치">10. 스마트카 로그 시뮬레이터 설치</h2>

<h3 id="1-server02에-작업-폴더-생성">1) server02에 작업 폴더 생성</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home
<span class="nb">mkdir</span> <span class="nt">-p</span> /home/pilot-pjt/working/car-batch-log
<span class="nb">mkdir</span> /home/pilot-pjt/working/driver-realtime-log
<span class="nb">chmod </span>777 <span class="nt">-R</span> /home/pilot-pjt
</code></pre></div></div>

<p><br /></p>

<h3 id="2-자바-컴파일-실행-환경-변경-17---18">2) 자바 컴파일, 실행 환경 변경 (1.7 -&gt; 1.8)</h3>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">rm</span> /usr/bin/java
<span class="nb">rm</span> /usr/bin/javac
<span class="nb">ln</span> <span class="nt">-s</span> /usr/java/jdk1.8.0_181-cloudera/bin/javac /usr/bin/javac
<span class="nb">ln</span> <span class="nt">-s</span> /usr/java/jdk1.8.0_181-cloudera/bin/java /usr/bin/java
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>java <span class="nt">-version</span>
</code></pre></div></div>
<ul>
  <li>1.8.0_181 확인</li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDuWeE%2FbtrWv8B0NEs%2FjCK9ED53KM8zf0y46hF8G0%2Fimg.png" alt="" /></p>

<p><br /></p>

<h3 id="3-자바로-만들어진-스마트카-로그-시뮬레이터-프로그램-server02에-업로드">3) 자바로 만들어진 스마트카 로그 시뮬레이터 프로그램 server02에 업로드</h3>
<ul>
  <li>
    <p>파일질라 이용
<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FceNJHe%2FbtrWxtrCjBC%2FkF7u4u2kDS90Gnx38nQYK1%2Fimg.png" alt="" /></p>
  </li>
  <li>
    <p>bigdata.smartcar.loggen-1.0.jar 파일을 /home/pilot-pjt/working에 업로드</p>
  </li>
</ul>

<p><br /></p>

<h3 id="4-스마트카-로그-시뮬레이터-실행">4) 스마트카 로그 시뮬레이터 실행</h3>
<ul>
  <li><code class="language-plaintext highlighter-rouge">bigdata.smartcar.loggen-1.0.jar</code> 파일에 두 개의 메인 자바프로그램이 있음
    <ul>
      <li>스마트카 운전자의 운행 정보를 실시간으로 발생시키는 <code class="language-plaintext highlighter-rouge">DriverLogMain.java</code></li>
      <li>스마트카의 상태 정보를 주기적으로 발생시키는 <code class="language-plaintext highlighter-rouge">CarLoginMain.java</code></li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">DriverLogMain.java</code> 먼저 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working
java <span class="nt">-cp</span> bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.DriverLogMain 20160101 10
</code></pre></div>    </div>
  </li>
  <li>java -cp [경로] [클래스 이름]  (현재 열려 있는 명령 창에서만 유효)
    <ul>
      <li>cp (classpath) : JVM이 프로그램을 실행할 때 클래스 파일을 찾는 데 기준이 되는 파일 경로, JVM의 매개 변수</li>
      <li>자바에서 외부 라이브러리 파일이나 jar 파일 포함하여 컴파일하기 위해서는 classpath 이용</li>
    </ul>
  </li>
  <li><strong>bigdata.smartcar.loggen-1.0.jar</strong> : 포함하고자 하는 라이브러리나 jar 파일 (필요한 클래스 파일들)</li>
  <li><strong>com.wikibook.bigdata.smartcar.loggen.DriverLogMain</strong> : 컴파일 할 파일</li>
</ul>

<p><br /></p>

<ul>
  <li><strong>시뮬레이터 작동 확인</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working/driver-realtime-log
<span class="nb">tail</span> <span class="nt">-f</span> SmartCarDriverInfo.log
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F0Y5EV%2FbtrWzRZA0Hx%2FR9Jloh0FrZuJ8vSS2TO9L0%2Fimg.png" alt="" /></p>

<p><br /></p>

<ul>
  <li><strong>데이터 형식 정의</strong></li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiqEGG%2FbtrWx8Hv5jU%2FWCKW0a6yZ6GUqpKRrZKitK%2Fimg.png" alt="" /></p>

<p><br /></p>

<ul>
  <li><strong>CarLogMain.java 실행</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working
java <span class="nt">-cp</span> bigdata.smartcar.loggen-1.0.jar com.wikibook.bigdata.smartcar.loggen.CarLogMain 20160101 10
</code></pre></div>    </div>
  </li>
  <li>코드 설명
    <ul>
      <li>첫번째 매개 변수: 실행 날짜</li>
      <li>두번째 매개 변수: 스마트카 대 수
  -&gt; 2016년 1월 1일 기준으로 10대의 스마트카에 대한 로그 파일인 SmartCarStatusInfo_20160101.txt 생성됨</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>시뮬레이터 작동 확인</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd</span> /home/pilot-pjt/working/SmartCar
<span class="nb">tail</span> <span class="nt">-f</span> SmartCarStatusInfo_20160101.txt
</code></pre></div>    </div>
    <p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fef6z6h%2FbtrWwgGOUHT%2FD1z6WrbOshWUdPvkjEiYCk%2Fimg.png" alt="" /></p>
  </li>
</ul>

<p><br /></p>

<ul>
  <li><strong>데이터 형식 정의</strong></li>
</ul>

<p><img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbu0fNq%2FbtrWx5c0MEM%2FU9JS4am5kifZ5iqA58Bk50%2Fimg.png" alt="" /></p>]]></content><author><name>GitHub User</name></author><category term="Hadoop" /><summary type="html"><![CDATA[[출처: 실무로 배우는 빅데이터 기술, 김강원 저]]]></summary></entry></feed>